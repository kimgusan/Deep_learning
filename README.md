# Deep Learning

-   ì¸ê³µ ì‹ ê²½ë§(Artivicial Neural Network)ì˜ ì¸µì„ ì—°ì†ì ìœ¼ë¡œ ê¹Šê²Œ ìŒ“ì•„ì˜¬ë ¤ ë°ì´í„°ë¥¼ í•™ìŠµí•˜ëŠ” ë°©ì‹ì„ ì˜ë¯¸í•œë‹¤.
-   ì¸ê°„ì´ í•™ìŠµí•˜ê³  ê¸°ì–µí•˜ëŠ” ë§¤ì»¤ë‹ˆì¦˜ì„ ëª¨ë°©í•œ ê¸°ê³„í•™ìŠµì´ë‹¤.
-   ì¸ê°„ì€ í•™ìŠµ ì‹œ, ë‡Œì— ìˆëŠ” ë‰´ëŸ°ì´ ìê·¹ì„ ë°›ì•„ë“¤ì—¬ì„œ ì¼ì • ìê·¹ ì´ìƒì´ ë˜ë©´, í™”í•™ë¬¼ì§ˆì„ í†µí•´ ë‹¤ë¥¸ ë‰´ëŸ°ê³¼ ì—°ê²°ë˜ë©° í•´ë‹¹ ë¶€ë¶„ì´ ë°œë‹¬í•œë‹¤.
-   ìê·¹ì´ ì•½í•˜ê±°ë‚˜ ê¸°ì¤€ì¹˜ë¥¼ ë„˜ì§€ ëª»í•˜ë©´, ë‰´ëŸ°ì€ ì—°ê²°ë˜ì§€ ì•ŠëŠ”ë‹¤.
-   ì…ë ¥í•œ ë°ì´í„°ê°€ í™œì„± í•¨ìˆ˜ì—ì„œ ì„ê³„ì ì„ ë„˜ê²Œ ë˜ë©´ ì¶œë ¥ëœë‹¤.
-   ì´ˆê¸° ì¸ê³µ ì‹ ê²½ë§(Perceptron)ì—ì„œ ê¹Šê²Œ ì¸µì„ ìŒ“ì•„ í•™ìŠµí•˜ëŠ” ë”¥ ëŸ¬ë‹ìœ¼ë¡œ ë°œì „í•œë‹¤.
-   ë”¥ ëŸ¬ë‹ì€ Input nodes layer, Hidden nodes layer, Output nodes layer, ì´ë ‡ê²Œ ì„¸ ê°€ì§€ ì¸µì´ ì¡´ì¬í•œë‹¤.

## ëª©ì°¨

1. <details>
       <summary>perceptron</summary>
       <ul>
           <li>SLP
               <details>
                   <summary>theory & Code</summary>
                   <ul>
                       <li><a href="#slp-theory">ì´ë¡ </a></li>
                       <li><a href="#slp-code">ì£¼ìš” ì½”ë“œ</a></li>
                   </ul>
               </details>
           </li>
           <li>MLP
               <details>
                   <summary>theory & Code</summary>
                   <ul>
                       <li><a href="#mlp-theory">ì´ë¡ </a></li>
                       <li><a href="#mlp-code">ì£¼ìš” ì½”ë“œ</a></li>
                   </ul>
               </details>
           </li>
           <li>activation_function
               <details>
                   <summary>theory & Code</summary>
                   <ul>
                       <li><a href="#act-theory">ì´ë¡ </a></li>
                       <li><a href="#act-code">ì£¼ìš” ì½”ë“œ</a></li>
                   </ul>
               </details>
           </li>
           <li>optimizer
               <details>
                   <summary>theory & Code</summary>
                   <ul>
                       <li><a href="#opti-theory">ì´ë¡ </a></li>
                       <li><a href="#opti-code">ì£¼ìš” ì½”ë“œ</a></li>
                   </ul>
               </details>
           </li>
       </ul>
   </details>
2. [tensorflow](#tensorflow)
3. [CNN](#cnn)

---

## perceptron

### SLP

#### <div id="slp-theory">SLP ì´ë¡ </div>

SLP ê´€ë ¨ ì´ë¡  ë‚´ìš©

#### <div id="slp-code">SLP Code</div>

SLP ê´€ë ¨ ì½”ë“œ ë‚´ìš©

### MLP

#### <div id="mlp-theory">MLP ì´ë¡ </div>

MLP ê´€ë ¨ ì´ë¡  ë‚´ìš©

#### <div id="mlp-code">MLP Code</div>

MLP ê´€ë ¨ ì½”ë“œ ë‚´ìš©

### activation_function

#### <div id="act-theory">Activation Function ì´ë¡ </div>

Activation Function ê´€ë ¨ ì´ë¡  ë‚´ìš©

#### <div id="act-code">Activation Function Code</div>

Activation Function ê´€ë ¨ ì½”ë“œ ë‚´ìš©

### optimizer

#### <div id="opti-theory">Optimizer ì´ë¡ </div>

Optimizer ê´€ë ¨ ì´ë¡  ë‚´ìš©

#### <div id="opti-code">Optimizer Code</div>

Optimizer ê´€ë ¨ ì½”ë“œ ë‚´ìš©

## tensorflow

<div id="tensorflow">

### Tensorflow, í…ì„œí”Œë¡œìš°

-   êµ¬ê¸€ì´ ê°œë°œí•œ ì˜¤í”ˆì†ŒìŠ¤ ì†Œí”„íŠ¸ì›¨ì–´ ë¼ì´ë¸ŒëŸ¬ë¦¬ì´ë©°, ë¨¸ì‹ ëŸ¬ë‹ê³¼ ë”¥ëŸ¬ë‹ì„ ì‰½ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ë‹¤ì–‘í•œ ê¸°ëŠ¥ì„ ì œê³µí•œë‹¤.
-   ì£¼ë¡œ ì´ë¯¸ì§€ ì¸ì‹ì´ë‚˜ ë°˜ë³µ ì‹ ê²½ë§ êµ¬ì„±, ê¸°ê³„ ë²ˆì—­, í•„ê¸° ìˆ«ì íŒë³„ ë“±ì„ ìœ„í•œ ê°ì¢… ì‹ ê²½ë§ í•™ìŠµì— ì‚¬ìš©ëœë‹¤.
-   ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ ë§Œë“¤ ë•Œ, ê¸°ì´ˆë¶€í„° ì„¸ì„¸í•˜ê²Œ ì‘ì—…í•´ì•¼ í•˜ê¸° ë•Œë¬¸ì— ì§„ì…ì¥ë²½ì´ ë†’ë‹¤.

### Keras, ì¼€ë¼ìŠ¤

-   ì¼ë°˜ ì‚¬ìš© ì‚¬ë¡€ì— ìµœì í™”ë˜ê³  "ìµœì í™”, ê°„ë‹¨, ì¼ê´€, ë‹¨ìˆœí™”"ëœ ì¸í„°í˜ì´ìŠ¤ë¥¼ ì œê³µí•œë‹¤.
-   ì†ì‰½ê²Œ ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ ê°œë°œí•˜ê³  í™œìš©í•  ìˆ˜ ìˆë„ë¡ ì§ê´€ì ì¸ APIë¥¼ ì œê³µí•œë‹¤.
-   í…ì„œí”Œë¡œìš° 2ë²„ì „ ì´ìƒë¶€í„° ì¼€ë¼ìŠ¤ê°€ í¬í•¨ë˜ì—ˆê¸° ë•Œë¬¸ì— í…ì„œí”Œë¡œìš°ë¥¼ í†µí•´ ì¼€ë¼ìŠ¤ë¥¼ ì‚¬ìš©í•œë‹¤.
-   ê¸°ì¡´ Keras íŒ¨í‚¤ì§€ë³´ë‹¤ëŠ” ì´ì œ Tensorflowì— ë‚´ì¥ëœ Keras ì‚¬ìš©ì´ ë” ê¶Œì¥ëœë‹¤.

---

#### Sequential API

-   ê°„ë‹¨í•œ ëª¨ë¸ì„ êµ¬í˜„í•˜ê¸°ì— ì í•©í•˜ê³  ë‹¨ìˆœí•˜ê²Œ ì¸µì„ ìŒ“ëŠ” ë°©ì‹ìœ¼ë¡œ ì‰½ê³  ì‚¬ìš©í•˜ê¸°ê°€ ê°„ë‹¨í•˜ë‹¤.
-   ë‹¨ì¼ ì…ë ¥ ë° ì¶œë ¥ë§Œ ìˆìœ¼ë¯€ë¡œ ë ˆì´ì–´ë¥¼ ê³µìœ í•˜ê±°ë‚˜ ì—¬ëŸ¬ ì…ë ¥ ë˜ëŠ” ì¶œë ¥ì„ ê°€ì§ˆ ìˆ˜ ìˆëŠ” ëª¨ë¸ì„ ìƒì„±í•  ìˆ˜ ì—†ë‹¤.

#### Funcional API

-   Funtional APIëŠ” Sequential APIë¡œëŠ” êµ¬í˜„í•˜ê¸° ì–´ë ¤ìš´ ë³µì¡í•œ ëª¨ë¸ë“¤ì„ êµ¬í˜„í•  ìˆ˜ ìˆë‹¤.
-   ì—¬ëŸ¬ ê°œì˜ ì…ë ¥ ë° ì¶œë ¥ì„ ê°€ì§„ ëª¨ë¸ì„ êµ¬í˜„í•˜ê±°ë‚˜ ì¸µ ê°„ì˜ ì—°ê²° ë° ì—°ì‚°ì„ ìˆ˜í–‰í•˜ëŠ” ëª¨ë¸ êµ¬í˜„ ì‹œ ì‚¬ìš©í•œë‹¤.

---

### Grayscale, RGB

-   í‘ë°± ì´ë¯¸ì§€ì™€ ì»¬ëŸ¬ ì´ë¯¸ì§€ëŠ” ê° 2ì°¨ì›ê³¼ 3ì°¨ì›ìœ¼ë¡œ í‘œí˜„ë  ìˆ˜ ìˆë‹¤.
-   í‘ë°± ì´ë¯¸ì§€ëŠ” 0 ~ 255ë¥¼ ê°–ëŠ” 2ì°¨ì› ë°°ì—´(ë†’ì´ X ë„ˆë¹„)ì´ê³ ,  
    ì»¬ëŸ¬ ì´ë¯¸ì§€ëŠ” 0 ~ 255ë¥¼ ê°–ëŠ” R, G, B 2ì°¨ì› ë°°ì—´ 3ê°œë¥¼ ê°–ëŠ” 3ì°¨ì›(ë†’ì´ X ë„ˆë¹„ X ì±„ë„)ì´ë‹¤.

### Grayscale Image Matrix

-   ê²€ì€ìƒ‰ì— ê°€ê¹Œìš´ ìƒ‰ì€ 0ì— ê°€ê¹ê³  í°ìƒ‰ì— ê°€ê¹Œìš°ë©´ 255ì— ê°€ê¹ë‹¤.
-   ëª¨ë“  í”½ì…€ì´ featureì´ë‹¤.

---

### Callback API (í™œìš©ì„±ì´ ë†’ìŒ!)

-   ëª¨ë¸ì´ í•™ìŠµ ì¤‘ì— ì¶©ëŒì´ ë°œìƒí•˜ê±°ë‚˜ ë„¤íŠ¸ì›Œí¬ê°€ ëŠê¸°ë©´, ëª¨ë“  í›ˆë ¨ ì‹œê°„ì´ ë‚­ë¹„ë  ìˆ˜ ìˆê³ ,  
    ê³¼ì í•©ì„ ë°©ì§€í•˜ê¸° ìœ„í•´ í›ˆë ¨ì„ ì¤‘ê°„ì— ì¤‘ì§€í•´ì•¼ í•  ìˆ˜ë„ ìˆë‹¤.
-   ëª¨ë¸ì´ í•™ìŠµì„ ì‹œì‘í•˜ë©´ í•™ìŠµì´ ì™„ë£Œë  ë•Œê¹Œì§€ ì•„ë¬´ëŸ° ì œì–´ë¥¼ í•˜ì§€ ëª»í•˜ê²Œ ë˜ê³ ,  
    ì‹ ê²½ë§ í›ˆë ¨ì„ ì™„ë£Œí•˜ëŠ” ë°ì—ëŠ” ëª‡ ì‹œê°„ ë˜ëŠ” ë©°ì¹ ì´ ê±¸ë¦´ ìˆ˜ ìˆê¸° ë•Œë¬¸ì— ëª¨ë¸ì„ ëª¨ë‹ˆí„°ë§í•˜ê³  ì œì–´í•  ìˆ˜ ìˆëŠ” ê¸°ëŠ¥ì´ í•„ìš”í•˜ë‹¤.
-   í›ˆë ¨ ì‹œ(fit()) Callback APIë¥¼ ë“±ë¡ì‹œí‚¤ë©´ ë°˜ë³µ ë‚´ì—ì„œ íŠ¹ì • ì´ë²¤íŠ¸ ë°œìƒë§ˆë‹¤ ë“±ë¡ëœ callbackì´ í˜¸ì¶œë˜ì–´ ìˆ˜í–‰ëœë‹¤.

**1) ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=False, save_weight_only=False, mode='auto')**

-   íŠ¹ì • ì¡°ê±´ì— ë”°ë¼ì„œ ëª¨ë¸ ë˜ëŠ” ê°€ì¤‘ì¹˜ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•œë‹¤.
-   filepath: "weight.{epoch: 03d}-{val_loss:.4f}-{acc:.4f}.weights.hdf5" ì™€ ê°™ì´ ëª¨ë¸ì˜ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì €ì¥í•œë‹¤.
-   monitor: ëª¨ë‹ˆí„°ë§í•  ì„±ëŠ¥ ì§€í‘œë¥¼ ì‘ì„±í•œë‹¤.
-   save_best_only: ê°€ì¥ ì¢‹ì€ ì„±ëŠ¥ì„ ë‚˜íƒ€ë‚´ëŠ” ëª¨ë¸ì„ ì €ì¥í•  ì§€ì— ëŒ€í•œ ì—¬ë¶€
-   save_weights_only: weightsë§Œ ì €ì¥í•  ì§€ì— ëŒ€í•œ ì—¬ë¶€
-   mode: {auto, min, max} ì¤‘ í•œ ê°€ì§€ë¥¼ ì‘ì„±í•œë‹¤. monitorì˜ ì„±ëŠ¥ ì§€í‘œì— ë”°ë¼ ì¢‹ì€ ê²½ìš°ë¥¼ ì„ íƒí•œë‹¤.  
    \*monitorì˜ ì„±ëŠ¥ ì§€í‘œê°€ ê°ì†Œí•´ì•¼ ì¢‹ì€ ê²½ìš° min, ì¦ê°€í•´ì•¼ ì¢‹ì€ ê²½ìš° max, monitorì˜ ì´ë¦„ìœ¼ë¡œë¶€í„° ìë™ìœ¼ë¡œ ìœ ì¶”í•˜ê³  ì‹¶ë‹¤ë©´ autoë¥¼ ì‚¬ìš©í•œë‹¤.

**2) ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, verbose=0, mode='auto, min_lr=0')** (LR: Learning Rate)

-   íŠ¹ì • ë°˜ë³µë™ì•ˆ ì„±ëŠ¥ì´ ê°œì„ ë˜ì§€ ì•Šì„ ë•Œ, í•™ìŠµë¥ ì„ ë™ì ìœ¼ë¡œ ê°ì†Œì‹œí‚¨ë‹¤.
-   monitor: ëª¨ë‹ˆí„°ë§í•  ì„±ëŠ¥ ì§€í‘œë¥¼ ì‘ì„±í•œë‹¤.
-   factor: í•™ìŠµë¥ ì„ ê°ì†Œì‹œí‚¬ ë¹„ìœ¨, ìƒˆë¡œìš´ í•™ìŠµë¥  = ê¸°ì¡´ í•™ìŠµë¥  \* factor
-   patience: í•™ìŠµë¥ ì„ ì¤„ì´ê¸° ì „ì— monitorí•  ë°˜ë³µ íšŸìˆ˜
-   mode: {auto, min, max} ì¤‘ í•œ ê°€ì§€ë¥¼ ì‘ì„±í•œë‹¤. monitorì˜ ì„±ëŠ¥ ì§€í‘œì— ë”°ë¼ ì¢‹ì€ ê²½ìš°ë¥¼ ì„ íƒí•œë‹¤.  
    \*monitorì˜ ì„±ëŠ¥ ì§€í‘œê°€ ê°ì†Œí•´ì•¼ ì¢‹ì€ ê²½ìš° min, ì¦ê°€í•´ì•¼ ì¢‹ì€ ê²½ìš° max, monitorì˜ ì´ë¦„ìœ¼ë¡œë¶€í„° ìë™ìœ¼ë¡œ ìœ ì¶”í•˜ê³  ì‹¶ë‹¤ë©´ autoë¥¼ ì‚¬ìš©í•œë‹¤.

**3) EarlyStopping(monitor='val_loss'm patient=0, verbose=0, mode='auto')**

-   íŠ¹ì • ë°˜ë³µë™ì•ˆ ì„±ëŠ¥ì´ ê°œì„ ë˜ì§€ ì•Šì„ ë•Œ, í•™ìŠµì„ ì¡°ê¸°ì— ì¤‘ë‹¨í•œë‹¤.
-   monitor: ëª¨ë‹ˆí„°ë§í•  ì„±ëŠ¥ ì§€í‘œë¥¼ ì‘ì„±í•œë‹¤.
-   patience: Early Stoppingì„ ì ìš©í•˜ê¸° ì „ì— monitorí•  ë°˜ë³µ íšŸìˆ˜.
-   mode: {auto, min, max} ì¤‘ í•œ ê°€ì§€ë¥¼ ì‘ì„±í•œë‹¤. monitorì˜ ì„±ëŠ¥ ì§€í‘œì— ë”°ë¼ ì¢‹ì€ ê²½ìš°ë¥¼ ì„ íƒí•œë‹¤.  
    \*monitorì˜ ì„±ëŠ¥ ì§€í‘œê°€ ê°ì†Œí•´ì•¼ ì¢‹ì€ ê²½ìš° min, ì¦ê°€í•´ì•¼ ì¢‹ì€ ê²½ìš° max, monitorì˜ ì´ë¦„ìœ¼ë¡œë¶€í„° ìë™ìœ¼ë¡œ ìœ ì¶”í•˜ê³  ì‹¶ë‹¤ë©´ autoë¥¼ ì‚¬ìš©í•œë‹¤.

#### <div id="tensowflow-code">tensorflow Code</div>

<details>
    <summary> 1. kerasì—ì„œ ë¶ˆëŸ¬ì˜¨ ì´ë¯¸ì§€ì— ëŒ€í•˜ì—¬ ì´ë¯¸ì§€ í‘œê¸° í•¨ìˆ˜ ì½”ë“œ</summary>

        def show_images(images, targets, ncols=8):
        figure, axs = plt.subplots(figsize=(22, 6), nrows=1, ncols=ncols)
        for i in range(ncols):
            axs[i].imshow(images[i], cmap='gray')
            axs[i].set_title(class_names[targets[i]])

        show_images(train_images[:8], train_targets[:8])
        show_images(train_images[8:16], train_targets[8:16])

</details>

<details>
    <summary> 2. Sequential API Code</summary>

        from tensorflow.keras.layers import Dense, Flatten
        from tensorflow.keras.models import Sequential
        from tensorflow.keras.losses import CategoricalCrossentropy
        from tensorflow.keras.optimizers import Adam

        # shape
        INPUT_SIZE = 28

        model = Sequential([
            # ì…ë ¥ì¸µ
            Flatten(input_shape=(INPUT_SIZE, INPUT_SIZE)),
            # ì€ë‹‰ì¸µ
            Dense(64, activation='relu'),
            # ì€ë‹‰ì¸µ
            Dense(128, activation='relu'),
            # ì¶œë ¥ì¸µ (ë‹¤ì¤‘ ë¶„ë¥˜ ì´ê¸° ë•Œë¬¸ì— í™œì„± í•¨ìˆ˜ëŠ” softmax ì‚¬ìš©)
            Dense(10, activation='softmax')
        ])

        # # ê²½ì‚¬í•˜ê°•ë²• optimizer, ë° ìµœì í™”
        # ì†ì‹¤í•¨ìˆ˜ëŠ” ë‹¤ì¤‘ í•¨ìˆ˜ì´ê¸° ë•Œë¬¸ì— CategoricalCrossentropy ì‚¬ìš©
        model.compile(optimizer=Adam(0.001), loss=CategoricalCrossentropy(), metrics=['acc'])

</details>

<details>
    <summary>3. ê²€ì¦ë°ì´í„°ë¥¼ í¬í•¨í•œ ì •í™•ë„ ê·¸ë˜í”„ í‘œí˜„</summary>
        #ë¼ì´ë¸ŒëŸ¬ë¦¬ í˜¸ì¶œ
        import matplotlib.pyplot as plt

        plt.plot(history.history['acc'], label='train')
        plt.plot(history.history['val_acc'], label='validation')
        plt.legend()
        plt.show()

</details>

<details>
<summary>4. ê²€ì¦ ë°ì´í„° ì •í™•ë„ ë° ì†ì‹¤ í•¨ìˆ˜ í™•ì¸</summary>

    # ê²€ì¦ë°ì´í„°ë¥¼ í™•ì¸í•˜ê¸° ìœ„í•œ evaluate í•¨ìˆ˜ ì‚¬ìš©
    model.evaluate(test_images, test_oh_targets, batch_size=32)

</details>

<details>
    <summary> 5. Funtional API Code</summary>

        ### call ë§¤ì§ ë©”ì†Œë“œ
        # call í•¨ìˆ˜ (ë§¤ì§ ë©”ì†Œë“œ)
        class Test:
            def __call__(self,data):
                return data + 10

---

        # call í•¨ìˆ˜ ë•ë¶„ì— ìƒì„±ì ë’¤ì— ê°’ì„ ë„£ì–´ì¤˜ì„œ ì‚¬ìš©ì´ ê°€ëŠ¥í•˜ë‹¤.

        from tensorflow.keras.layers import Layer, Input, Dense, Flatten
        from tensorflow.keras.models import Model

        INPUT_SIZE = 28

        def create_model():
            input_tensor = Input((INPUT_SIZE,INPUT_SIZE))
            x = Flatten()(input_tensor)
            x = Dense(64, activation='relu')(x)
            x = Dense(128, activation='relu')(x)
            output = Dense(10, activation='softmax')(x)

            model = Model(inputs=input_tensor, outputs=output)
            return model


        model = create_model()
        model.summary()

</details>

<details>
    <summary>6. tensorflow ì „ì²˜ë¦¬ ê³¼ì • (arrayê°ì²´ ë³€í™˜, ì›-í•« ì¸ì½”ë”©, í›ˆë ¨/ê²€ì¦/í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„ë¦¬)</summary>

    from tensorflow.keras.utils import to_categorical
    from sklearn.model_selection import train_test_split
    import numpy as np

    (train_images, train_targets), (test_images, test_targets) = fashion_mnist.load_data()

    # array ê°ì²´ ë³€í™˜ ë° ì‹¤ìˆ˜ ë³€í™˜, ìƒ‰ìƒì„ í‘œí˜„í•˜ê¸° ìœ„í•´ 255.0 ìœ¼ë¡œ ë³€í™˜
    def get_preprocessed_data(images, targets):
        images = np.array(images / 255.0, dtype=np.float32)
        targets = np.array(targets, dtype=np.float32)

        return images, targets

    # íƒ€ê²Ÿ ë°ì´í„°ì— ëŒ€í•˜ì—¬ ì›-í•« ì¸ì½”ë”© ë©”ì†Œë“œ ìƒì„±
    def get_preprocessed_ohe(images, targets):
        images, targets = get_preprocessed_data(images, targets)
        oh_targets = to_categorical(targets)

        return images, oh_targets

    # í›ˆë ¨, ê²€ì¦, í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ë¶„ë¦¬í•˜ê¸° ìœ„í•œ ë©”ì†Œë“œ ìƒì„±
    def get_train_valid_test(train_images, train_targets, test_images, test_targets, validation_size=0.2, random_state=124):
        train_images, train_oh_targets = get_preprocessed_ohe(train_images, train_targets)
        test_images, test_oh_targets = get_preprocessed_ohe(test_images, test_targets)

        train_images, validation_images, train_oh_targets, validation_oh_targets = \
        train_test_split(train_images, train_oh_targets, stratify=train_oh_targets, test_size=validation_size, random_state=random_state)

        return (train_images, train_oh_targets), (validation_images, validation_oh_targets), (test_images, test_oh_targets)

---

    from tensorflow.keras.datasets import fashion_mnist

    (train_images, train_targets), (test_images, test_targets) = fashion_mnist.load_data()

    (train_images, train_oh_targets), (validation_images, validation_oh_targets), (test_images, test_oh_targets) = \
    get_train_valid_test(train_images, train_targets, test_images, test_targets)

    print(train_images.shape, train_oh_targets.shape)
    print(validation_images.shape, validation_oh_targets.shape)
    print(test_images.shape, test_oh_targets.shape)

</details>

<details>
    <summary>tip. model.predict (pred_prob), np.argmax</summary>

        # í›ˆë ¨ê³¼ ì •ë‹µì˜ ì°¨ì›ì„ ë§ì¶”ê¸° ìœ„í•´ ì°¨ì›ì„ ëŠ˜ë¦¬ëŠ” ì‘ì—…
        import numpy as np
        np.expand_dims(test_images[0], axis=0).shape

        # ì •ë‹µì´ ë‚˜ì˜¬ í™•ë¥ 
        pred_prob = model.predict(np.expand_dims(test_images[8500], axis=0))
        print(pred_prob)

        # ì •ë‹µì´ ë‚˜ì˜¬ í™•ë¥  ë° ì •ë‹´ì„ ì¶œë ¥
        pred_proba = model.predict(np.expand_dims(test_images[326], axis=0))
        print('softmax output:', pred_proba)

        # argmax() : ê°€ì¥ ë†’ì€ ê°’ì˜ ì¸ë±ìŠ¤ë¥¼ ì°¾ì•„ì„œ í‘œê¸°í•˜ëŠ” í•¨ìˆ˜
        pred = np.argmax(np.squeeze(pred_proba))
        print('predicted target value:', pred)

</details>

<details>
    <summary>7. Callback API(ModelCheckpoint, ReduceLROnPlateau, EarlyStopping)</summary>

        from tensorflow.keras.optimizers import Adam
        from tensorflow.keras.losses import CategoricalCrossentropy
        from tensorflow.keras.callbacks import ModelCheckpoint

        model = create_model()
        model.compile(optimizer=Adam(), loss=CategoricalCrossentropy(), metrics=['acc'])

        mcp_cb = ModelCheckpoint(
            filepath="./callback_files/weights.{epoch:03d}-{val_loss:.4f}-{acc:.4f}.weights.h5",
            monitor='val_loss',
            save_best_only=False,
            # Modelì´ ì•„ëŠ” weight ë¥¼ ì €ì¥í•  ë•Œ Trueì„¤ì •
            save_weights_only=True,
            mode='min'
        )

        rlr_cb = ReduceLROnPlateau(
            monitor='val_loss',
            factor=0.1,
            patience=2,
            mode='min'
        )

        ely_cb = EarlyStopping(
            monitor='val_loss',
            patience=3,
            mode='min'
        )

        history = model.fit(x=train_images, y=train_oh_targets, validation_data=(validation_images, validation_oh_targets), batch_size=64, epochs=20, callbacks=[mcp_cb, rlr_cb, ely_cb])

</details>
</div>

<hr>

## CNN

<div id="cnn">

### CNN (Convolutional Neural Network), í•©ì„±ê³± ì‹ ê²½ë§

-   ì‹¤ì œ ì´ë¯¸ì§€ ë°ì´í„°ëŠ” ë¶„ë¥˜ ëŒ€ìƒì´ ì´ë¯¸ì§€ì—ì„œ ê³ ì •ëœ ìœ„ì¹˜ì— ìˆì§€ ì•Šì€ ê²½ìš°ê°€ ëŒ€ë¶€ë¶„ì´ë‹¤.
-   ì‹¤ì œ ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ ë¶„ë¥˜í•˜ê¸° ìœ„í•´ì„œëŠ”, ì´ë¯¸ì§€ì˜ ê° featureë“¤ì„ ê·¸ëŒ€ë¡œ í•™ìŠµí•˜ëŠ” ê²ƒì´ ì•„ë‹Œ, CNNìœ¼ë¡œ íŒ¨í„´ì„ ì¸ì‹í•œ ë’¤ í•™ìŠµí•´ì•¼ í•œë‹¤.

-   ì´ë¯¸ì§€ì˜ í¬ê¸°ê°€ ì»¤ì§ˆ ìˆ˜ë¡ êµ‰ì¥íˆ ë§ì€ Weightê°€ í•„ìš”í•˜ê¸° ë•Œë¬¸ì— ë¶„ë¥˜ê¸°ì— ë°”ë¡œ ë„£ì§€ ì•Šê³ , ì´ë¥¼ ì‚¬ì „ì— ì¶”ì¶œ ë° ì¶•ì†Œí•´ì•¼ í•œë‹¤.
-   CNNì€ ì¸ê°„ì˜ ì‹œì‹ ê²½ êµ¬ì¡°ë¥¼ ëª¨ë°©í•œ ê¸°ìˆ ë¡œì„œ, ì´ë¯¸ì§€ì˜ íŒ¨í„´ì„ ì°¾ì„ ë•Œ ì‚¬ìš©í•œë‹¤.
-   Feature Extractionì„ í†µí•´ ê° ë‹¨ê³„ë¥¼ ê±°ì¹˜ë©´ì„œ, í•¨ì¶•ëœ ì´ë¯¸ì§€ ì¡°ê°ìœ¼ë¡œ ë¶„ë¦¬ë˜ê³  ê° ì´ë¯¸ì§€ ì¡°ê°ì„ í†µí•´ ì´ë¯¸ì§€ì˜ íŒ¨í„´ì„ ì¸ì‹í•œë‹¤.

-   CNNì€ ë¶„ë¥˜í•˜ê¸°ì— ì í•©í•œ ìµœì ì˜ featureë¥¼ ì¶”ì¶œí•˜ê³ , ìµœì ì˜ featureë¥¼ ì¶”ì¶œí•˜ê¸° ìœ„í•œ ìµœì ì˜ Weightì™€ filterë¥¼ ê³„ì‚°í•œë‹¤.

#### Filter

-   ì¼ë°˜ì ìœ¼ë¡œ ì •ë°© í–‰ë ¬ë¡œ êµ¬í˜„ë˜ì–´ ìˆê³ , ì›ë³¸ ì´ë¯¸ì§€ì— ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•˜ì—¬ ìˆœì°¨ì ìœ¼ë¡œ ìƒˆë¡œìš´ í”½ì…€ê°’ì„ ë§Œë“¤ë©´ì„œ ì ìš©í•œë‹¤.
-   ì‚¬ìš©ìê°€ ëª©ì ì— ë§ëŠ” íŠ¹ì • í•„í„°ë¥¼ ë§Œë“¤ê±°ë‚˜ ê¸°ì¡´ì— ì„¤ê³„ëœ ë‹¤ì–‘í•œ í•„í„°ë¥¼ ì„ íƒí•˜ì—¬ ì´ë¯¸ì§€ì— ì ìš©í•œë‹¤.  
    í•˜ì§€ë§Œ, CNNì€ ìµœì ì˜ í•„í„°ê°’ì„ í•™ìŠµí•˜ì—¬ ìŠ¤ìŠ¤ë¡œ ìµœì í™” í•œë‹¤.

#### Kernel

-   filter ì•ˆì— 1 ~ nê°œì˜ ì»¤ë„ì´ ì¡´ì¬í•œë‹¤. ì»¤ë„ì˜ ê°œìˆ˜ëŠ” ë°˜ë“œì‹œ ì´ë¯¸ì§€ì˜ ì±„ë„ ìˆ˜ì™€ ë™ì¼í•´ì•¼ í•œë‹¤.
-   kernel SizeëŠ” ê°€ë¡œ X ì„¸ë¡œë¥¼ ì˜ë¯¸í•˜ë©°, ê°€ë¡œì™€ ì„¸ë¡œëŠ” ì„œë¡œ ë‹¤ë¥¼ ìˆ˜ ìˆì§€ë§Œ ë³´í†µì€ ì¼ì¹˜ì‹œí‚¨ë‹¤.
-   kernel Sizeê°€ í¬ë©´ í´ ìˆ˜ë¡ ì…ë ¥ ì´ë¯¸ì§€ì—ì„œ ë” ë§ì€ feature ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ìˆì§€ë§Œ, í° ì‚¬ì´ì¦ˆì˜ kernelë¡œ Convolution Backboneì„ í•  ê²½ìš° í›¨ì”¬ ë” ë§ì€ ì—°ì‚°ëŸ‰ê³¼ íŒŒë¼ë¯¸í„°ê°€ í•„ìš”í•˜ë‹¤.

\*\* ì»¤ë„, ì±„ë„, í•„í„°

#### Stride

-   ì…ë ¥ ì´ë¯¸ì§€ì— Convolution Filterë¥¼ ì ìš©í•  ë•Œ Slide Windowê°€ ì´ë™í•˜ëŠ” ê°„ê²©ì„ ì˜ë¯¸í•œë‹¤.
-   ê¸°ë³¸ strideëŠ” 1ì´ì§€ë§Œ, 2ë¥¼ ì ìš©í•˜ë©´ ì…ë ¥ feature map ëŒ€ë¹„ ì¶œë ¥ feature mapì˜ í¬ê¸°ê°€ ì ˆë°˜ì •ë„ ì¤„ì–´ë“ ë‹¤.
-   strideë¥¼ í‚¤ìš°ë©´ feature ì •ë³´ë¥¼ ì†ì‹¤í•  ê°€ëŠ¥ì„±ì´ ë†’ì•„ì§€ì§€ë§Œ, ì˜¤íˆë ¤ ë¶ˆí•„ìš”í•œ íŠ¹ì„±ì„ ì œê±°í•˜ëŠ” íš¨ê³¼ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ìˆê³  Convolution ì—°ì‚° ì†ë„ë¥¼ í–¥ìƒ ì‹œí‚¨ë‹¤.

#### Padding

-   Filterë¥¼ ì ìš©í•˜ì—¬ Convolution ìˆ˜í–‰ ì‹œ ì¶œë ¥ feature mapì´ ì…ë ¥ feature map ëŒ€ë¹„ ê³„ì†í•´ì„œ ì‘ì•„ì§€ëŠ” ê²ƒì„ ë§‰ê¸° ìœ„í•´ ì‚¬ìš©í•œë‹¤.
-   Filter ì ìš© ì „, ì…ë ¥ feature mapì˜ ìƒí•˜ì¢Œìš° ëì— ê°ê° ì—´ê³¼ í–‰ì„ ì¶”ê°€í•œ ë’¤, 0ìœ¼ë¡œ ì±„ì›Œì„œ í¬ê¸°ë¥¼ ì¦ê°€ì‹œí‚¨ë‹¤.
-   ì¶œë ¥ ì´ë¯¸ì§€ì˜ í¬ê¸°ë¥¼ ì…ë ¥ ì´ë¯¸ì§€ì˜ í¬ê¸°ì™€ ë™ì¼í•˜ê²Œ ìœ ì§€í•˜ê¸° ìœ„í•´ì„œ ì§ì ‘ ê³„ì‚°í•  í•„ìš” ì—†ì´ "same"ì´ë¼ëŠ” ê°’ì„ í†µí•´ ì…ë ¥ ì´ë¯¸ì§€ì˜ í¬ê¸°ì™€ ë™ì¼í•˜ê²Œ ë§ì¶œ ìˆ˜ ìˆë‹¤.

#### Pooling

-   Convolutoinì´ ì ìš©ëœ feature mapì˜ ì¼ì • ì—­ì˜ë³„ë¡œ í•˜ë‚˜ì˜ ê°’ì„ ì¶”ì¶œí•˜ì—¬ feature mapì˜ ì‚¬ì´ì¦ˆë¥¼ ì¤„ì¸ë‹¤.
-   ë³´í†µì€ Convolution -> Relu activation -> Pooling ìˆœì„œë¡œ ì ìš©í•œë‹¤.
-   ë¹„ìŠ·í•œ featureë“¤ì´ ì„œë¡œ ë‹¤ë¥¸ ì´ë¯¸ì§€ì—ì„œ ìœ„ì¹˜ê°€ ë‹¬ë¼ì§€ë©´ì„œ ë‹¤ë¥´ê²Œ í•´ì„ë˜ëŠ” í˜„ìƒì„ ì¤‘í™”ì‹œí‚¬ ìˆ˜ ìˆê³ ,
    feature mapì˜ í¬ê¸°ê°€ ì¤„ì–´ë“¤ê¸° ë•Œë¬¸ì—, ì—°ì‚° ì„±ëŠ¥ì´ í–¥ìƒëœë‹¤.
-   Max Poolingê³¼ Average Poolingì´ ìˆìœ¼ë©°, Max Poolingì€ ì¤‘ìš”ë„ê°€ ê°€ì¥ ë†’ì€ featureë¥¼ ì¶”ì¶œí•˜ê³ , Average Poolingì€ ì „ì²´ë¥¼ ë²„ë¬´ë ¤ì„œ ì¶”ì¶œí•œë‹¤.

#### ğŸš© ì •ë¦¬

-   Strideë¥¼ ì¦ê°€ì‹œí‚¤ëŠ” ê²ƒê³¼ Poolingì„ ì ìš©í•˜ëŠ” ê²ƒì„ ì¶œë ¥ feature mapì˜ í¬ê¸°ë¥¼ ì¤„ì´ëŠ”ë° ì‚¬ìš©í•˜ëŠ” ê²ƒì´ë‹¤.
-   Convolution ì—°ì‚°ì„ ì§„í–‰í•˜ë©´ì„œ, feature mapì˜ í¬ê¸°ë¥¼ ì¤„ì´ë©´, ìœ„ì¹˜ ë³€í™”ì— ë”°ë¥¸ featureì˜ ì˜í–¥ë„ë„ ì¤„ì–´ë“¤ê¸° ë•Œë¬¸ì— ê³¼ì í•©ì„ ë°©ì§€í•  ìˆ˜ ìˆëŠ” ì¥ì ì´ ìˆë‹¤.
-   Poolingì˜ ê²½ìš° íŠ¹ì • ìœ„ì¹˜ì˜ feature ê°’ì´ ì†ì‹¤ë˜ëŠ” ì´ìŠˆ ë“±ìœ¼ë¡œ ì¸í•˜ì—¬ ìµœê·¼ Advanced CNNì—ì„œëŠ” ë§ì´ ì‚¬ìš©ë˜ì§€ ì•ŠëŠ”ë‹¤.
-   Classifierì—ì„œëŠ” Fully Connected Layerì˜ ì§€ë‚˜ì¹œ ì—°ê²°ë¡œ ì¸í•´ ë§ì€ íŒŒë¼ë¯¸í„°ê°€ ìƒì„±ë˜ë¯€ë¡œ ì˜¤íˆëŸ¬ ê³¼ì í•©ì´ ë°œìƒí•  ìˆ˜ ìˆë‹¤.

-   ìœ„ì˜ ìƒí™©ì„ ëŒ€ë¹„í•˜ê¸° ìœ„í•´ Dropoutì„ ì‚¬ìš©í•´ì„œ Layerê°„ ì—°ê²°ì„ ì¤„ì¼ ìˆ˜ ìˆìœ¼ë©° ê³¼ì í•©ì„ ë°©ì§€í•  ìˆ˜ ìˆë‹¤. (ë‰´ëŸ°ì„ ë¹„í™œì„±í™” ì‹œí‚¤ëŠ” ì‘ì—….)

#### <div id="cnn-code">CNN Code</div>

<details>
    <summary>1. Funtional API ë¥¼ ì´ìš©í•œ CNN model êµ¬ì„±.</summary>
        from tensorflow.keras.layers import Input, Conv2D, MaxPool2D, Dense, Flatten
        from tensorflow.keras.models import Model

        INPUT_SIZE = 28

        # ì…ë ¥ í…ì„œ ì •ì˜: 28x28 í¬ê¸°ì˜ gray ì´ë¯¸ì§€
        # ë”°ë¼ì„œ Input í•­ëª©ì— 3ì°¨ì›ìœ¼ë¡œ ì…ë ¥ ì´ë¯¸ì§€ì˜ ì±„ë„ ìˆ˜ë¥¼ ì…ë ¥í•œë‹¤
        (ë‹¨, 3ì°¨ì›ìœ¼ë¡œ ë‚˜ì—´ ë˜ì–´ìˆì„ ê²½ìš° ì±„ë„ ìˆ˜ ì´ì ê°œìˆ˜ë¥¼ ì˜ë¯¸í•œë‹¤.)
        input_tensor = Input(shape=(INPUT_SIZE, INPUT_SIZE, 1))

        ## parms ì´ ê°œìˆ˜
        ## input = 1
        ## kernel = 3 * 3 = 9
        ## filter = 16
        ## 9 * 16 + 16 = 160

        # Conv2DëŠ” 2ì°¨ì› í•©ì„±ê³±(Convolution) ë ˆì´ì–´ë¥¼ ì˜ë¯¸í•˜ë©° feature mapì„ ìƒì„±í•˜ê¸° ìœ„í•œ ë ˆì´ì–´

        x = Conv2D(filters = 16, kernel_size= 3, strides=1, padding='same',activation='relu')(input_tensor)

        ## input = 16
        ## kernel = 4 * 4 = 16
        ## filter = 32
        ## 16 * 16 * 32 + 32 = 8224

        x = Conv2D(filters = 32, kernel_size= 4, strides=1, padding='same',activation='relu')(x)

        # input = 32
        # kernel = 4 * 4 = 16
        # filter = 64
        # 32 * 16 * 64 + 64 = 32832

        x = Conv2D(filters = 64, kernel_size= 4, strides=1,activation='relu')(x)

        x = MaxPool2D(2)(x)

        # ì…ë ¥ì¸µ
        x = Flatten()(x)
        # íˆë“ ì¸µ
        x = Dense(50, activation='relu')(x)
        # íˆë“ ì¸µ
        x = Dense(20, activation='relu')(x)
        # ì¶œë ¥ì¸µ
        output = Dense(10, activation='softmax')(x)

        model = Model(inputs= input_tensor, outputs = output)
        model.summary()

</details>

<details>
    <summary>2. Dropout (ë‰´ëŸ° ë¹„í™œì„±í™” ë¹„ìœ¨).</summary>
        from tensorflow.keras.layers import Input, Conv2D, MaxPool2D, Dense, Flatten, Dropout
        from tensorflow.keras.models import Model

        INPUT_SIZE = 28

        input_tensor = Input(shape=(INPUT_SIZE, INPUT_SIZE, 1))


        x = Conv2D(filters = 16, kernel_size= 3, strides=1, padding='same',activation='relu')(input_tensor)
        x = Conv2D(filters = 32, kernel_size= 4, strides=1, padding='same',activation='relu')(x)
        x = Conv2D(filters = 64, kernel_size= 4, strides=1,activation='relu')(x)

        x = MaxPool2D(2)(x)

        x = Flatten()(x)
        # Dropout - ë¹„í™œì„±í™” í•  ë¹„ìœ¨ ì„ íƒ
        x = Dropout(rate=0.5)(x)
        x = Dense(50, activation='relu')(x)
        x = Dense(20, activation='relu')(x)
        output = Dense(10, activation='softmax')(x)

        model = Model(inputs= input_tensor, outputs = output)
        model.summary()

</details>

</div>
