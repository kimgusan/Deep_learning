# Deep Learning

-   ì¸ê³µ ì‹ ê²½ë§(Artivicial Neural Network)ì˜ ì¸µì„ ì—°ì†ì ìœ¼ë¡œ ê¹Šê²Œ ìŒ“ì•„ì˜¬ë ¤ ë°ì´í„°ë¥¼ í•™ìŠµí•˜ëŠ” ë°©ì‹ì„ ì˜ë¯¸í•œë‹¤.
-   ì¸ê°„ì´ í•™ìŠµí•˜ê³  ê¸°ì–µí•˜ëŠ” ë§¤ì»¤ë‹ˆì¦˜ì„ ëª¨ë°©í•œ ê¸°ê³„í•™ìŠµì´ë‹¤.
-   ì¸ê°„ì€ í•™ìŠµ ì‹œ, ë‡Œì— ìˆëŠ” ë‰´ëŸ°ì´ ìê·¹ì„ ë°›ì•„ë“¤ì—¬ì„œ ì¼ì • ìê·¹ ì´ìƒì´ ë˜ë©´, í™”í•™ë¬¼ì§ˆì„ í†µí•´ ë‹¤ë¥¸ ë‰´ëŸ°ê³¼ ì—°ê²°ë˜ë©° í•´ë‹¹ ë¶€ë¶„ì´ ë°œë‹¬í•œë‹¤.
-   ìê·¹ì´ ì•½í•˜ê±°ë‚˜ ê¸°ì¤€ì¹˜ë¥¼ ë„˜ì§€ ëª»í•˜ë©´, ë‰´ëŸ°ì€ ì—°ê²°ë˜ì§€ ì•ŠëŠ”ë‹¤.
-   ì…ë ¥í•œ ë°ì´í„°ê°€ í™œì„± í•¨ìˆ˜ì—ì„œ ì„ê³„ì ì„ ë„˜ê²Œ ë˜ë©´ ì¶œë ¥ëœë‹¤.
-   ì´ˆê¸° ì¸ê³µ ì‹ ê²½ë§(Perceptron)ì—ì„œ ê¹Šê²Œ ì¸µì„ ìŒ“ì•„ í•™ìŠµí•˜ëŠ” ë”¥ ëŸ¬ë‹ìœ¼ë¡œ ë°œì „í•œë‹¤.
-   ë”¥ ëŸ¬ë‹ì€ Input nodes layer, Hidden nodes layer, Output nodes layer, ì´ë ‡ê²Œ ì„¸ ê°€ì§€ ì¸µì´ ì¡´ì¬í•œë‹¤.

## ëª©ì°¨

1. [Perceptron](#perceptron)
2. [Tensorflow](#tensorflow)
3. [CNN](#cnn)

---

## Perceptron

<div id="Perceptron">

### SLP (Single Layer Perceptron), ë‹¨ì¸µ í¼ì…‰íŠ¸ë¡ , ë‹¨ì¼ í¼ì…‰íŠ¸ë¡ 

-   ê°€ì¥ ë‹¨ìˆœí•œ í˜•íƒœì˜ ì‹ ê²½ë§ìœ¼ë¡œì„œ, Hidden Layerê°€ ì—†ê³  Single Layerë¡œ êµ¬ì„±ë˜ì–´ ìˆë‹¤.
-   í¼ì…‰íŠ¸ë¡ ì˜ êµ¬ì¡°ëŠ” ì…ë ¥ featureì™€ ê°€ì¤‘ì¹˜, activation function, ì¶œë ¥ ê°’ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆë‹¤.
-   ì‹ ê²½ ì„¸í¬ì—ì„œ ì‹ í˜¸ë¥¼ ì „ë‹¬í•˜ëŠ” ì¶•ì‚­ëŒê¸°ì˜ ì—­í• ì„ í¼ì…‰íŠ¸ë¡ ì—ì„œëŠ” ê°€ì¤‘ì¹˜ê°€ ëŒ€ì‹ í•˜ê³ ,  
     ì…ë ¥ ê°’ê³¼ ê°€ì¤‘ì¹˜ ê°’ì€ ëª¨ë‘ ì¸ê³µ ë‰´ë ¨(í™œì„± í•¨ìˆ˜)ìœ¼ë¡œ ë„ì°©í•œë‹¤.
-   ê°€ì¤‘ì¹˜ì˜ ê°’ì´ í´ìˆ˜ë¡ í•´ë‹¹ ì…ë ¥ ê°’ì´ ì¤‘ìš”í•˜ë‹¤ëŠ” ëœ»ì´ê³ , ì¸ê³µ ë‰´ëŸ°(í™œì„± í•¨ìˆ˜)ì— ë„ì°©í•œ ê° ì…ë ¥ ê°’ê³¼ ê°€ì¤‘ì¹˜ ê°’ì„ ê³±í•œ ë’¤ ì „ì²´ í•©í•œ ê°’ì„ êµ¬í•œë‹¤.
-   ì¸ê³µ ë‰´ëŸ°(í™œì„± í•¨ìˆ˜)ì€ ë³´í†µ ì‹œê·¸ëª¨ì´ë“œ í•¨ìˆ˜ì™€ ê°™ì€ ê³„ë‹¨ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬,  
     í•©í•œ ê°’ì„ í™•ë¥ ë¡œ ë³€í™˜í•˜ê³  ì´ ë•Œ, ì„ê³„ì¹˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ 0 ë˜ëŠ” 1ì„ ì¶œë ¥í•œë‹¤.

-   ë¡œì§€ìŠ¤í‹± íšŒê·€ ëª¨ë¸ì´ ì¸ê³µ ì‹ ê²½ë§ì—ì„œëŠ” í•˜ë‚˜ì˜ ì¸ê³µ ë‰´ëŸ°ìœ¼ë¡œ ë³¼ ìˆ˜ ìˆë‹¤.
-   ê²°ê³¼ì ìœ¼ë¡œ í¼ì…‰íŠ¸ë¡ ì˜ íšŒê·€ ëª¨ë¸ê³¼ ë§ˆì°¬ê°€ì§€ë¡œ ì‹¤ì œ ê°’ê³¼ ì˜ˆì¸¡ ê°’ì˜ ì°¨ì´ê°€ ìµœì†Œê°€ ë˜ëŠ” ê°€ì¤‘ì¹˜ ê°’ì„ ì°¾ëŠ” ê³¼ì •ì´ í¼ì…‰íŠ¸ë¡ ì´ í•™ìŠµí•˜ëŠ” ê³¼ì •ì´ë‹¤.
-   ìµœì†Œ ê°€ì¤‘ì¹˜ ê°’ì„ ì„¤ì •í•œ ë’¤ ì…ë ¥ feature ê°’ìœ¼ë¡œ ì˜ˆì¸¡ ê°’ì„ ê³„ì‚°í•˜ê³ , ì‹¤ì œ ê°’ê³¼ì˜ ì°¨ì´ë¥¼ êµ¬í•œ ë’¤ ì´ë¥¼ ì¤„ì¼ ìˆ˜ ìˆë„ë¡ ê°€ì¤‘ì¹˜ ê°’ì„ ë³€ê²½í•œë‹¤.
-   í¼ì…‰íŠ¸ë¡ ì˜ í™œì •í™” ì •ë„ë¥¼ í¸í–¥(bias)ìœ¼ë¡œ ì¡°ì ˆí•  ìˆ˜ ìˆìœ¼ë©°, í¸í–¥ì„ í†µí•´ ì–´ëŠì •ë„ì˜ ìê·¹ì„ ë¯¸ë¦¬ ì£¼ê³  ì‹œì‘ í•  ìˆ˜ ìˆë‹¤.
-   ë‰´ëŸ°ì´ í™œì„±í™”ë˜ê¸° ìœ„í•´ í•„ìš”í•œ ìê·¹ì´ 1000ì´ë¼ê³  ê°€ì •í•˜ë©´, ì…ë ¥ ê°’ì„ 500ë§Œ ë°›ì•„ë„ í¸í–¥ì„ 2ë¡œ ì£¼ì–´ 1000ì„ ë§Œë“¤ ìˆ˜ ìˆë‹¤.

-   í¼ì…‰íŠ¸ë¡ ì˜ ì¶œë ¥ ê°’ê³¼ ì‹¤ì œ ê°’ì˜ ì°¨ì´ë¥¼ ì¤„ì—¬ë‚˜ê°€ëŠ” ë°©í–¥ì„±ìœ¼ë¡œ ê³„ì†í•´ì„œ ê°€ì¤‘ì¹˜ ê°’ì„ ë³€ê²½í•˜ë©°, ì´ ë•Œ ê²½ì‚¬í•˜ê°•ë²•ì„ ì‚¬ìš©í•œë‹¤.

#### SGD (Stochastiic Gradient Descent), í™•ë¥ ì  ê²½ì‚¬ í•˜ê°•ë²•

-   ê²½ì‚¬ í•˜ê°•ë²• ë°©ì‹ì€ ì „ì²´ í•™ìŠµ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê³„ì‚°í•œë‹¤. í•˜ì§€ë§Œ ì…ë ¥ ë°ì´í„°ê°€ í¬ê³  ë ˆì´ì–´ê°€ ë§ì„ ìˆ˜ë¡ ë§ì€ ìì›ì´ ì†Œëª¨ëœë‹¤.
-   ì¼ë°˜ì ìœ¼ë¡œ ë©”ëª¨ë¦¬ ë¶€ì¡±ìœ¼ë¡œ ì¸í•´ ì—°ì‚°ì´ ë¶ˆê°€ëŠ¥í•˜ê¸° ë•Œë¬¸ì—, ì´ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´ SGD ë°©ì‹ì´ ë„ì…ë˜ì—ˆë‹¤.
-   ì „ì²´ í•™ìŠµ ë°ì´í„° ì¤‘, ë‹¨ í•œ ê±´ë§Œ ì„ì˜ë¡œ ì„ íƒí•˜ì—¬ ê²½ì‚¬ í•˜ê°•ë²•ì„ ì‹¤ì‹œí•˜ëŠ” ë°©ì‹ì„ ì˜ë¯¸í•œë‹¤.
-   ë§ì€ ê±´ ìˆ˜ ì¤‘ì— í•œ ê±´ë§Œ ì‹¤ì‹œí•˜ê¸° ë•Œë¬¸ì—, ë¹ ë¥´ê²Œ ìµœì ì ì„ ì°¾ì„ ìˆ˜ ìˆì§€ë§Œ ë…¸ì´ì¦ˆê°€ ì‹¬í•˜ë‹¤.
-   ë¬´ì‘ìœ„ë¡œ ì¶”ì¶œëœ ìƒ˜í”Œ ë°ì´í„°ì— ëŒ€í•´ ê²½ì‚¬ í•˜ê°•ë²•ì„ ì‹¤ì‹œí•˜ê¸° ë•Œë¬¸ì— ì§„í­ì´ í¬ê³  ë¶ˆì•ˆì •í•´ ë³´ì¼ ìˆ˜ ìˆë‹¤.
-   ì¼ë°˜ì ìœ¼ë¡œ ì‚¬ìš©í•˜ì§€ ì•Šê³ , SGDë¥¼ ì–˜ê¸°í•  ë•Œì—ëŠ” ë³´í†µ ë¯¸ë‹ˆ ë°°ì¹˜ ê²½ì‚¬ í•˜ê°•ë²•ì„ ì˜ë¯¸í•œë‹¤.

-   ì „ì²´ í•™ìŠµ ë°ì´í„° ì¤‘, íŠ¹ì • í¬ê¸°(Batch í¬ê¸°)ë§Œí¼ ì„ì˜ë¡œ ì„ íƒí•´ì„œ ê²½ì‚¬ í•˜ê°•ë²•ì„ ì‹¤ì‹œí•œë‹¤. ì´ ë˜í•œ, í™•ë¥ ì  ê²½ì‚¬ í•˜ê°•ë²•

-   ì „ì²´ í•™ìŠµ ë°ì´í„°ê°€ 1000ê±´ì´ë¼ê³  í•˜ê³ , batch sizeë¥¼ 100ê±´ì´ë¼ ê°€ì •í•˜ë©´, ì „ì²´ ë°ì´í„°ë¥¼ batch sizeë§Œí¼ ë‚˜ëˆ ì„œ ê°€ì ¸ì˜¨ ë’¤ ì„ê³ , ê²½ì‚¬í•˜ê°•ë²•ì„ ê³„ì‚°í•œë‹¤.  
    ì´ ê²½ìš°, 10ë²ˆ ë°˜ë³µí•´ì•¼ 1000ê°œì˜ ë°ì´í„°ê°€ ëª¨ë‘ í•™ìŠµë˜ê³  ì´ë¥¼ epochë¼ê³  í•œë‹¤. ì¦‰, 10 epoch \* 100 batch ì´ë‹¤.

### (MLP) Multi Layer Perceptron, ë‹¤ì¸µ í¼ì…‰íŠ¸ë¡ , ë‹¤ì¤‘ í¼ì…‰íŠ¸ë¡ 

-   ë³´ë‹¤ ë³µì¡í•œ ë¬¸ì œì˜ í•´ê²°ì„ ìœ„í•´ì„œ ì…ë ¥ì¸µê³¼ ì¶œë ¥ì¸µ ì‚¬ì´ì— ì€ë‹‰ì¸µì´ í¬í•¨ë˜ì–´ ìˆë‹¤.
-   í¼ì…‰íŠ¸ë¡ ì„ ì—¬ëŸ¬ì¸µ ìŒ“ì€ ì¸ê³µ ì‹ ê²½ë§ìœ¼ë¡œì„œ, ê° ì¸µì—ëŠ” í™œì„±í•¨ìˆ˜ë¥¼ í†µí•´ ì…ë ¥ì„ ì²˜ë¦¬í•œë‹¤.
-   ì¸µì´ ê¹Šì–´ì§ˆ ìˆ˜ë¡ ì •í™•í•œ ë¶„ë¥˜ê°€ ê°€ëŠ¥í•´ì§€ì§€ë§Œ, ë„ˆë¬´ ê¹Šì–´ì§€ë©´ Overfittingì´ ë°œìƒí•œë‹¤.

#### ANN (Artificial Neural Network), ì¸ê³µ ì‹ ê²½ë§

-   ì€ë‹‰ì¸µì´ 1ê°œì¼ ê²½ìš° ì´ë¥¼ ì¸ê³µ ì‹ ê²½ë§ì´ë¼ê³  í•œë‹¤.

#### DNN (Deep Neural Network), ì‹¬ì¸µ ì‹ ê²½ë§

-   ì€ë‹‰ì¸µì´ 2ê°œ ì´ìƒì¼ ê²½ìš° ì´ë¥¼ ì‹¬ì¸µ ì‹ ê²½ë§ì´ë¼ê³  í•œë‹¤.

#### **Back-propagation, ì—­ì „íŒŒ**

-   ì‹¬ì¸µ ì‹ ê²½ë§ì—ì„œ ìµœì¢… ì¶œë ¥(ì˜ˆì¸¡)ì„ í•˜ê¸° ìœ„í•œ ì‹ì´ ìƒê¸°ì§€ë§Œ ì‹ì´ ë„ˆë¬´ ë³µì¡í•´ì§€ê¸° ë•Œë¬¸ì— í¸ë¯¸ë¶„ì„ ì§„í–‰í•˜ê¸°ì— í•œê³„ê°€ ìˆë‹¤.
-   ì¦‰, í¸ë¯¸ë¶„ì„ í†µí•´ ê°€ì¤‘ì¹˜ ê°’ì„ êµ¬í•˜ê³ , ê²½ì‚¬ í•˜ê°•ë²•ì„ í†µí•´ ê°€ì¤‘ì¹˜ ê°’ì„ ì—…ë°ì´íŠ¸ í•˜ë©°, ì†ì‹¤ í•¨ìˆ˜ì˜ ìµœì†Œê°’ì„ ì°¾ì•„ì•¼ í•˜ëŠ”ë°, ìˆœë°©í–¥ìœ¼ë¡œëŠ” ë³µì¡í•œ ë¯¸ë¶„ì‹ì„ ê³„ì‚°í•  ìˆ˜ê°€ ì—†ë‹¤.  
    ë”°ë¼ì„œ ë¯¸ë¶„ì˜ ì—°ì‡„ ë²•ì¹™(Chain Rule)ì„ ì‚¬ìš©í•˜ì—¬ ì—­ë°©í–¥ìœ¼ë¡œ í¸ë¯¸ë¶„ì„ ì§„í–‰í•œë‹¤.

### Activation Function, í™œì„±í™” í•¨ìˆ˜

-   ì¸ê³µ ì‹ ê²½ë§ì—ì„œ ì…ë ¥ ê°’ì— ê°€ì¤‘ì¹˜ë¥¼ ê³±í•œ ë’¤ í•©í•œ ê²°ê³¼ë¥¼ ì ìš©í•˜ëŠ” í•¨ìˆ˜ì´ë‹¤.

---

1. **ì‹œê·¸ëª¨ì´ë“œ í•¨ìˆ˜**
    - ì€ë‹‰ì¸µì´ ì•„ë‹Œ ìµœì¢… í™œì„±í™” í•¨ìˆ˜, ì¶œë ¥ì¸µì—ì„œ ì‚¬ìš©ëœë‹¤.
    - ì€ë‹‰ì¸µì—ì„œ ì‚¬ìš© ì‹œ, ì…ë ¥ ê°’ì´ ì–‘ì˜ ë°©í–¥ìœ¼ë¡œ í° ê°’ì¼ ê²½ìš° ì¶œë ¥ê°’ì˜ ë³€í™”ê°€ ì—†ìœ¼ë©°, ìŒì˜ ë°©í–¥ë„ ë§ˆì°¬ê°€ì§€ì´ë‹¤.  
      í‰ê· ì´ 0ì´ ì•„ë‹ˆê¸° ë•Œë¬¸ì— ì •ê·œ ë¶„í¬ í˜•íƒœê°€ ì•„ë‹ˆê³ , ì´ëŠ” ë°©í–¥ì— ë”°ë¼ ê¸°ìš¸ê¸°ê°€ ë‹¬ë ¤ì ¸ì„œ íƒìƒ‰ ê²½ë¡œê°€ ë¹„íš¨ìœ¨ì (ì§€ê·¸ì¬ê·¸)ì´ ëœë‹¤.
2. **ì†Œí”„íŠ¸ë§¥ìŠ¤ í•¨ìˆ˜**

    - ì€ë‹‰ì¸µì´ ì•„ë‹Œ ìµœì¢… í™œì„±í™” í•¨ìˆ˜(ì¶œë ¥ì¸µ)ì—ì„œ ì‚¬ìš©ëœë‹¤.
    - ì‹œê·¸ëª¨ì´ë“œì™€ ìœ ì‚¬í•˜ê²Œ 0 ~ 1 ì‚¬ì´ì˜ ê°’ì„ ì¶œë ¥í•˜ì§€ë§Œ, ì´ì§„ ë¶„ë¥˜ê°€ ì•„ë‹Œ **ë‹¤ì¤‘ ë¶„ë¥˜**ë¥¼ í†µí•´ ëª¨ë“  í™•ë¥ ê°’ì´ 1ì´ ë˜ë„ë¡ í•´ì¤€ë‹¤.
    - ì—¬ëŸ¬ ê°œì˜ íƒ€ê²Ÿ ë°ì´í„°ë¥¼ ë¶„ë¥˜í•˜ëŠ” ë‹¤ì¤‘ ë¶„ë¥˜ì˜ ìµœì¢… í™œì„±í™” í•¨ìˆ˜(ì¶œë ¥ì¸µ)ë¡œ ì‚¬ìš©ëœë‹¤.

3. íƒ„ì  íŠ¸ í•¨ìˆ˜

    - ì€ë‹‰ì¸µì´ ì•„ë‹Œ ìµœì¢… í™œì„±í™” í•¨ìˆ˜(ì¶œë ¥ì¸µ)ì—ì„œ ì‚¬ìš©ëœë‹¤.
    - ì€ë‹‰ì¸µì—ì„œ ì‚¬ìš© ì‹œ, ì‹œê·¸ëª¨ì´ë“œì™€ ë‹¬ë¦¬ -1 ~ 1 ì‚¬ì´ì˜ ê°’ì´ ì¶œë ¥í•´ì„œ í‰ê· ì´ 0ì´ ë  ìˆ˜ ìˆì§€ë§Œ,  
      ì—¬ì „íˆ ì…ë ¥ ê°’ì˜ ì–‘ì˜ ë°¥í–¥ìœ¼ë¡œ í° ê°’ì¼ ê²½ìš° ì¶œë ¥ê°’ì˜ ë³€í™”ê°€ ë¯¸ë¹„í•˜ê³  ìŒì˜ ë°©í–¥ë„ ë§ˆì°¬ê°€ì§€ ì´ë‹¤.

4. **ë ë£¨ í•¨ìˆ˜**
    - ëŒ€í‘œì ì¸ ì€ë‹‰ì¸µì˜ í™œì„± í•¨ìˆ˜ì´ë‹¤.
    - ì…ë ¥ ê°’ì´ 0ë³´ë‹¤ ì‘ìœ¼ë©´ ì¶œë ¥ì€ 0, 0ë³´ë‹¤ í¬ë©´ ì…ë ¥ê°’ì„ ì¶œë ¥í•˜ê²Œ ëœë‹¤.

### Optimizer, ìµœì í™”

-   ìµœì ì˜ ê²½ì‚¬ í•˜ê°•ë²•ì„ ì ìš©í•˜ê¸° ìœ„í•´ í•„ìš”í•˜ë©°, ìµœì†Œê°’ì„ ì°¾ì•„ê°€ëŠ” ë°©ë²•ë“¤ì„ ì˜ë¯¸í•œë‹¤.
-   lossë¥¼ ì¤„ì´ëŠ” ë°©í–¥ìœ¼ë¡œ ìµœì†Œ lossë¥¼ ë³´ë‹¤ ë¹ ë¥´ê³  ì•ˆì •ì ìœ¼ë¡œ ìˆ˜ë ´í•  ìˆ˜ ìˆì–´ì•¼ í•œë‹¤.

#### Momentum

-   ê°€ì¤‘ì¹˜ë¥¼ ê³„ì† ì—…ë°ì´íŠ¸í•  ë•Œë§ˆë‹¤ ì´ì „ì˜ ê°’ì„ ì¼ì • ìˆ˜ì¤€ ë°˜ì˜ì‹œí‚¤ë©´ì„œ ìƒˆë¡œìš´ ê°€ì¤‘ì¹˜ë¡œ ì—…ë°ì´íŠ¸í•œë‹¤.
-   ì§€ì—­ ìµœì†Œê°’ì—ì„œ ë²—ì–´ë‚˜ì§€ ëª»í•˜ëŠ” ë¬¸ì œë¥¼ í•´ê²°í•  ìˆ˜ ìˆìœ¼ë©°, ì§„í–‰í–ˆë˜ ë°©í–¥ë§Œí¼ ì¶”ê°€ì ìœ¼ë¡œ ë”í•˜ì—¬, ê´€ì„±ì²˜ëŸ¼ ë¹ ì ¸ë‚˜ì˜¬ ìˆ˜ ìˆê²Œ í•´ì¤€ë‹¤.

#### AdaGrad (Adaptive Gradient)

-   ê°€ì¤‘ì¹˜ ë³„ë¡œ ì„œë¡œ ë‹¤ë¥¸ í•™ìŠµë¥ ì„ ë™ì ìœ¼ë¡œ ì ìš©í•œë‹¤.
-   ì ê²Œ ë³€í™”ëœ ê°€ì¤‘ì¹˜ëŠ” ë³´ë‹¤ í° í•™ìŠµë¥ ì„ ì ìš©í•˜ê³ , ë§ì´ ë³€í™”ëœ ê°€ì¤‘ì¹˜ëŠ” ë³´ë‹¤ ì‘ì€ í•™ìŠµë¥ ì„ ì ìš©ì‹œí‚¨ë‹¤.
-   ì²˜ìŒì—ëŠ” í° ë³´í­ìœ¼ë¡œ ì´ë™í•˜ë‹¤ê°€ ìµœì†Œê°’ì— ê°€ê¹Œì›Œì§ˆ ìˆ˜ë¡ ì‘ì€ ë³´í­ìœ¼ë¡œ ì´ë™í•˜ê²Œ ëœë‹¤.
-   ê³¼ê±°ì˜ ëª¨ë“  ê¸°ìš¸ê¸°ë¥¼ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì— í•™ìŠµë¥ ì´ ê¸‰ê²©íˆ ê°ì†Œí•˜ì—¬, ë¶„ëª¨ê°€ ì»¤ì§ìœ¼ë¡œì¨ í•™ìŠµë¥ ì´ 0ì— ê°€ê¹Œì›Œì§€ëŠ” ë¬¸ì œê°€ ìˆë‹¤.

#### RMSProp (Root Mean Sqaure Propagation)

-   AdaGradì˜ ë‹¨ì ì„ ë³´ì™„í•œ ê¸°ë²•ìœ¼ë¡œì„œ, í•™ìŠµë¥ ì´ ì§€ë‚˜ì¹˜ê²Œ ì‘ì•„ì§€ëŠ” ê²ƒì„ ë§‰ê¸° ìœ„í•´ ì§€ìˆ˜ ê°€ì¤‘ í‰ê· ë²•(exponentially weighted average)ì„ í†µí•´ êµ¬í•œë‹¤.
-   ì§€ìˆ˜ ê°€ì¤‘ í‰ê· ë²•ì´ë€, ë°ì´í„°ì˜ ì´ë™ í‰ê· ì„ êµ¬í•  ë•Œ ì˜¤ë˜ëœ ë°ì´í„°ê°€ ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ì§€ìˆ˜ì ìœ¼ë¡œ ê°ì‡ í•˜ë„ë¡ í•˜ëŠ” ë°©ë²•ì´ë‹¤.
-   ì´ì „ì˜ ê¸°ìš¸ê¸°ë“¤ì„ ë˜‘ê°™ì´ ë”í•´ê°€ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ í›¨ì”¬ ì´ì „ì˜ ê¸°ìš¸ê¸°ëŠ” ì¡°ê¸ˆ ë°˜ì˜í•˜ê³  ìµœê·¼ì˜ ê¸°ìš¸ê¸°ë¥¼ ë§ì´ ë°˜ì˜í•œë‹¤.
-   featureë§ˆë‹¤ ì ì ˆí•œ í•™ìŠµë¥ ì„ ì ìš©í•˜ì—¬ íš¨ìœ¨ì ì¸ í•™ìŠµì„ ì§„í–‰í•  ìˆ˜ ìˆê³ , AdaGradë³´ë‹¤ í•™ìŠµì„ ì˜¤ë˜ í•  ìˆ˜ ìˆë‹¤.

#### Adam (Adaptive Moment Estimation)

-   Momentumê³¼ RMSProp ë‘ ê°€ì§€ ë°©ì‹ì„ ê²°í•©í•œ í˜•íƒœë¡œì„œ, ì§„í–‰í•˜ë˜ ì†ë„ì— ê´€ì„±ì„ ì£¼ê³ , ì§€ìˆ˜ ê°€ì¤‘ í‰ê· ë²•ì„ ì ìš©í•œ ì•Œê³ ë¦¬ì¦˜ì´ë‹¤.
-   ìµœì í™” ë°©ë²• ì¤‘ì—ì„œ ê°€ì¥ ë§ì´ ì‚¬ìš©ë˜ëŠ” ì•Œê³ ë¦¬ì¦˜ì´ë©°, ìˆ˜ì‹ì€ ì•„ë˜ì™€ ê°™ë‹¤.

</div>

## tensorflow

<div id="tensorflow">

### Tensorflow, í…ì„œí”Œë¡œìš°

-   êµ¬ê¸€ì´ ê°œë°œí•œ ì˜¤í”ˆì†ŒìŠ¤ ì†Œí”„íŠ¸ì›¨ì–´ ë¼ì´ë¸ŒëŸ¬ë¦¬ì´ë©°, ë¨¸ì‹ ëŸ¬ë‹ê³¼ ë”¥ëŸ¬ë‹ì„ ì‰½ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ë‹¤ì–‘í•œ ê¸°ëŠ¥ì„ ì œê³µí•œë‹¤.
-   ì£¼ë¡œ ì´ë¯¸ì§€ ì¸ì‹ì´ë‚˜ ë°˜ë³µ ì‹ ê²½ë§ êµ¬ì„±, ê¸°ê³„ ë²ˆì—­, í•„ê¸° ìˆ«ì íŒë³„ ë“±ì„ ìœ„í•œ ê°ì¢… ì‹ ê²½ë§ í•™ìŠµì— ì‚¬ìš©ëœë‹¤.
-   ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ ë§Œë“¤ ë•Œ, ê¸°ì´ˆë¶€í„° ì„¸ì„¸í•˜ê²Œ ì‘ì—…í•´ì•¼ í•˜ê¸° ë•Œë¬¸ì— ì§„ì…ì¥ë²½ì´ ë†’ë‹¤.

### Keras, ì¼€ë¼ìŠ¤

-   ì¼ë°˜ ì‚¬ìš© ì‚¬ë¡€ì— ìµœì í™”ë˜ê³  "ìµœì í™”, ê°„ë‹¨, ì¼ê´€, ë‹¨ìˆœí™”"ëœ ì¸í„°í˜ì´ìŠ¤ë¥¼ ì œê³µí•œë‹¤.
-   ì†ì‰½ê²Œ ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ ê°œë°œí•˜ê³  í™œìš©í•  ìˆ˜ ìˆë„ë¡ ì§ê´€ì ì¸ APIë¥¼ ì œê³µí•œë‹¤.
-   í…ì„œí”Œë¡œìš° 2ë²„ì „ ì´ìƒë¶€í„° ì¼€ë¼ìŠ¤ê°€ í¬í•¨ë˜ì—ˆê¸° ë•Œë¬¸ì— í…ì„œí”Œë¡œìš°ë¥¼ í†µí•´ ì¼€ë¼ìŠ¤ë¥¼ ì‚¬ìš©í•œë‹¤.
-   ê¸°ì¡´ Keras íŒ¨í‚¤ì§€ë³´ë‹¤ëŠ” ì´ì œ Tensorflowì— ë‚´ì¥ëœ Keras ì‚¬ìš©ì´ ë” ê¶Œì¥ëœë‹¤.

---

#### Sequential API

-   ê°„ë‹¨í•œ ëª¨ë¸ì„ êµ¬í˜„í•˜ê¸°ì— ì í•©í•˜ê³  ë‹¨ìˆœí•˜ê²Œ ì¸µì„ ìŒ“ëŠ” ë°©ì‹ìœ¼ë¡œ ì‰½ê³  ì‚¬ìš©í•˜ê¸°ê°€ ê°„ë‹¨í•˜ë‹¤.
-   ë‹¨ì¼ ì…ë ¥ ë° ì¶œë ¥ë§Œ ìˆìœ¼ë¯€ë¡œ ë ˆì´ì–´ë¥¼ ê³µìœ í•˜ê±°ë‚˜ ì—¬ëŸ¬ ì…ë ¥ ë˜ëŠ” ì¶œë ¥ì„ ê°€ì§ˆ ìˆ˜ ìˆëŠ” ëª¨ë¸ì„ ìƒì„±í•  ìˆ˜ ì—†ë‹¤.

#### Funcional API

-   Funtional APIëŠ” Sequential APIë¡œëŠ” êµ¬í˜„í•˜ê¸° ì–´ë ¤ìš´ ë³µì¡í•œ ëª¨ë¸ë“¤ì„ êµ¬í˜„í•  ìˆ˜ ìˆë‹¤.
-   ì—¬ëŸ¬ ê°œì˜ ì…ë ¥ ë° ì¶œë ¥ì„ ê°€ì§„ ëª¨ë¸ì„ êµ¬í˜„í•˜ê±°ë‚˜ ì¸µ ê°„ì˜ ì—°ê²° ë° ì—°ì‚°ì„ ìˆ˜í–‰í•˜ëŠ” ëª¨ë¸ êµ¬í˜„ ì‹œ ì‚¬ìš©í•œë‹¤.

---

### Grayscale, RGB

-   í‘ë°± ì´ë¯¸ì§€ì™€ ì»¬ëŸ¬ ì´ë¯¸ì§€ëŠ” ê° 2ì°¨ì›ê³¼ 3ì°¨ì›ìœ¼ë¡œ í‘œí˜„ë  ìˆ˜ ìˆë‹¤.
-   í‘ë°± ì´ë¯¸ì§€ëŠ” 0 ~ 255ë¥¼ ê°–ëŠ” 2ì°¨ì› ë°°ì—´(ë†’ì´ X ë„ˆë¹„)ì´ê³ ,  
    ì»¬ëŸ¬ ì´ë¯¸ì§€ëŠ” 0 ~ 255ë¥¼ ê°–ëŠ” R, G, B 2ì°¨ì› ë°°ì—´ 3ê°œë¥¼ ê°–ëŠ” 3ì°¨ì›(ë†’ì´ X ë„ˆë¹„ X ì±„ë„)ì´ë‹¤.

### Grayscale Image Matrix

-   ê²€ì€ìƒ‰ì— ê°€ê¹Œìš´ ìƒ‰ì€ 0ì— ê°€ê¹ê³  í°ìƒ‰ì— ê°€ê¹Œìš°ë©´ 255ì— ê°€ê¹ë‹¤.
-   ëª¨ë“  í”½ì…€ì´ featureì´ë‹¤.

---

### Callback API (í™œìš©ì„±ì´ ë†’ìŒ!)

-   ëª¨ë¸ì´ í•™ìŠµ ì¤‘ì— ì¶©ëŒì´ ë°œìƒí•˜ê±°ë‚˜ ë„¤íŠ¸ì›Œí¬ê°€ ëŠê¸°ë©´, ëª¨ë“  í›ˆë ¨ ì‹œê°„ì´ ë‚­ë¹„ë  ìˆ˜ ìˆê³ ,  
    ê³¼ì í•©ì„ ë°©ì§€í•˜ê¸° ìœ„í•´ í›ˆë ¨ì„ ì¤‘ê°„ì— ì¤‘ì§€í•´ì•¼ í•  ìˆ˜ë„ ìˆë‹¤.
-   ëª¨ë¸ì´ í•™ìŠµì„ ì‹œì‘í•˜ë©´ í•™ìŠµì´ ì™„ë£Œë  ë•Œê¹Œì§€ ì•„ë¬´ëŸ° ì œì–´ë¥¼ í•˜ì§€ ëª»í•˜ê²Œ ë˜ê³ ,  
    ì‹ ê²½ë§ í›ˆë ¨ì„ ì™„ë£Œí•˜ëŠ” ë°ì—ëŠ” ëª‡ ì‹œê°„ ë˜ëŠ” ë©°ì¹ ì´ ê±¸ë¦´ ìˆ˜ ìˆê¸° ë•Œë¬¸ì— ëª¨ë¸ì„ ëª¨ë‹ˆí„°ë§í•˜ê³  ì œì–´í•  ìˆ˜ ìˆëŠ” ê¸°ëŠ¥ì´ í•„ìš”í•˜ë‹¤.
-   í›ˆë ¨ ì‹œ(fit()) Callback APIë¥¼ ë“±ë¡ì‹œí‚¤ë©´ ë°˜ë³µ ë‚´ì—ì„œ íŠ¹ì • ì´ë²¤íŠ¸ ë°œìƒë§ˆë‹¤ ë“±ë¡ëœ callbackì´ í˜¸ì¶œë˜ì–´ ìˆ˜í–‰ëœë‹¤.

**1) ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=False, save_weight_only=False, mode='auto')**

-   íŠ¹ì • ì¡°ê±´ì— ë”°ë¼ì„œ ëª¨ë¸ ë˜ëŠ” ê°€ì¤‘ì¹˜ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•œë‹¤.
-   filepath: "weight.{epoch: 03d}-{val_loss:.4f}-{acc:.4f}.weights.hdf5" ì™€ ê°™ì´ ëª¨ë¸ì˜ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì €ì¥í•œë‹¤.
-   monitor: ëª¨ë‹ˆí„°ë§í•  ì„±ëŠ¥ ì§€í‘œë¥¼ ì‘ì„±í•œë‹¤.
-   save_best_only: ê°€ì¥ ì¢‹ì€ ì„±ëŠ¥ì„ ë‚˜íƒ€ë‚´ëŠ” ëª¨ë¸ì„ ì €ì¥í•  ì§€ì— ëŒ€í•œ ì—¬ë¶€
-   save_weights_only: weightsë§Œ ì €ì¥í•  ì§€ì— ëŒ€í•œ ì—¬ë¶€
-   mode: {auto, min, max} ì¤‘ í•œ ê°€ì§€ë¥¼ ì‘ì„±í•œë‹¤. monitorì˜ ì„±ëŠ¥ ì§€í‘œì— ë”°ë¼ ì¢‹ì€ ê²½ìš°ë¥¼ ì„ íƒí•œë‹¤.  
    \*monitorì˜ ì„±ëŠ¥ ì§€í‘œê°€ ê°ì†Œí•´ì•¼ ì¢‹ì€ ê²½ìš° min, ì¦ê°€í•´ì•¼ ì¢‹ì€ ê²½ìš° max, monitorì˜ ì´ë¦„ìœ¼ë¡œë¶€í„° ìë™ìœ¼ë¡œ ìœ ì¶”í•˜ê³  ì‹¶ë‹¤ë©´ autoë¥¼ ì‚¬ìš©í•œë‹¤.

**2) ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, verbose=0, mode='auto, min_lr=0')** (LR: Learning Rate)

-   íŠ¹ì • ë°˜ë³µë™ì•ˆ ì„±ëŠ¥ì´ ê°œì„ ë˜ì§€ ì•Šì„ ë•Œ, í•™ìŠµë¥ ì„ ë™ì ìœ¼ë¡œ ê°ì†Œì‹œí‚¨ë‹¤.
-   monitor: ëª¨ë‹ˆí„°ë§í•  ì„±ëŠ¥ ì§€í‘œë¥¼ ì‘ì„±í•œë‹¤.
-   factor: í•™ìŠµë¥ ì„ ê°ì†Œì‹œí‚¬ ë¹„ìœ¨, ìƒˆë¡œìš´ í•™ìŠµë¥  = ê¸°ì¡´ í•™ìŠµë¥  \* factor
-   patience: í•™ìŠµë¥ ì„ ì¤„ì´ê¸° ì „ì— monitorí•  ë°˜ë³µ íšŸìˆ˜
-   mode: {auto, min, max} ì¤‘ í•œ ê°€ì§€ë¥¼ ì‘ì„±í•œë‹¤. monitorì˜ ì„±ëŠ¥ ì§€í‘œì— ë”°ë¼ ì¢‹ì€ ê²½ìš°ë¥¼ ì„ íƒí•œë‹¤.  
    \*monitorì˜ ì„±ëŠ¥ ì§€í‘œê°€ ê°ì†Œí•´ì•¼ ì¢‹ì€ ê²½ìš° min, ì¦ê°€í•´ì•¼ ì¢‹ì€ ê²½ìš° max, monitorì˜ ì´ë¦„ìœ¼ë¡œë¶€í„° ìë™ìœ¼ë¡œ ìœ ì¶”í•˜ê³  ì‹¶ë‹¤ë©´ autoë¥¼ ì‚¬ìš©í•œë‹¤.

**3) EarlyStopping(monitor='val_loss'm patient=0, verbose=0, mode='auto')**

-   íŠ¹ì • ë°˜ë³µë™ì•ˆ ì„±ëŠ¥ì´ ê°œì„ ë˜ì§€ ì•Šì„ ë•Œ, í•™ìŠµì„ ì¡°ê¸°ì— ì¤‘ë‹¨í•œë‹¤.
-   monitor: ëª¨ë‹ˆí„°ë§í•  ì„±ëŠ¥ ì§€í‘œë¥¼ ì‘ì„±í•œë‹¤.
-   patience: Early Stoppingì„ ì ìš©í•˜ê¸° ì „ì— monitorí•  ë°˜ë³µ íšŸìˆ˜.
-   mode: {auto, min, max} ì¤‘ í•œ ê°€ì§€ë¥¼ ì‘ì„±í•œë‹¤. monitorì˜ ì„±ëŠ¥ ì§€í‘œì— ë”°ë¼ ì¢‹ì€ ê²½ìš°ë¥¼ ì„ íƒí•œë‹¤.  
    \*monitorì˜ ì„±ëŠ¥ ì§€í‘œê°€ ê°ì†Œí•´ì•¼ ì¢‹ì€ ê²½ìš° min, ì¦ê°€í•´ì•¼ ì¢‹ì€ ê²½ìš° max, monitorì˜ ì´ë¦„ìœ¼ë¡œë¶€í„° ìë™ìœ¼ë¡œ ìœ ì¶”í•˜ê³  ì‹¶ë‹¤ë©´ autoë¥¼ ì‚¬ìš©í•œë‹¤.

#### <div id="tensowflow-code">tensorflow Code</div>

<details>
    <summary> 1. kerasì—ì„œ ë¶ˆëŸ¬ì˜¨ ì´ë¯¸ì§€ì— ëŒ€í•˜ì—¬ ì´ë¯¸ì§€ í‘œê¸° í•¨ìˆ˜ ì½”ë“œ</summary>

        def show_images(images, targets, ncols=8):
        figure, axs = plt.subplots(figsize=(22, 6), nrows=1, ncols=ncols)
        for i in range(ncols):
            axs[i].imshow(images[i], cmap='gray')
            axs[i].set_title(class_names[targets[i]])

        show_images(train_images[:8], train_targets[:8])
        show_images(train_images[8:16], train_targets[8:16])

</details>

<details>
    <summary> 2. Sequential API Code</summary>

        from tensorflow.keras.layers import Dense, Flatten
        from tensorflow.keras.models import Sequential
        from tensorflow.keras.losses import CategoricalCrossentropy
        from tensorflow.keras.optimizers import Adam

        # shape
        INPUT_SIZE = 28

        model = Sequential([
            # ì…ë ¥ì¸µ
            Flatten(input_shape=(INPUT_SIZE, INPUT_SIZE)),
            # ì€ë‹‰ì¸µ
            Dense(64, activation='relu'),
            # ì€ë‹‰ì¸µ
            Dense(128, activation='relu'),
            # ì¶œë ¥ì¸µ (ë‹¤ì¤‘ ë¶„ë¥˜ ì´ê¸° ë•Œë¬¸ì— í™œì„± í•¨ìˆ˜ëŠ” softmax ì‚¬ìš©)
            Dense(10, activation='softmax')
        ])

        # # ê²½ì‚¬í•˜ê°•ë²• optimizer, ë° ìµœì í™”
        # ì†ì‹¤í•¨ìˆ˜ëŠ” ë‹¤ì¤‘ í•¨ìˆ˜ì´ê¸° ë•Œë¬¸ì— CategoricalCrossentropy ì‚¬ìš©
        model.compile(optimizer=Adam(0.001), loss=CategoricalCrossentropy(), metrics=['acc'])

</details>

<details>
    <summary>3. ê²€ì¦ë°ì´í„°ë¥¼ í¬í•¨í•œ ì •í™•ë„ ê·¸ë˜í”„ í‘œí˜„</summary>
        #ë¼ì´ë¸ŒëŸ¬ë¦¬ í˜¸ì¶œ
        import matplotlib.pyplot as plt

        plt.plot(history.history['acc'], label='train')
        plt.plot(history.history['val_acc'], label='validation')
        plt.legend()
        plt.show()

</details>

<details>
<summary>4. ê²€ì¦ ë°ì´í„° ì •í™•ë„ ë° ì†ì‹¤ í•¨ìˆ˜ í™•ì¸</summary>

    # ê²€ì¦ë°ì´í„°ë¥¼ í™•ì¸í•˜ê¸° ìœ„í•œ evaluate í•¨ìˆ˜ ì‚¬ìš©
    model.evaluate(test_images, test_oh_targets, batch_size=32)

</details>

<details>
    <summary> 5. Funtional API Code</summary>

        ### call ë§¤ì§ ë©”ì†Œë“œ
        # call í•¨ìˆ˜ (ë§¤ì§ ë©”ì†Œë“œ)
        class Test:
            def __call__(self,data):
                return data + 10

---

        # call í•¨ìˆ˜ ë•ë¶„ì— ìƒì„±ì ë’¤ì— ê°’ì„ ë„£ì–´ì¤˜ì„œ ì‚¬ìš©ì´ ê°€ëŠ¥í•˜ë‹¤.

        from tensorflow.keras.layers import Layer, Input, Dense, Flatten
        from tensorflow.keras.models import Model

        INPUT_SIZE = 28

        def create_model():
            input_tensor = Input((INPUT_SIZE,INPUT_SIZE))
            x = Flatten()(input_tensor)
            x = Dense(64, activation='relu')(x)
            x = Dense(128, activation='relu')(x)
            output = Dense(10, activation='softmax')(x)

            model = Model(inputs=input_tensor, outputs=output)
            return model


        model = create_model()
        model.summary()

</details>

<details>
    <summary>6. tensorflow ì „ì²˜ë¦¬ ê³¼ì • (arrayê°ì²´ ë³€í™˜, ì›-í•« ì¸ì½”ë”©, í›ˆë ¨/ê²€ì¦/í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„ë¦¬)</summary>

    from tensorflow.keras.utils import to_categorical
    from sklearn.model_selection import train_test_split
    import numpy as np

    (train_images, train_targets), (test_images, test_targets) = fashion_mnist.load_data()

    # array ê°ì²´ ë³€í™˜ ë° ì‹¤ìˆ˜ ë³€í™˜, ìƒ‰ìƒì„ í‘œí˜„í•˜ê¸° ìœ„í•´ 255.0 ìœ¼ë¡œ ë³€í™˜
    def get_preprocessed_data(images, targets):
        images = np.array(images / 255.0, dtype=np.float32)
        targets = np.array(targets, dtype=np.float32)

        return images, targets

    # íƒ€ê²Ÿ ë°ì´í„°ì— ëŒ€í•˜ì—¬ ì›-í•« ì¸ì½”ë”© ë©”ì†Œë“œ ìƒì„±
    def get_preprocessed_ohe(images, targets):
        images, targets = get_preprocessed_data(images, targets)
        oh_targets = to_categorical(targets)

        return images, oh_targets

    # í›ˆë ¨, ê²€ì¦, í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ë¶„ë¦¬í•˜ê¸° ìœ„í•œ ë©”ì†Œë“œ ìƒì„±
    def get_train_valid_test(train_images, train_targets, test_images, test_targets, validation_size=0.2, random_state=124):
        train_images, train_oh_targets = get_preprocessed_ohe(train_images, train_targets)
        test_images, test_oh_targets = get_preprocessed_ohe(test_images, test_targets)

        train_images, validation_images, train_oh_targets, validation_oh_targets = \
        train_test_split(train_images, train_oh_targets, stratify=train_oh_targets, test_size=validation_size, random_state=random_state)

        return (train_images, train_oh_targets), (validation_images, validation_oh_targets), (test_images, test_oh_targets)

---

    from tensorflow.keras.datasets import fashion_mnist

    (train_images, train_targets), (test_images, test_targets) = fashion_mnist.load_data()

    (train_images, train_oh_targets), (validation_images, validation_oh_targets), (test_images, test_oh_targets) = \
    get_train_valid_test(train_images, train_targets, test_images, test_targets)

    print(train_images.shape, train_oh_targets.shape)
    print(validation_images.shape, validation_oh_targets.shape)
    print(test_images.shape, test_oh_targets.shape)

</details>

<details>
    <summary>tip. model.predict (pred_prob), np.argmax</summary>

        # í›ˆë ¨ê³¼ ì •ë‹µì˜ ì°¨ì›ì„ ë§ì¶”ê¸° ìœ„í•´ ì°¨ì›ì„ ëŠ˜ë¦¬ëŠ” ì‘ì—…
        import numpy as np
        np.expand_dims(test_images[0], axis=0).shape

        # ì •ë‹µì´ ë‚˜ì˜¬ í™•ë¥ 
        pred_prob = model.predict(np.expand_dims(test_images[8500], axis=0))
        print(pred_prob)

        # ì •ë‹µì´ ë‚˜ì˜¬ í™•ë¥  ë° ì •ë‹´ì„ ì¶œë ¥
        pred_proba = model.predict(np.expand_dims(test_images[326], axis=0))
        print('softmax output:', pred_proba)

        # argmax() : ê°€ì¥ ë†’ì€ ê°’ì˜ ì¸ë±ìŠ¤ë¥¼ ì°¾ì•„ì„œ í‘œê¸°í•˜ëŠ” í•¨ìˆ˜
        pred = np.argmax(np.squeeze(pred_proba))
        print('predicted target value:', pred)

</details>

<details>
    <summary>7. Callback API(ModelCheckpoint, ReduceLROnPlateau, EarlyStopping)</summary>

        from tensorflow.keras.optimizers import Adam
        from tensorflow.keras.losses import CategoricalCrossentropy
        from tensorflow.keras.callbacks import ModelCheckpoint

        model = create_model()
        model.compile(optimizer=Adam(), loss=CategoricalCrossentropy(), metrics=['acc'])

        mcp_cb = ModelCheckpoint(
            filepath="./callback_files/weights.{epoch:03d}-{val_loss:.4f}-{acc:.4f}.weights.h5",
            monitor='val_loss',
            save_best_only=False,
            # Modelì´ ì•„ëŠ” weight ë¥¼ ì €ì¥í•  ë•Œ Trueì„¤ì •
            save_weights_only=True,
            mode='min'
        )

        rlr_cb = ReduceLROnPlateau(
            monitor='val_loss',
            factor=0.1,
            patience=2,
            mode='min'
        )

        ely_cb = EarlyStopping(
            monitor='val_loss',
            patience=3,
            mode='min'
        )

        history = model.fit(x=train_images, y=train_oh_targets, validation_data=(validation_images, validation_oh_targets), batch_size=64, epochs=20, callbacks=[mcp_cb, rlr_cb, ely_cb])

</details>

<details>
    <summary>8. callbackì„ ì´ìš©í•œ ê°€ì¤‘ì¹˜ íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°</summary>
        model.load_weights('./callback_files/')
        model.compile(optimizer=Adam(), loss=CategoricalCrossentropy(), metrics=['acc'])
</details>

</div>

<hr>

## CNN

<div id="cnn">

### CNN (Convolutional Neural Network), í•©ì„±ê³± ì‹ ê²½ë§

-   ì‹¤ì œ ì´ë¯¸ì§€ ë°ì´í„°ëŠ” ë¶„ë¥˜ ëŒ€ìƒì´ ì´ë¯¸ì§€ì—ì„œ ê³ ì •ëœ ìœ„ì¹˜ì— ìˆì§€ ì•Šì€ ê²½ìš°ê°€ ëŒ€ë¶€ë¶„ì´ë‹¤.
-   ì‹¤ì œ ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ ë¶„ë¥˜í•˜ê¸° ìœ„í•´ì„œëŠ”, ì´ë¯¸ì§€ì˜ ê° featureë“¤ì„ ê·¸ëŒ€ë¡œ í•™ìŠµí•˜ëŠ” ê²ƒì´ ì•„ë‹Œ, CNNìœ¼ë¡œ íŒ¨í„´ì„ ì¸ì‹í•œ ë’¤ í•™ìŠµí•´ì•¼ í•œë‹¤.

-   ì´ë¯¸ì§€ì˜ í¬ê¸°ê°€ ì»¤ì§ˆ ìˆ˜ë¡ êµ‰ì¥íˆ ë§ì€ Weightê°€ í•„ìš”í•˜ê¸° ë•Œë¬¸ì— ë¶„ë¥˜ê¸°ì— ë°”ë¡œ ë„£ì§€ ì•Šê³ , ì´ë¥¼ ì‚¬ì „ì— ì¶”ì¶œ ë° ì¶•ì†Œí•´ì•¼ í•œë‹¤.
-   CNNì€ ì¸ê°„ì˜ ì‹œì‹ ê²½ êµ¬ì¡°ë¥¼ ëª¨ë°©í•œ ê¸°ìˆ ë¡œì„œ, ì´ë¯¸ì§€ì˜ íŒ¨í„´ì„ ì°¾ì„ ë•Œ ì‚¬ìš©í•œë‹¤.
-   Feature Extractionì„ í†µí•´ ê° ë‹¨ê³„ë¥¼ ê±°ì¹˜ë©´ì„œ, í•¨ì¶•ëœ ì´ë¯¸ì§€ ì¡°ê°ìœ¼ë¡œ ë¶„ë¦¬ë˜ê³  ê° ì´ë¯¸ì§€ ì¡°ê°ì„ í†µí•´ ì´ë¯¸ì§€ì˜ íŒ¨í„´ì„ ì¸ì‹í•œë‹¤.

-   CNNì€ ë¶„ë¥˜í•˜ê¸°ì— ì í•©í•œ ìµœì ì˜ featureë¥¼ ì¶”ì¶œí•˜ê³ , ìµœì ì˜ featureë¥¼ ì¶”ì¶œí•˜ê¸° ìœ„í•œ ìµœì ì˜ Weightì™€ filterë¥¼ ê³„ì‚°í•œë‹¤.

#### Filter

-   ì¼ë°˜ì ìœ¼ë¡œ ì •ë°© í–‰ë ¬ë¡œ êµ¬í˜„ë˜ì–´ ìˆê³ , ì›ë³¸ ì´ë¯¸ì§€ì— ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•˜ì—¬ ìˆœì°¨ì ìœ¼ë¡œ ìƒˆë¡œìš´ í”½ì…€ê°’ì„ ë§Œë“¤ë©´ì„œ ì ìš©í•œë‹¤.
-   ì‚¬ìš©ìê°€ ëª©ì ì— ë§ëŠ” íŠ¹ì • í•„í„°ë¥¼ ë§Œë“¤ê±°ë‚˜ ê¸°ì¡´ì— ì„¤ê³„ëœ ë‹¤ì–‘í•œ í•„í„°ë¥¼ ì„ íƒí•˜ì—¬ ì´ë¯¸ì§€ì— ì ìš©í•œë‹¤.  
    í•˜ì§€ë§Œ, CNNì€ ìµœì ì˜ í•„í„°ê°’ì„ í•™ìŠµí•˜ì—¬ ìŠ¤ìŠ¤ë¡œ ìµœì í™” í•œë‹¤.

#### Kernel

-   filter ì•ˆì— 1 ~ nê°œì˜ ì»¤ë„ì´ ì¡´ì¬í•œë‹¤. ì»¤ë„ì˜ ê°œìˆ˜ëŠ” ë°˜ë“œì‹œ ì´ë¯¸ì§€ì˜ ì±„ë„ ìˆ˜ì™€ ë™ì¼í•´ì•¼ í•œë‹¤.
-   kernel SizeëŠ” ê°€ë¡œ X ì„¸ë¡œë¥¼ ì˜ë¯¸í•˜ë©°, ê°€ë¡œì™€ ì„¸ë¡œëŠ” ì„œë¡œ ë‹¤ë¥¼ ìˆ˜ ìˆì§€ë§Œ ë³´í†µì€ ì¼ì¹˜ì‹œí‚¨ë‹¤.
-   kernel Sizeê°€ í¬ë©´ í´ ìˆ˜ë¡ ì…ë ¥ ì´ë¯¸ì§€ì—ì„œ ë” ë§ì€ feature ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ìˆì§€ë§Œ, í° ì‚¬ì´ì¦ˆì˜ kernelë¡œ Convolution Backboneì„ í•  ê²½ìš° í›¨ì”¬ ë” ë§ì€ ì—°ì‚°ëŸ‰ê³¼ íŒŒë¼ë¯¸í„°ê°€ í•„ìš”í•˜ë‹¤.

\*\* ì»¤ë„, ì±„ë„, í•„í„°

#### Stride

-   ì…ë ¥ ì´ë¯¸ì§€ì— Convolution Filterë¥¼ ì ìš©í•  ë•Œ Slide Windowê°€ ì´ë™í•˜ëŠ” ê°„ê²©ì„ ì˜ë¯¸í•œë‹¤.
-   ê¸°ë³¸ strideëŠ” 1ì´ì§€ë§Œ, 2ë¥¼ ì ìš©í•˜ë©´ ì…ë ¥ feature map ëŒ€ë¹„ ì¶œë ¥ feature mapì˜ í¬ê¸°ê°€ ì ˆë°˜ì •ë„ ì¤„ì–´ë“ ë‹¤.
-   strideë¥¼ í‚¤ìš°ë©´ feature ì •ë³´ë¥¼ ì†ì‹¤í•  ê°€ëŠ¥ì„±ì´ ë†’ì•„ì§€ì§€ë§Œ, ì˜¤íˆë ¤ ë¶ˆí•„ìš”í•œ íŠ¹ì„±ì„ ì œê±°í•˜ëŠ” íš¨ê³¼ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ìˆê³  Convolution ì—°ì‚° ì†ë„ë¥¼ í–¥ìƒ ì‹œí‚¨ë‹¤.

#### Padding

-   Filterë¥¼ ì ìš©í•˜ì—¬ Convolution ìˆ˜í–‰ ì‹œ ì¶œë ¥ feature mapì´ ì…ë ¥ feature map ëŒ€ë¹„ ê³„ì†í•´ì„œ ì‘ì•„ì§€ëŠ” ê²ƒì„ ë§‰ê¸° ìœ„í•´ ì‚¬ìš©í•œë‹¤.
-   Filter ì ìš© ì „, ì…ë ¥ feature mapì˜ ìƒí•˜ì¢Œìš° ëì— ê°ê° ì—´ê³¼ í–‰ì„ ì¶”ê°€í•œ ë’¤, 0ìœ¼ë¡œ ì±„ì›Œì„œ í¬ê¸°ë¥¼ ì¦ê°€ì‹œí‚¨ë‹¤.
-   ì¶œë ¥ ì´ë¯¸ì§€ì˜ í¬ê¸°ë¥¼ ì…ë ¥ ì´ë¯¸ì§€ì˜ í¬ê¸°ì™€ ë™ì¼í•˜ê²Œ ìœ ì§€í•˜ê¸° ìœ„í•´ì„œ ì§ì ‘ ê³„ì‚°í•  í•„ìš” ì—†ì´ "same"ì´ë¼ëŠ” ê°’ì„ í†µí•´ ì…ë ¥ ì´ë¯¸ì§€ì˜ í¬ê¸°ì™€ ë™ì¼í•˜ê²Œ ë§ì¶œ ìˆ˜ ìˆë‹¤.

#### Pooling

-   Convolutoinì´ ì ìš©ëœ feature mapì˜ ì¼ì • ì—­ì˜ë³„ë¡œ í•˜ë‚˜ì˜ ê°’ì„ ì¶”ì¶œí•˜ì—¬ feature mapì˜ ì‚¬ì´ì¦ˆë¥¼ ì¤„ì¸ë‹¤.
-   ë³´í†µì€ Convolution -> Relu activation -> Pooling ìˆœì„œë¡œ ì ìš©í•œë‹¤.
-   ë¹„ìŠ·í•œ featureë“¤ì´ ì„œë¡œ ë‹¤ë¥¸ ì´ë¯¸ì§€ì—ì„œ ìœ„ì¹˜ê°€ ë‹¬ë¼ì§€ë©´ì„œ ë‹¤ë¥´ê²Œ í•´ì„ë˜ëŠ” í˜„ìƒì„ ì¤‘í™”ì‹œí‚¬ ìˆ˜ ìˆê³ ,
    feature mapì˜ í¬ê¸°ê°€ ì¤„ì–´ë“¤ê¸° ë•Œë¬¸ì—, ì—°ì‚° ì„±ëŠ¥ì´ í–¥ìƒëœë‹¤.
-   Max Poolingê³¼ Average Poolingì´ ìˆìœ¼ë©°, Max Poolingì€ ì¤‘ìš”ë„ê°€ ê°€ì¥ ë†’ì€ featureë¥¼ ì¶”ì¶œí•˜ê³ , Average Poolingì€ ì „ì²´ë¥¼ ë²„ë¬´ë ¤ì„œ ì¶”ì¶œí•œë‹¤.

#### ğŸš© ì •ë¦¬

-   Strideë¥¼ ì¦ê°€ì‹œí‚¤ëŠ” ê²ƒê³¼ Poolingì„ ì ìš©í•˜ëŠ” ê²ƒì„ ì¶œë ¥ feature mapì˜ í¬ê¸°ë¥¼ ì¤„ì´ëŠ”ë° ì‚¬ìš©í•˜ëŠ” ê²ƒì´ë‹¤.
-   Convolution ì—°ì‚°ì„ ì§„í–‰í•˜ë©´ì„œ, feature mapì˜ í¬ê¸°ë¥¼ ì¤„ì´ë©´, ìœ„ì¹˜ ë³€í™”ì— ë”°ë¥¸ featureì˜ ì˜í–¥ë„ë„ ì¤„ì–´ë“¤ê¸° ë•Œë¬¸ì— ê³¼ì í•©ì„ ë°©ì§€í•  ìˆ˜ ìˆëŠ” ì¥ì ì´ ìˆë‹¤.
-   Poolingì˜ ê²½ìš° íŠ¹ì • ìœ„ì¹˜ì˜ feature ê°’ì´ ì†ì‹¤ë˜ëŠ” ì´ìŠˆ ë“±ìœ¼ë¡œ ì¸í•˜ì—¬ ìµœê·¼ Advanced CNNì—ì„œëŠ” ë§ì´ ì‚¬ìš©ë˜ì§€ ì•ŠëŠ”ë‹¤.
-   Classifierì—ì„œëŠ” Fully Connected Layerì˜ ì§€ë‚˜ì¹œ ì—°ê²°ë¡œ ì¸í•´ ë§ì€ íŒŒë¼ë¯¸í„°ê°€ ìƒì„±ë˜ë¯€ë¡œ ì˜¤íˆëŸ¬ ê³¼ì í•©ì´ ë°œìƒí•  ìˆ˜ ìˆë‹¤.

-   ìœ„ì˜ ìƒí™©ì„ ëŒ€ë¹„í•˜ê¸° ìœ„í•´ Dropoutì„ ì‚¬ìš©í•´ì„œ Layerê°„ ì—°ê²°ì„ ì¤„ì¼ ìˆ˜ ìˆìœ¼ë©° ê³¼ì í•©ì„ ë°©ì§€í•  ìˆ˜ ìˆë‹¤. (ë‰´ëŸ°ì„ ë¹„í™œì„±í™” ì‹œí‚¤ëŠ” ì‘ì—….)

---

### CNN (RGB)

-   RGB ì˜ìƒì´ê¸° ë•Œë¬¸ì— í•„í„°ì˜ ê²½ìš° '3'ì´ ì ìš©ëœë‹¤.
-   input data ì™€ì˜ ì°¨ì›ì„ ë§ì¶”ê¸° ìœ„í•´ Squeeze ë¥¼ ì‚¬ìš©í•œë‹¤ (<-> Unsqueeze)

---

### CNN Performance

-   CNN ëª¨ë¸ì„ ì œì‘í•  ë•Œ, ë‹¤ì–‘í•œ ê¸°ë²•ì„ í†µí•´ ì„±ëŠ¥ ê°œì„  ë° ê³¼ì í•© ê³„ì‚°ì´ ê°€ëŠ¥í•˜ë‹¤.

#### Weight Initialization, ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”

-   ì²˜ìŒ ê°€ì¤‘ì¹˜ë¥¼ ì–´ë–»ê²Œ ì¤„ ê²ƒì¸ì§€ë¥¼ ì •í•˜ëŠ” ë°©ë²•ì´ë©°, ì²˜ìŒ ê°€ì¤‘ì¹˜ë¥¼ ì–´ë–»ê²Œ ì„¤ì •í•˜ëŠëƒì— ë”°ë¼ ëª¨ë¸ì˜ ì„±ëŠ¥ì´ í¬ê²Œ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆë‹¤.

> 1. ì‚¬ë¹„ì—ë¥´ ê¸€ë¡œë¡œíŠ¸ ì´ˆê¸°í™”
>
> -   ê³ ì •ëœ í‘œì¤€í¸ì°¨ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šê³ , ì´ì „ ì¸µì˜ ë…¸ë“œ ìˆ˜ì— ë§ê²Œ í˜„ì¬ ì¸µì˜ ê°€ì¤‘ì¹˜ë¥¼ ì´ˆê¸°í™”í•œë‹¤.
> -   ì¸µë§ˆë‹¤ ë…¸ë“œ ê°œìˆ˜ë¥¼ ë‹¤ë¥´ê²Œ ì„¤ì •í•˜ë”ë¼ë„ ì´ì— ë§ê²Œ ê°€ì¤‘ì¹˜ê°€ ì´ˆê¸°í™”ë˜ê¸° ë•Œë¬¸ì— ê³ ì •ëœ í‘œì¤€í¸ì°¨ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒë³´ë‹¤ ì´ìƒì¹˜ì— ë¯¼ê°í•˜ì§€ ì•Šë‹¤.
> -   í™œì„±í™” í•¨ìˆ˜ê°€ ReLUì¼ ë•Œ, ì¸µì´ ì§€ë‚  ìˆ˜ë¡ í™œì„±í™” ê°’ì´ ê³ ë¥´ì§€ ëª»í•˜ê²Œ ë˜ëŠ” ë¬¸ì œê°€ ìƒê²¨ì„œ, **ì¶œë ¥ì¸µì—ì„œë§Œ ì‚¬ìš©**í•œë‹¤.

> 2. ì¹´ì´ë° íˆ ì´ˆê¸°í™”
>
> -   ê³ ì •ëœ í‘œì¤€í¸ì°¨ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šê³ , ì´ì „ ì¸µì˜ ë…¸ë“œ ìˆ˜ì— ë§ê²Œ í˜„ì¬ ì¸µì˜ ê°€ì¤‘ì¹˜ë¥¼ ì´ˆê¸°í™”í•œë‹¤.
> -   ì¸µë§ˆë‹¤ ë…¸ë“œ ê°œìˆ˜ë¥¼ ë‹¤ë¥´ê²Œ ì„¤ì •í•˜ë”ë¼ë„ ì´ì— ë§ê²Œ ê°€ì¤‘ì¹˜ê°€ ì´ˆê¸°í™”ë˜ê¸° ë•Œë¬¸ì— ê³ ì •ëœ í‘œì¤€í¸ì°¨ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒë³´ë‹¤ ì´ìƒì¹˜ì— ë¯¼ê°í•˜ì§€ ì•Šë‹¤.
> -   í™œì„±í™” í•¨ìˆ˜ê°€ ReLUì¼ ë•Œ, ì¶”ì²œí•˜ëŠ” ì´ˆê¸°í™” ë°©ë²•ìœ¼ë¡œì„œ, ì¸µì´ ê¹Šì–´ì§€ë”ë¼ë„ ëª¨ë“  í™œì„±ê°’ì´ ê³ ë¥´ê²Œ ë¶„í¬ëœë‹¤.

#### Batch Normalization, ë°°ì¹˜ ì •ê·œí™”

-   ì…ë ¥ ë°ì´í„° ê°„ì— ê°’ì˜ ì°¨ì´ê°€ ë°œìƒí•˜ë©´, ê°€ì¤‘ì¹˜ì˜ ë¹„ì¤‘ë„ ë‹¬ë¼ì§€ê¸° ë•Œë¬¸ì— ì¸µì„ í†µê³¼í•  ìˆ˜ë¡ í¸ì°¨ê°€ ì‹¬í•´ì§„ë‹¤.  
    ì´ë¥¼ ë‚´ë¶€ ê³µë³€ëŸ‰ ì´ë™(Internel Convariant Shift)ì´ë¼ê³  í•œë‹¤.
-   ê°€ì¤‘ì¹˜ì˜ ê°’ì˜ ë¯¸ì¤‘ì´ ë‹¬ë¼ì§€ë©´, íŠ¹ì • ê°€ì¤‘ì¹˜ì— ì¤‘ì ì„ ë‘ë©´ì„œ ê²½ì‚¬ í•˜ê°•ë²•ì´ ì§„í–‰ë˜ê¸° ë•Œë¬¸ì—,  
    ëª¨ë“  ì…ë ¥ê°’ì„ í‘œì¤€ ì •ê·œí™”í•˜ì—¬ ìµœì ì˜ parameterë¥¼ ë³´ë‹¤ ë¹ ë¥´ê²Œ í•™ìŠµí•  ìˆ˜ ìˆë„ë¡ í•´ì•¼í•œë‹¤.
-   ê°€ì¤‘ì¹˜ë¥¼ ì´ˆê¸°í™”í•  ë•Œ ë¯¼ê°ë„ë¥¼ ê°ì†Œì‹œí‚¤ê³ , í•™ìŠµ ì†ë„ë¥¼ ì¦ê°€ì‹œí‚¤ë©°, ëª¨ë¸ì„ ì¼ë°˜í™”í•˜ê¸° ìœ„í•´ì„œ ì‚¬ìš©í•œë‹¤.

-   BNì€ activation function ì•ì— ì ìš©í•˜ë©´, weight ê°’ì€ í‰ê· ì´ 0, ë¶„ì‚°ì´ 1ì¸ ìƒíƒœë¡œ ì •ê·œë¶„í¬ê°€ ëœë‹¤.
-   ReLUê°€ activationìœ¼ë¡œ ì ìš©ë˜ë©´ ìŒìˆ˜ì— í•´ë‹¹í•˜ëŠ”(ì ˆë°˜ ì •ë„) ë¶€ë¶„ì´ 0ì´ ëœë‹¤.  
    ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ì„œ (ê°ë§ˆ)ì™€ (ë² íƒ€)ë¥¼ ì‚¬ìš©í•´ì„œ ìŒìˆ˜ë¶€ë¶„ì´ ëª¨ë‘ 0ì´ ë˜ëŠ” ê²ƒì„ ë§‰ì•„ì¤€ë‹¤.

#### Batch Size

-   batch sizeë¥¼ ì‘ê²Œ í•˜ë©´, ì ì ˆí•œ noiseê°€ ìƒê²¨ì„œ overfittingì„ ë°©ì§€í•˜ê²Œ ë˜ê³ , ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ê³„ê¸°ê°€ ë  ìˆ˜ ìˆì§€ë§Œ, ë„ˆë¬´ ì‘ì•„ì„œëŠ” ì•ˆëœë‹¤.
-   batch sizeë¥¼ ë„ˆë¬´ ì‘ê²Œ í•˜ëŠ” ê²½ìš°ì—ëŠ” batchë‹¹ sample ìˆ˜ê°€ ì‘ì•„ì ¸ì„œ í›ˆë ¨ ë°ì´í„°ë¥¼ í•™ìŠµí•˜ëŠ” ë°ì— ë¶€ì¡±í•  ìˆ˜ ìˆë‹¤.
-   ë”°ë¼ì„œ êµ‰ì¥íˆ í¬ê²Œ ì£¼ëŠ” ê²ƒ ë³´ë‹¤ëŠ” ì‘ê²Œ ì£¼ëŠ” ê²ƒì´ ì¢‹ìœ¼ë©°, ì´ë¥¼ ë„ˆë¬´ ì‘ê²Œ ì£¼ì–´ì„œëŠ” ì•ˆëœë‹¤.  
    **ë…¼ë¬¸ì— ë”°ë¥´ë©´ 8ë³´ë‹¤ í¬ê³  32ë³´ë‹¤ ì‘ê²Œ ì£¼ëŠ” ê²ƒì´ íš¨ê³¼ì ì´ë¼ê³  í•œë‹¤.**

#### Weight Regularization (ê°€ì¤‘ì¹˜ ê·œì œ), Weight Decay (ê°€ì¤‘ì¹˜ ê°ì†Œ)

-   loss functionì€ loss ê°’ì´ ì‘ì•„ì§€ëŠ” ë°©í–¥ìœ¼ë¡œ ë°©í–¥ìœ¼ë¡œ ê°€ì¤‘ì¹˜ë¥¼ updateí•œë‹¤.
-   í•˜ì§€ë§Œ, lossë¥¼ ì¤„ì´ëŠ” ë°ì—ë§Œ ì‹ ê²½ì“°ê²Œ ë˜ë©´, íŠ¹ì • ê°€ì¤‘ì¹˜ê°€ ë„ˆë¬´ ì»¤ì§€ë©´ì„œ ì˜¤íˆë ¤ ë‚˜ìœ ê²°ê³¼ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ìˆë‹¤.
-   ê¸°ì¡´ ê°€ì¤‘ì¹˜ì— íŠ¹ì • ì—°ì‚°ì„ ìˆ˜í–‰í•˜ì—¬ loss functionì˜ ì¶œë ¥ ê°’ê³¼ ë”í•´ì£¼ë©´ loss functionì˜ ê²°ê³¼ë¥¼ ì–´ëŠì •ë„ ì œì–´í•  ìˆ˜ ìˆê²Œ ëœë‹¤.
-   ë³´í†µ íŒŒë¼ë¯¸í„°ê°€ ë§ì€ Dense Layerì—ì„œ ë§ì´ ì‚¬ìš©ë˜ê³  ê°€ì¤‘ì¹˜ ê·œì œë³´ë‹¤ëŠ” loss functionì— ê·œì œë¥¼ ê±¸ì–´ ê°€ì¤‘ì¹˜ë¥¼ ê°ì†Œì‹œí‚¤ëŠ” ì›ë¦¬ì´ë‹¤.
-   kerenlregularizer íŒŒë¼ë¯¸í„°ì—ì„œ l1, l2ì„ ì„ íƒí•  ìˆ˜ ìˆë‹¤.

### ì‹¤ì œ ì˜ìƒ ë°ì´í„°ë¥¼ train, validation, test ë°ì´í„° ë¶„ë¦¬

-   ì•„ë˜ code 6 ì°¸ì¡°

---

### Data Augmentation, ë°ì´í„° ì¦ê°•

-   ì´ë¯¸ì§€ì˜ ì¢…ë¥˜ì™€ ê°œìˆ˜ê°€ ì ìœ¼ë©´, CNN ëª¨ë¸ì˜ ì„±ëŠ¥ì´ ë–¨ì–´ì§ˆ ìˆ˜ ë°–ì— ì—†ë‹¤. ë˜í•œ ëª‡ ì•ˆë˜ëŠ” ì´ë¯¸ì§€ë¡œ í›ˆë ¨ì‹œí‚¤ë©´ ê³¼ì í•©ì´ ë°œìƒí•œë‹¤.
-   CNN ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ë†’ì´ê³  ê³¼ì í•©ì„ ê°œì„ í•˜ê¸° ìœ„í•´ì„œëŠ” ì´ë¯¸ì§€ì˜ ì¢…ë¥˜ì™€ ê°œìˆ˜ê°€ ë§ì•„ì•¼ í•œë‹¤. ì¦‰, ë°ì´í„° ì–‘ì„ ëŠ˜ë ¤ì•¼ í•œë‹¤.
-   ì´ë¯¸ì§€ ë°ì´í„°ëŠ” í•™ìŠµ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ì—¬ ì–‘ì„ ëŠ˜ë¦¬ê¸° ì‰½ì§€ ì•Šê¸° ë•Œë¬¸ì—, ì›ë³¸ ì´ë¯¸ì§€ë¥¼ ë³€í˜• ì‹œì¼œì„œ ì–‘ì„ ëŠ˜ë¦´ ìˆ˜ ìˆë‹¤.
-   Data Augmentationì„ í†µí•´ ì›ë³¸ ì´ë¯¸ì§€ì— ë‹¤ì–‘í•œ ë³€í˜•ì„ ì£¼ì–´ì„œ í•™ìŠµ ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ ëŠ˜ë¦¬ëŠ” ê²ƒê³¼ ìœ ì‚¬í•œ íš¨ê³¼ë¥¼ ë³¼ ìˆ˜ ìˆë‹¤.
-   ì›ë³¸ í•™ìŠµ ì´ë¯¸ì§€ì˜ ê°œìˆ˜ë¥¼ ëŠ˜ë¦¬ëŠ” ê²ƒì´ ì•„ë‹Œ ë§¤ í•™ìŠµ ë§ˆë‹¤ ê°œë³„ ì›ë³¸ ì´ë¯¸ì§€ë¥¼ ë³€í˜•í•´ì„œ í•™ìŠµì„ ìˆ˜í–‰í•œë‹¤.

#### ê³µê°„ ë ˆë²¨ ë³€í˜•

-   ì¢Œìš° ë˜ëŠ” ìƒí•˜ ë°˜ì „, íŠ¹ì • ì˜ì—­ë§Œí¼ í™•ëŒ€, ì¶•ì†Œ íšŒì „ ë“±ìœ¼ë¡œ ë³€í˜•ì‹œí‚¨ë‹¤.

#### í”½ì…€ ë ˆë²¨ ë³€í˜•

-   ë°ê¸°, ëŒ€ë¹„, ì±„í„¸ ë³€ê²½ ë“±ë“±

#### ğŸš©ì •ë¦¬

##### ê¸°ë³¸ì ìœ¼ë¡œ ë§ì´ ì‚¬ìš©ë˜ëŠ” ë³€í™˜ì€ ì•„ë˜ì™€ ê°™ë‹¤. (í•„ìš”ì‹œ ì¶”ê°€ í•„ìš” í•­ëª©ì„ ì°¾ì•„ ì ìš© í•  ê²ƒ.)

-   Vertical
-   Horizontal
-   ShiftScaleRotation
-   RandomCrop, CenterCrop, RandomBrightnessContrast
-   ColorJitter
-   CLAHE, Blur, CoarseDropout

---

### â­ï¸ Pretrained_Model

-   ëª¨ë¸ì„ ì²˜ìŒë¶€í„° í•™ìŠµí•˜ë©´ ì˜¤ëœ ì‹œê°„ í•™ìŠµì„ í•´ì•¼í•œë‹¤. ì´ë¥¼ ìœ„í•´ ëŒ€ê·œëª¨ í•™ìŠµ ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ ì‚¬ì „ì— í›ˆë ¨ëœ ëª¨ë¸ì„ í™œìš©í•œë‹¤.
-   ëŒ€ê·œëª¨ ë°ì´í„° ì„¸íŠ¸ì—ì„œ í›ˆë ¨ë˜ê³  ì €ì¥ëœ ë„¤íŠ¸ì›Œí¬ë¡œì„œ, ì¼ë°˜ì ìœ¼ë¡œ ëŒ€ê·œëª¨ ì´ë¯¸ì§€ ë¶„ë¥˜ ì‘ì—…ì—ì„œ í›ˆë ¨ëœ ê²ƒì„ ëœ»í•œë‹¤.
-   ì…ë ¥ ì´ë¯¸ì§€ëŠ” ëŒ€ë¶€ë¶„ 244 \* 244 í¬ê¸°ì´ë©°, ëª¨ë¸ ë³„ë¡œ ì°¨ì´ê°€ ìˆë‹¤.
-   ìë™ì°¨ë‚˜ ê³ ì–‘ì´ ë“±ì„ í¬í•¨í•œ 1000ê°œì˜ í´ë˜ìŠ¤, ì´ 1400ë§Œê°œì˜ ì´ë¯¸ì§€ë¡œ êµ¬ì„±ëœ ImageNet ë°ì´í„° ì„¸íŠ¸ë¡œ ì‚¬ì „ í›ˆë ¨ë˜ì—ˆë‹¤.

> #### ImageNet Large Scale Recognition Challenge (ILSVRC)
>
> 2017ë…„ê¹Œì§€ ëŒ€íšŒê°€ ì£¼ìµœë˜ì—ˆìœ¼ë©°, ì´í›„ì—ë„ ì¢‹ì€ ëª¨ë¸ë“¤ì´ ë“±ì¥í–ˆê³ , ì•ìœ¼ë¡œë„ ê³„ì† ë“±ì¥í•  ê²ƒì´ë‹¤.  
> ë©”ì´ì € í”Œë ˆì´ì–´ë“¤(êµ¬ê¸€, ë§ˆì´í¬ë¡œì†Œí”„íŠ¸)ì´ ë§Œë“¤ì–´ë†“ì€ ëª¨ë¸ë“¤ë„ ë“±ì¥í–ˆë‹¤.

#### 1. VGGNet (ì˜¥ìŠ¤í¬ë“œ ëŒ€í•™ì˜ ì—°êµ¬íŒ€)

-   2014ë…„ ILSVRCì—ì„œ GoogleNetì´ 1ìœ„, VGGëŠ” 2ìœ„ë¥¼ ì°¨ì§€í–ˆë‹¤.
-   GoogleNetì˜ ì˜¤ë¥˜ìœ¨ì€ 6.7%, VGGì˜ ì˜¤ë¥˜ìœ¨ì€ 7.3%ì´ê³ , 0.6%ì°¨ì´ ë°–ì— ë‚˜ì§€ ì•Šì•˜ë‹¤.
-   ê°„ê²°í•˜ê³  ë‹¨ìˆœí•œ ì•„í‚¤í…ì³ì„ì—ë„ ë¶ˆêµ¬í•˜ê³  1ìœ„ì¸ GoogleNetê³¼ í° ì°¨ì´ ì—†ëŠ” ì„±ëŠ¥ì„ ë³´ì—¬ì„œ ì£¼ëª©ì„ ë°›ê²Œ ë˜ì—ˆë‹¤.
-   ë„¤íŠ¸ì›Œí¬ ê¹Šì´ì— ë”°ë¥¸ ëª¨ë¸ ì„±ëŠ¥ì˜ ì˜í–¥ì— ëŒ€í•œ ì—°êµ¬ì— ì§‘ì¤‘í•˜ì—¬ ë§Œë“¤ì–´ì§„ ë„¤íŠ¸ì›Œí¬ì´ë‹¤.
-   ì‹ ê²½ë§ì„ ê¹Šê²Œ ë§Œë“¤ ìˆ˜ë¡ ì„±ëŠ¥ì´ ì¢‹ì•„ì§ì„ í™•ì¸í•˜ì˜€ì§€ë§Œ, ì»¤ë„ ì‚¬ì´ì¦ˆê°€ í´ ìˆ˜ë¡ ì´ë¯¸ì§€ ì‚¬ì´ì¦ˆê°€ ê¸‰ê²©í•˜ê²Œ ì¶•ì†Œë˜ê¸° ë•Œë¬¸ì—, ë” ê¹Šì€ ì¸µì„ ë§Œë“¤ê¸° ì–´ë µê³  íŒŒë¼ë¯¸í„° ê°œìˆ˜ì™€ ì—°ì‚°ëŸ‰ë„ ë” ë§ì´ í•„ìš”í•˜ë‹¤ëŠ” ê²ƒì„ ì•Œì•˜ë‹¤.
-   **ë”°ë¼ì„œ kernel í¬ê¸°ë¥¼ 3x3ìœ¼ë¡œ ë‹¨ì¼í™”í–ˆìœ¼ë©°, Padding, Strides ê°’ì„ ì¡°ì •í•˜ì—¬ ë‹¨ìˆœí•œ ë„¤íŠ¸ì›Œí¬ë¡œ êµ¬ì„±ë˜ì—ˆë‹¤.**
-   2ê°œì˜ 3x3 ì»¤ë„ì€ 5x5 ì»¤ë„ê³¼ ë™ì¼í•œ í¬ê¸°ì˜ feature mapì„ ìƒì„±í•˜ê¸° ë•Œë¬¸ì— 3x3 ì»¤ë„ë¡œ ì—°ì‚°í•˜ë©´, ì¸µì„ ë” ë§Œë“¤ ìˆ˜ ìˆê²Œ ëœë‹¤.

#### 2. Inception Network (GoogleNet)

-   ì—¬ëŸ¬ ì‚¬ì´ì¦ˆì˜ ì»¤ë„ë“¤ì„ í•œêº¼ë²ˆì— ê²°í•©í•˜ëŠ” ë°©ì‹ì„ ì‚¬ìš©í•˜ë©°, ì´ë¥¼ ë¬¶ì–´ì„œ inception moduleì´ë¼ê³  í•œë‹¤.
-   ì—¬ëŸ¬ ê°œì˜ inception moduleì„ ì—°ì†ì ìœ¼ë¡œ ì´ì–´ì„œ êµ¬ì„±í•˜ê³  ì—¬ëŸ¬ ì‚¬ì´ì¦ˆì˜ í•„í„°ë“¤ì´ ì„œë¡œ ë‹¤ë¥¸ ê³µê°„ ê¸°ë°˜ìœ¼ë¡œ featureë“¤ì„ ì¶”ì¶œí•œë‹¤.
-   inception moduleì„ ê²°í•©í•˜ë©´ì„œ ë³´ë‹¤ í’ë¶€í•œ feature Extractor Layerë¥¼ êµ¬ì„±í•˜ê²Œ ëœë‹¤.
-   í•˜ì§€ë§Œ ì—¬ëŸ¬ ì‚¬ì´ì¦ˆì˜ ì»¤ë„ì„ ê²°í•©í•˜ê²Œ ë˜ë©´, Convolution ì—°ì‚°ì„ ìˆ˜í–‰í•  ë•Œ íŒŒë¼ë¯¸í„° ìˆ˜ê°€ ì¦ê°€ë˜ê³  ê³¼ì í•©ìœ¼ë¡œ ì´ì–´ì§„ë‹¤.
-   ì´ë¥¼ ê·¹ë³µí•˜ê³ ì ì—°ì‚°ì„ ìˆ˜í–‰í•˜ê¸° ì „ì— 1x1 Convolutionì„ ì ìš©í•´ì„œ íŒŒë¼ë¯¸í„° ìˆ˜ë¥¼ íšê¸°ì ìœ¼ë¡œ ê°ì†Œì‹œí‚¨ë‹¤. (1x1 ìœ¼ë¡œ ì„¤ì •í•˜ê³  ì±„ë„ ìˆ˜ë¥¼ ì¡°ì •í•  ìˆ˜ ìˆë‹¤.)
-   1x1 Convolutionì„ ì ìš©í•˜ë©´ ì…ë ¥ ë°ì´í„°ì˜ íŠ¹ì§•ì„ í•¨ì¶•ì ìœ¼ë¡œ í‘œí˜„í•˜ë©´ì„œ íŒŒë¼ë¯¸í„° ìˆ˜ë¥¼ ì¤„ì´ëŠ” ì°¨ì› ì¶•ì†Œ ì—­í• ì„ ìˆ˜í–‰í•˜ê²Œ ëœë‹¤.

##### 1X1 Convolution

-   í–‰ê³¼ ì—´ì˜ í¬ê¸° ë³€í™˜ ì—†ì´ Channelì˜ ìˆ˜ë¥¼ ì¡°ì ˆí•  ìˆ˜ ìˆê³ , weight ë° ë¹„ì„ í˜•ì„±ì„ ì¶”ê°€í•˜ëŠ” ì—­í• ì„ í•œë‹¤.
-   í–‰ê³¼ ì—´ì˜ ì‚¬ì´ì¦ˆë¥¼ ì¤„ì´ê³  ì‹¶ë‹¤ë©´, Poolingì„ ì‚¬ìš©í•˜ë©´ ë˜ê³ , ì±„ë„ ìˆ˜ë§Œ ì¤„ì´ê³  ì‹¶ë‹¤ë©´ 1X1 Convolutionì„ ì‚¬ìš©í•˜ë©´ ëœë‹¤.

#### 3. ResNet (ë§ˆì´í¬ë¡œì†Œí”„íŠ¸)

-   VGG ì´í›„ ë” ê¹Šì€ Networkì— ëŒ€í•œ ì—°êµ¬ê°€ ì¦ê°€í–ˆì§€ë§Œ, Network ê¹Šì´ê°€ ê¹Šì–´ì§ˆ ìˆ˜ë¡ ì˜¤íˆë ¤ accuracyê°€ ë–¨ì–´ì§€ëŠ” ë¬¸ì œê°€ ìˆì—ˆë‹¤.
-   ì¸µì´ ê¹Šì–´ì§ˆ ìˆ˜ë¡ ê³„ì†í•´ì„œ ê¸°ìš¸ê¸°ê°€ 0ì— ê°€ê¹Œì›Œì§€ëŠ” Gradient vanishingì´ ë°œìƒí•˜ê¸° ë•Œë¬¸ì´ë‹¤.

-   ì´ë¥¼ í•´ê²°í•˜ê³ ì ì¸µì„ ë§Œë“¤ë˜, Input ë°ì´í„°ì™€ ê²°ê³¼ê°€ ë™ì¼í•˜ê²Œ ë‚˜ì˜¬ ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ì¸µì„ ì—°êµ¬í•˜ê¸° ì‹œì‘í–ˆë‹¤.  
    í•¨ìˆ˜ë¡œ ë‚˜íƒ€ë‚´ë©´ H(x) = xì´ë‹¤.
-   í•˜ì§€ë§Œ í™œì„±í™” í•¨ìˆ˜ë¥¼ í†µê³¼í•œ ê°’ì„ ê¸°ì¡´ Input ë°ì´í„°ì™€ ë™ì¼í•˜ê²Œ ë§Œë“œëŠ” ê²ƒì€ êµ‰ì¥íˆ ë³µì¡í–ˆê¸° ë•Œë¬¸ì—  
    H(x) = F(x) + x ì¦‰, F(x)ë¥¼ 0ìœ¼ë¡œ ë§Œë“œëŠ” F(x)ì— í¬ì»¤ìŠ¤ë¥¼ í•˜ê²Œ ëœë‹¤.
-   inputì€ xì´ê³ , Modelì¸ F(x)ë¼ëŠ” ì¼ë ¨ì˜ ê³¼ì •ì„ ê±°ì¹˜ë©´ì„œ ìì‹ ì¸ xê°€ ë”í•´ì ¸ì„œ outputìœ¼ë¡œ F(x) + xê°€ ë‚˜ì˜¤ëŠ” êµ¬ì¡°ê°€ ëœë‹¤.

---

### Transfer Learning, ì „ì´ í•™ìŠµ

-   ì´ë¯¸ì§€ ë¶„ë¥˜ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ë°ì— ì‚¬ìš©í–ˆë˜ ëª¨ë¸ì„ ë‹¤ë¥¸ ë°ì´í„°ì„¸íŠ¸ í˜¹ì€ ë‹¤ë¥¸ ë¬¸ì œì— ì ìš©ì‹œì¼œ í•´ê²°í•˜ëŠ” ê²ƒì„ ì˜ë¯¸í•œë‹¤.
-   ì¦‰, ì‚¬ì „ì— í•™ìŠµëœ ëª¨ë¸ì„ ë‹¤ë¥¸ ì‘ì—…ì— ì´ìš©í•˜ëŠ” ê²ƒì„ ì˜ë¯¸í•œë‹¤.
-   Pretrained Modelì˜ Convolutional Base êµ¬ì¡°(Conv2D + Pooling)ë¥¼ ê·¸ëŒ€ë¡œ ë‘ê³  ë¶„ë¥˜ê¸°(FC)ë¥¼ ë¶™ì—¬ì„œ í•™ìŠµì‹œí‚¨ë‹¤.

-   ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ì˜ ìš©ë„ë¥¼ ë³€ê²½í•˜ê¸° ìœ„í•œ ì¸µë³„ ë¯¸ì„¸ ì¡°ì •(fine tuning)ì€ ë°ì´í„° ì„¸íŠ¸ì˜ í¬ê¸°ì™€ ìœ ì‚¬ì„±ì„ ê¸°ë°˜ìœ¼ë¡œ ê³ ë¯¼í•˜ì—¬ ì¡°ì •í•œë‹¤.
-   2018ë…„ FAIR(Facebook AI Research)ë…¼ë¬¸ì—ì„œ ì‹¤í—˜ì„ í†µí•´ 'ì „ì´í•™ìŠµì´ í•™ìŠµ ì†ë„ ë©´ì—ì„œ íš¨ê³¼ê°€ ìˆë‹¤'ë¼ëŠ” ê²ƒì„ ë°í˜€ëƒˆë‹¤.

---

### Scaling Preprocessing

-   0 ~ 1, -1 ~ 1, z-score ë³€í™˜ ì¤‘ì—ì„œ í•œ ê°œë¥¼ ì„ íƒí•˜ì—¬ ë²”ìœ„ë¥¼ ì¶•ì†Œí•˜ëŠ” ì‘ì—…ì„ ì˜ë¯¸í•œë‹¤. (x ì¶•ì„ í™•ì¸)
-   Pretrained Modelì€ ì£¼ë¡œ tf(tensorflow)ì™€ torch í”„ë ˆì„ì›Œí¬ ë°©ì‹ì„ ì‚¬ìš©í•œë‹¤.
-   tfëŠ” -1 ~ 1, torchëŠ” z-score ë³€í™˜í•˜ëŠ” ê²ƒì´ ê° í”„ë ˆì„ì›Œí¬ì˜ ì „í†µì´ë‹¤.

## <div id="Code Advanced">Code Advanced</div>

<details>
    <summary>1. Funtional API ë¥¼ ì´ìš©í•œ CNN model êµ¬ì„±.</summary>

        from tensorflow.keras.layers import Input, Conv2D, MaxPool2D, Dense, Flatten
        from tensorflow.keras.models import Model

        INPUT_SIZE = 28

        # ì…ë ¥ í…ì„œ ì •ì˜: 28x28 í¬ê¸°ì˜ gray ì´ë¯¸ì§€
        # ë”°ë¼ì„œ Input í•­ëª©ì— 3ì°¨ì›ìœ¼ë¡œ ì…ë ¥ ì´ë¯¸ì§€ì˜ ì±„ë„ ìˆ˜ë¥¼ ì…ë ¥í•œë‹¤
        (ë‹¨, 3ì°¨ì›ìœ¼ë¡œ ë‚˜ì—´ ë˜ì–´ìˆì„ ê²½ìš° ì±„ë„ ìˆ˜ ì´ì ê°œìˆ˜ë¥¼ ì˜ë¯¸í•œë‹¤.)
        input_tensor = Input(shape=(INPUT_SIZE, INPUT_SIZE, 1))

        ## parms ì´ ê°œìˆ˜
        ## input = 1
        ## kernel = 3 * 3 = 9
        ## filter = 16
        ## 9 * 16 + 16 = 160

        # Conv2DëŠ” 2ì°¨ì› í•©ì„±ê³±(Convolution) ë ˆì´ì–´ë¥¼ ì˜ë¯¸í•˜ë©° feature mapì„ ìƒì„±í•˜ê¸° ìœ„í•œ ë ˆì´ì–´

        x = Conv2D(filters = 16, kernel_size= 3, strides=1, padding='same',activation='relu')(input_tensor)

        ## input = 16
        ## kernel = 4 * 4 = 16
        ## filter = 32
        ## 16 * 16 * 32 + 32 = 8224

        x = Conv2D(filters = 32, kernel_size= 4, strides=1, padding='same',activation='relu')(x)

        # input = 32
        # kernel = 4 * 4 = 16
        # filter = 64
        # 32 * 16 * 64 + 64 = 32832

        x = Conv2D(filters = 64, kernel_size= 4, strides=1,activation='relu')(x)

        x = MaxPool2D(2)(x)

        # ì…ë ¥ì¸µ
        x = Flatten()(x)
        # íˆë“ ì¸µ
        x = Dense(50, activation='relu')(x)
        # íˆë“ ì¸µ
        x = Dense(20, activation='relu')(x)
        # ì¶œë ¥ì¸µ
        output = Dense(10, activation='softmax')(x)

        model = Model(inputs= input_tensor, outputs = output)
        model.summary()

</details>

<details>
    <summary>2. Dropout (ë‰´ëŸ° ë¹„í™œì„±í™” ë¹„ìœ¨).</summary>

        from tensorflow.keras.layers import Input, Conv2D, MaxPool2D, Dense, Flatten, Dropout
        from tensorflow.keras.models import Model

        INPUT_SIZE = 28

        input_tensor = Input(shape=(INPUT_SIZE, INPUT_SIZE, 1))


        x = Conv2D(filters = 16, kernel_size= 3, strides=1, padding='same',activation='relu')(input_tensor)
        x = Conv2D(filters = 32, kernel_size= 4, strides=1, padding='same',activation='relu')(x)
        x = Conv2D(filters = 64, kernel_size= 4, strides=1,activation='relu')(x)

        x = MaxPool2D(2)(x)

        x = Flatten()(x)

        # Dropout(rate=ë¹„í™œì„±í™” í•  ë¹„ìœ¨ ì„ íƒ)

        x = Dropout(rate=0.5)(x)
        x = Dense(50, activation='relu')(x)
        x = Dense(20, activation='relu')(x)
        output = Dense(10, activation='softmax')(x)

        model = Model(inputs= input_tensor, outputs = output)
        model.summary()

</details>

<details>
    <summary>Tip.validation_split</summary>

    # compile ì§„í–‰ ì‹œ ë³„ë„ë¡œ validation ë°ì´í„°ë¥¼ êµ¬ë¶„í•˜ì§€ ì•Šê³  validation_splitì„ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤.

    model.fit(x=train_iamges, y=train_target, batch_size=8, epochs=10,
    validation_split=0.2)

</details>

<details>
    <summary>3. RGB ì˜ìƒ CNN ëª¨ë¸ ìƒì„±</summary>

    from tensorflow.keras.models import Model
    from tensorflow.keras.layers import Dense, Flatten, Conv2D, Dropout, MaxPooling2D, Input, Activation
    from tensorflow.keras.callbacks import Callback

    INPUT_SIZE = 32

    # RGB ì˜ìƒì´ê¸° ë•Œë¬¸ì— ìµœì´ˆ 3ê°œì˜ í•„í„°ë¥¼ ë„£ëŠ”ë‹¤.
    input_tensor = Input(shape=(INPUT_SIZE, INPUT_SIZE, 3))

    # padding default == valid
    x = Conv2D(filters = 32, kernel_size=5, padding='valid', activation='relu')(input_tensor)
    x = Conv2D(filters = 32, kernel_size=3, padding='same', activation='relu')(x)
    x = MaxPooling2D(2)(x)

    x = Conv2D(filters = 64, kernel_size=3, padding='same', activation='relu')(x)
    x = Conv2D(filters = 64, kernel_size=3, padding='same')(x)
    # CNN performance ì˜ ë°°ì¹˜ ì •ê·œí™” ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ê¸° ìœ„í•´ í™œì„±í•¨ìˆ˜ë¥¼ ë”°ë¡œ ì ìš©í•œë‹¤.
    x = Activation('relu')(x)
    x = MaxPooling2D(2)(x)

    x = Conv2D(filters = 128, kernel_size=3, padding='same', activation='relu')(x)
    x = Conv2D(filters = 128, kernel_size=3, padding='same')(x)
    x = Activation('relu')(x)
    x = MaxPooling2D(2)(x)

    x = Flatten(name='classifier_A00_Flatten')(x)
    x = Dropout(name='classifierA_DropOut01', rate=0.5)(x)
    x = Dense(300, activation='relu', name='classifierAD01')(x)
    x = Dropout(name='classifierA_DropOut02', rate=0.5)(x)
    output = Dense(10, activation='softmax', name='output')(x)


    model = Model(inputs = input_tensor, outputs = output)
    model.summary()

</details>

<details>
    <summary>4. keras.losses SparseCategoricalCrossentropy(ì›-í•« ì¸ì½”ë”© í›„ ì†ì‹¤í•¨ìˆ˜ í™•ì¸)</summary>

    from tensorflow.keras.optimizers import Adam
    # from tensorflow.keras.losses import CategoricalCrossentropy
    # ë‚´ê°€ ì›-í•« ì¸ì½”ë”©ì„ í•˜ì§€ì•Šê³  í•¨ìˆ˜ ë‚´ë¶€ì ìœ¼ë¡œ ì›-í•« ì¸ì½”ë”©ì„ ì‹œì¼œì¤€ë‹¤.
    from tensorflow.keras.losses import SparseCategoricalCrossentropy

    model.compile(optimizer=Adam(), loss=SparseCategoricalCrossentropy(), metrics = ['acc'])

</details>

<details>
    <summary>5. CNN Performance ì ìš© ëª¨ë¸(kernel_initializer(ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”), BatchNormalization(ë°°ì¹˜ ì •ê·œí™”), GlobalAveragePooling2D), kernel_regularizer(ê°€ì¤‘ì¹˜ ê·œì œ)</summary>

    from tensorflow.keras.models import Model
    from tensorflow.keras.layers import Input, Flatten, Dense, Conv2D, MaxPooling2D, Activation, Dropout, GlobalAveragePooling2D, BatchNormalization
    from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping
    from tensorflow.keras.regularizers import l1, l2

    INPUT_SIZE = 32

    input_tensor = Input(shape=(INPUT_SIZE,INPUT_SIZE,3))

    # alphaë¥¼ í¬ê²Œ í•  ìˆ˜ë¡ Weightê°’ì„ ì‘ê²Œ ë§Œë“¤ì–´ì„œ ê³¼ì í•©ì„ ê°œì„ í•  ìˆ˜ ìˆê³ ,
    # alphaë¥¼ ì‘ê²Œ í•  ìˆ˜ë¡ Weightì˜ ê°’ì´ ì»¤ì§€ì§€ë§Œ, ì–´ëŠ ì •ë„ ìƒì‡„í•˜ë¯€ë¡œ ê³¼ì†Œì í•©ì„ ê°œì„ í•  ìˆ˜ ìˆë‹¤.
    # ê°€ì¤‘ì¹˜ ì´ˆê¸°í™” (ì¹´ì´ë° íˆ ì´ˆê¸°í™”(he_normal))

    **
    input ì´í›„ ìµœì´ˆ ì¸µì—ì„œëŠ” ë³„ë„ì˜ ê·œì œë¥¼ ì•ˆì£¼ëŠ” ê²ƒì„ ê¶Œì¥.
    x = Conv2D(filters=64, kernel_size=3, padding='same'(input_tensor)
    # ë°°ì¹˜ ì •ê·œí™”
    x = BatchNormalization()(x)
    x = Activation('relu')(x)

    x = Conv2D(filters=64, kernel_size=3, padding='same', kernel_regularizer=l2(1e-5), kernel_initializer='he_normal')(x)
    x = BatchNormalization()(x)
    x = Activation('relu')(x)
    x = MaxPooling2D(2)(x)

    x = Conv2D(filters=128, kernel_size=3, padding='same' kernel_initializer='he_normal')(x)
    x = BatchNormalization()(x)
    x = Activation('relu')(x)

    x = Conv2D(filters=128, kernel_size=3, padding='same', kernel_initializer='he_normal')(x)
    x = BatchNormalization()(x)
    x = Activation('relu')(x)
    x = MaxPooling2D(2)(x)

    x = Conv2D(filters=256, kernel_size=3, padding='same', kernel_initializer='he_normal')(x)
    x = BatchNormalization()(x)
    x = Activation('relu')(x)

    x = Conv2D(filters=256, kernel_size=3, padding='same', kernel_initializer='he_normal')(x)
    x = BatchNormalization()(x)
    x = Activation('relu')(x)
    x = MaxPooling2D(2)(x)

    x = GlobalAveragePooling2D()(x)
    x = Dropout(rate=0.5)(x)
    x = Dense(300, activation='relu', kernel_regularizer=l2(1e-5), kernel_initializer='he_normal')(x)
    # ê°€ì¤‘ì¹˜ ì´ˆê¸°í™” (ì‚¬ë¹„ì—ë¥´ ê¸€ë¡œë¡œíŠ¸ ì´ˆê¸°í™” (glorot_normal))
    x = Dropout(rate=0.5)(x)
    output = Dense(10, activation='softmax', kernel_initializer='glorot_normal')(x)

    model = Model(inputs= input_tensor, outputs = output)
    model.summary()

</details>

<details>
    <summary>6. â­ï¸ (ì‹¤ì œ ì´ë¯¸ì§€)ë™ë¬¼ ì´ë¯¸ì§€ ì˜ìƒ train, val, test êµ¬ë¶„(MAC, Window)</summary>

    # ì‚¬ì „ì— ì •ì˜ëœ ëª…ì¹­ì´ ìˆê¸° ë•Œë¬¸ì— í•´ë‹¹ íŒŒì¼ì„ ë¶ˆë¡œì˜¤ëŠ” ë©”ì†Œë“œ
    with open('../d_cnn/datasets/animals/translate.py') as f:
        content = f.readline().strip()
        # print(content)
        # ë¬¸ìì—´ ì•ˆì— ìˆëŠ” ë”•ì…”ë„ˆë¦¬ë¥¼ ì •ìƒì ìœ¼ë¡œ ê°€ì ¸ì˜¤ê¸° ìœ„í•œ ë©”ì†Œë“œ eval
        contents1 = eval(content[content.index("{"):content.index("}") + 1])

        # key, valueê°€ ë’¤ì§‘ì–´ì ¸ ìˆëŠ” ìƒíƒœì´ê¸° ë•Œë¬¸ì— ë”•ì…”ë„ˆë¦¬ì˜ itemsë¥¼ ê°€ì ¸ì™€ì„œ key:value ë°˜ì „
        contents2 = {v: k for k, v in contents1.items()}

    print(contents1, contents2, sep='\n\n')

---

    from glob import glob
    import os

    root = '../d_cnn/datasets/animals/original/'

    # glob í•¨ìˆ˜ì˜ ê²½ìš° íŒŒì¼ëª…ì„ ë¦¬ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜.
    # osì˜ root ê²½ë¡œì— ìˆëŠ” ëª¨ë“  íŒŒì¼ëª…ì„ ë¦¬ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•˜ì—¬ ë¦¬ìŠ¤íŠ¸ ì—°ê²°.
    directories = glob(os.path.join(root, '*'))
    print(directories)

    for directory in directories:
        # í”Œë«í¼ ë…ë¦½ì ìœ¼ë¡œ ë””ë ‰í† ë¦¬ ì´ë¦„ ì¶”ì¶œ
        # basname (ë¦¬ëˆ…ìŠ¤ì—ì„œ íŒŒì¼ëª…ì´ë‚˜ í™•ì¥ìë¥¼ ì¶”ì¶œí•˜ê¸° ìœ„í•œ ëª…ë ¹ì–´)
        old_name = os.path.basename(directory)

        # í•´ë‹¹ ì˜ˆì™¸ì²˜ë¦¬ëŠ” translate.py í•­ëª©ì— key, valueê°€ ì¤‘ë³µìœ¼ë¡œ ë˜ì–´ ìˆì–´ ì‘ì„±
        try:
            new_name = contents1[old_name]
        except KeyError:
            new_name = contents2.get(old_name, old_name)  # old_nameì´ contents2ì— ì—†ìœ¼ë©´ ê·¸ëŒ€ë¡œ ìœ ì§€
        new_directory = os.path.join(root, new_name)
        os.rename(directory, new_directory)

    +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
    <!-- window ì…ë‹ˆë‹¤ -->
    from glob import glob
    import os

    root = './datasets/animals/original/'

    directories = glob(os.path.join(root, '*'))

    for directory in directories:
    # ìœˆë„ìš°ì˜ ê²½ìš° íŒŒì¼ëª… ì•ì´ â‚© ë¡œ ì¡´ì¬í•˜ê¸° ë•Œë¬¸ì— \\ ë¥¼ í†µí•˜ì—¬ í•´ë‹¹ íŒŒì¼ëª…ì„ ê°€ì ¸ì™€ì•¼ í•©ë‹ˆë‹¤.
        try:
            os.rename(directory, os.path.join(root, contents1[directory[directory.rindex('\\') + 1:]]))
        except KeyError as e:
            os.rename(directory, os.path.join(root, contents2[directory[directory.rindex('\\') + 1:]]))

---

    root = '../d_cnn/datasets/animals/original/'

    # í•´ë‹¹ ê²½ë¡œì— ìˆëŠ” ì „ì²´ ê²½ë¡œë¥¼ ë³€ìˆ˜ì— ì €ì¥
    directories = glob(os.path.join(root, '*'))
    directory_names = []

    # ë°˜ë³µì„ ì´ìš©í•œ í•´ë‹¹ ë””ë ‰í† ë¦¬ì˜ íŒŒì¼ëª…ì„ ì¶”ì¶œí•˜ì—¬ ë¦¬ìŠ¤íŠ¸ì— ì €ì¥
    for directory in directories:
        directory_names.append(os.path.basename(directory))

    print(directory_names)

---

    root = '../d_cnn/datasets/animals/original/'

    for name in directory_names:
        for i, file_name in enumerate(os.listdir(os.path.join(root, name))):
            old_file = os.path.join(root + name + '/', file_name)
            new_file = os.path.join(root + name + '/', name + str(i + 1) + '.png')

            # ê¸°ì¡´ì— ìˆë˜ íŒŒì¼ëª…ì„ í•´ë‹¹ root ë””ë ‰í† ë¦¬ì˜ ì´ë¦„ìœ¼ë¡œ ë³€ê²½ í›„ ë’¤ì— ë°˜ë³µ ì‹œ ì¦ê°€ë˜ëŠ” ìˆ«ì ì…ë ¥
            os.rename(old_file, new_file)

---

    from tensorflow.keras.preprocessing.image import ImageDataGenerator

    # ImageDataGenerator ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±
    # ëª¨ë“  ì´ë¯¸ì§€ì˜ í”½ì…€ê°’ì„ 1/255 ë¡œ ë‚˜ëˆ„ì–´ 0ê³¼ 1ì‚¬ì´ì˜ ê°’ìœ¼ë¡œ ë³€í™˜ í›„ image_data_generator ìƒì„±
    image_data_generator = ImageDataGenerator(rescale=1./255)

    # flow_from_directory ë©”ì†Œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ë””ë ‰í† ë¦¬ì—ì„œ ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  ì „ì²˜ë¦¬í•©ë‹ˆë‹¤.
    # flow_from_directoryëŠ” ImageDataGeneratorì˜ ë©”ì†Œë“œë¡œ ë””ë ‰í† ë¦¬ êµ¬ì¡°ì—ì„œ ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³ 
    # ì‹¤ì‹œê°„ìœ¼ë¡œ ì¦ê°• ë° ì „ì²˜ë¦¬ í•˜ëŠ”ë° ì‚¬ìš©
    generator = image_data_generator.flow_from_directory(
        root,                 # ì´ë¯¸ì§€ê°€ ì €ì¥ëœ ë””ë ‰í† ë¦¬ì˜ ê²½ë¡œ
        target_size=(150, 150),  # ëª¨ë“  ì´ë¯¸ì§€ë¥¼ (150, 150) í¬ê¸°ë¡œ ì¡°ì •í•©ë‹ˆë‹¤.
        batch_size=32,           # ë°°ì¹˜ í¬ê¸°ë¥¼ 32ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.
        class_mode='categorical' # í´ë˜ìŠ¤ ëª¨ë“œë¥¼ 'categorical'ë¡œ ì„¤ì •í•˜ì—¬ ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    )

    # ìƒì„±ëœ í´ë˜ìŠ¤ ì¸ë±ìŠ¤ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.
    # ë””ë ‰í† ë¦¬ êµ¬ì¡°ì—ì„œ ë°œê²¬ëœ í´ë˜ìŠ¤ì˜ ì´ë¦„ê³¼ ì¸ë±ìŠ¤ë¥¼ ë§¤í•‘í•œ ë”•ì…”ë„ˆë¦¬ ë°˜í™˜
    print(generator.class_indices)

---

    import pandas as pd
    from sklearn.model_selection import train_test_split

    # flow_from_directoryë¥¼ ì´ìš©í•œ ë©”ì†Œë“œë¡œ í•´ë‹¹ íŒŒì¼ì„ ì§ì ‘ ë¡œë“œí•˜ì—¬ ê²½ë¡œì™€ categoryë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.
    a_df = pd.DataFrame({'file_paths': generator.filepaths, 'targets': generator.classes})
    a_df

---

    # train, validation, test ë°ì´í„° ë¶„ë¦¬
    X_train, X_test, y_train, y_test =\
    train_test_split(a_df.file_paths, a_df.targets, stratify=a_df.targets, test_size=0.2, random_state=124)

    print(y_train.value_counts())
    print(y_test.value_counts())

    X_train, X_val, y_train, y_val = \
    train_test_split(X_train, y_train, stratify=y_train, test_size=0.2, random_state=124)

    print(y_train.value_counts())
    print(y_val.value_counts())

---

    # ê¸°ì¡´ 1ê°œì˜ í´ë”ì— ìˆëŠ” ì´ë¯¸ì§€ë“¤ì„ train, validation, test ì˜ìƒìœ¼ë¡œ ë””ë ‰í† ë¦¬ ë‚˜ëˆ ì„œ copy
    import shutil

    root = '../d_cnn/datasets/animals/'

    for file_path in X_train:
        # animal_dirì„ ê²½ë¡œ êµ¬ë¶„ìë¡œ ë¶„í• í•˜ì—¬ ì¶”ì¶œ
        # íŒŒì¼ ê²½ë¡œì—ì„œ directory ë¥¼ ì¶”ì¶œí•˜ë ¤ë©´ dirname ëª…ë ¹ì–´ë¥¼ ì‚¬ìš©
        animal_dir = file_path[len(os.path.join(root, 'original')) + 1:file_path.rindex('/')]
        destination = os.path.join(root, 'train', animal_dir)

        # destination ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ ìƒì„±
        if not os.path.exists(destination):
            os.makedirs(destination)

        # íŒŒì¼ì„ destination ë””ë ‰í† ë¦¬ë¡œ ë³µì‚¬
        shutil.copy2(file_path, destination)

---

    import shutil

    root = '../d_cnn/datasets/animals/'

    for file_path in X_val:
        # animal_dirì„ ê²½ë¡œ êµ¬ë¶„ìë¡œ ë¶„í• í•˜ì—¬ ì¶”ì¶œ
        animal_dir = file_path[len(os.path.join(root, 'original')) + 1:file_path.rindex('/')]
        destination = os.path.join(root, 'validation', animal_dir)

        # destination ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ ìƒì„±
        if not os.path.exists(destination):
            os.makedirs(destination)

        # íŒŒì¼ì„ destination ë””ë ‰í† ë¦¬ë¡œ ë³µì‚¬
        shutil.copy2(file_path, destination)

---

    root = '../d_cnn/datasets/animals/'

    for file_path in X_test:
        # animal_dirì„ ê²½ë¡œ êµ¬ë¶„ìë¡œ ë¶„í• í•˜ì—¬ ì¶”ì¶œ
        animal_dir = file_path[len(os.path.join(root, 'original')) + 1:file_path.rindex('/')]
        destination = os.path.join(root, 'test', animal_dir)

        # destination ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ ìƒì„±
        if not os.path.exists(destination):
            os.makedirs(destination)

        # íŒŒì¼ì„ destination ë””ë ‰í† ë¦¬ë¡œ ë³µì‚¬
        shutil.copy2(file_path, destination)

</details>

<details>
    <summary>7. Data augmentation, ë°ì´í„° ì¦ê°• (ImageDataGenerator),albumentations ë¦¬ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©ë²• í¬í•¨.</summary>

    import numpy as np
    from tensorflow.keras.preprocessing.image import ImageDataGenerator

    # Horizontal Filp: ì¢Œìš°ë°˜ì „ ì ìš©
    # ì ìš©í•˜ë”ë¼ë„ ë°˜ë“œì‹œ ë³€í™˜ë˜ì§€ ì•ŠëŠ”ë‹¤. íŠ¹ì • í™•ë¥ ë¡œ ëœë¤í•˜ê²Œ ì ìš©í•˜ê¸° ë–„ë¬¸ì´ë‹¤.
    idg = ImageDataGenerator(horizontal_flip=True)

    # ì´ë¯¸ì§€ì˜ ì°¨ì›ì„ ë§ì¶”ê¸° ìœ„í•´ í•˜ë‚˜ ì¦ê°€ì‹œí‚¨ë‹¤. (4ì°¨ì›ì¼ ë–„ => (ë°°ì¹˜ì‚¬ì´ì¦ˆ, w, h, cì±„ë„))
    # ImageDataGeneratorëŠ” ë°°ì¹˜ ì‚¬ì´ì¦ˆë¥¼ í¬í•¨í•œ 4ì°¨ì›ìœ¼ë¡œ ì—°ì‚°ë˜ê¸° ë•Œë¬¸ì—
    # ê¸°ì¡´ imageë¥¼ í•œ ì°¨ì› ì¦ê°€ì‹œì¼œ ì¤€ë‹¤
    image_batch = np.expand_dims(image, axis=0)

    # 4ì°¨ì› ì´ë¯¸ì§€(ë°°ì¹˜ ì‚¬ì´ì¦ˆ í¬í•¨)ë¥¼ fitì— ì „ë‹¬í•œë‹¤.
    idg.fit(image_batch)
    # fití•œ ë’¤ flowì— ë‹¤ì‹œ ë„£ì–´ì¤€ë‹¤.
    data_generator = idg.flow(image_batch)
    # ì ìš©ëœ ì´ë¯¸ì§€ë¥¼ nextë¡œ ê°€ì ¸ì˜¨ë‹¤.
    aug_image_batch = next(data_generator)
    # ì´ë¯¸ì§€ë¥¼ ì‹œê°í™”í•˜ê¸° ìœ„í•´ì„œ í•œ ì°¨ì› ê°ì†Œì‹œí‚¨ 3ì°¨ì›ìœ¼ë¡œ ë³€ê²½í•´ì¤€ë‹¤.
    aug_image = np.squeeze(aug_image_batch)

    # ì‹¤ìˆ˜ì—ì„œ ì •ìˆ˜ë¡œ ë³€ê²½ í›„ ì¶œë ¥í•´ì¤€ë‹¤.
    show_image(aug_image.astype('int'))


    ì˜ˆì‹œ) ì‹¤ì œë¡œëŠ” ë” ê²€ìƒ‰í•´ì„œ í•„ìš”í•œ ê²ƒ ì°¾ì•„ì„œ í•  ê²ƒ.(channel_chift ê°™ì€ ì¡°ê±´ë„ ìˆìŒ)
    idg = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    brightness_range=(0.7, 1.3),
    horizontal_flip=True,
    vertical_flip=True,
    rescale=1./255

)

    # í”½ì…€ ë‹¨ìœ„ë¡œ ë˜ì–´ ìˆê¸° ë•Œë¬¸ì— ìœ¡ì•ˆìœ¼ë¡œ êµ¬ë¶„ì´ ì•ˆë˜ë„ ì •ìƒì ìœ¼ë¡œ í™•ì¸ë˜ëŠ” ê²ƒ.
    show_aug_image_batch(image, idg)

---

    # ì›ë³¸ ì´ë¯¸ì§€ì˜ ì˜ìƒì„ ë³´ì—¬ì£¼ëŠ” í•¨ìˆ˜
    def show_images(images, targets, ncols=4, title=None):
        figsize, axs = plt.subplots(figsize=(ncols * 5, 4), nrows=1, ncols=ncols)
        for i in range(ncols):
            axs[i].imshow(images[i])
            axs[i].set_title(targets[i])

    ì›ë³¸ ì´ë¯¸ì§€ì™€ ë³€ê²½ëœ ì´ë¯¸ì§€ë¥¼ ë³´ì—¬ì£¼ê¸° ìœ„í•œ í•¨ìˆ˜
    def repeat_aug(original_image=None, target=None, aug=None, ncols=2):
        image_list = [original_image]
        target_list = ['Original']

        aug_image = aug(image=original_image)['image']
        image_list.append(aug_image)
        target_list.append(target)

        show_images(image_list, target_list, ncols=ncols)

---

    # conda install -c -conda-forge albumentations
    # HorizontalFlip => p: í™•ë¥ 

    import albumentations as A
    aug = A.HorizontalFlip(p=0.8)

    repeat_aug(original_image=image, target='HorizontalFlip', aug=aug)

    +++++++++++++++++++++++++++++++++++++++++++++++++

    aug = A.VerticalFlip(p=0.1)

    repeat_aug(original_image=image, target='VerticalFlip', aug=aug)

    +++++++++++++++++++++++++++++++++++++++++++++++++

    # limit=90 ì¼ ê²½ìš° -90 ~ 90 ë²”ìœ„ë¥¼ ê°–ëŠ”ë‹¤.
    # aug = A.Rotate(p=0.5, limit=90, border_mode=cv2.BORDER_REFLECT) # ë°˜ì‚¬
    # aug = A.Rotate(p=0.5, limit=90, border_mode=cv2.BORDER_WRAP) # í”½ì…€ ê°€ë¦¬ê¸°
    aug = A.Rotate(p=0.5, limit=90, border_mode=cv2.BORDER_CONSTANT) # ê²€ì€ìƒ‰ìœ¼ë¡œ ê°€ë¦¬ê¸°

    repeat_aug(original_image=image, target='Rotate', aug=aug)

    +++++++++++++++++++++++++++++++++++++++++++++++++

    aug = A.RandomRotate90(p=1)

    repeat_aug(original_image=image, target='RandomRotate90', aug=aug)

    # shiftì™€ scale(zoom), rotateë¥¼ í•¨ê»˜ ë˜ëŠ” ë³„ê°œë¡œ ì ìš©, ë³„ê°œë¡œ ì ìš©í•  ê²½ìš° ë‚˜ë¨¸ì§€ 0ìœ¼ë¡œ ì„¤ì •
    aug = A.ShiftScaleRotate(shift_limit=0.5, scale_limit=(-0.8, 1.5), rotate_limit=90, p=1, border_mode=cv2.BORDER_WRAP)

    repeat_aug(original_image=image, target='ShiftScaleRotate', aug=aug)

    +++++++++++++++++++++++++++++++++++++++++++++++++

    # ì—¬ëŸ¬ê°œì˜ augmentation ì„ ë¬¶ì–´ì„œ ì‚¬ìš©
    aug = A.Compose([
        A.VerticalFlip(p=0.5),
        A.HorizontalFlip(p=0.5)
    ])

    repeat_aug(original_image=image, target='Compose', aug=aug, ncols =5)

    +++++++++++++++++++++++++++++++++++++++++++++++++

    # íŠ¹ì • ì˜ì—­ì„ ì˜ë¼ë‚¸ í›„ ì›ë³¸ ì‚¬ì´ì¦ˆë¡œ ë‹¤ì‹œ Resize í•˜ì§€ ì•Šì€
    # x: width, y:height, maxê°’ì€ ì´ë¯¸ì§€ í¬ê¸°ë¡œ ì„¤ì •í•´ì•¼í•œë‹¤.
    # ë²”ìœ„ê°€ ì•„ë‹Œ ì§€ì •í•œ ë¶€ë¶„ì„ ì œì™¸í•œ ë‚˜ë¨¸ì§€ ë¶€ë¶„ì„ ê°€ì ¸ì˜¨ë‹¤.

    aug = A.Crop(x_min= 100, y_min= 100 , x_max=300, y_max=225, p=1)
    repeat_aug(original_image=image, target='Crop', aug=aug, ncols =5)

    aug(image=image)['image'].shape

    +++++++++++++++++++++++++++++++++++++++++++++++++

    aug = A.Compose([
        A.Crop(x_min= 100, y_min= 100 , x_max=300, y_max=225, p=1),
        A.Resize(250, 250)
    ])

    repeat_aug(original_image=image, target='Crop', aug=aug, ncols =2)
    aug(image=image)['image'].shape

    +++++++++++++++++++++++++++++++++++++++++++++++++

    aug =A.CenterCrop(height=100, width=200, p=1)

    repeat_aug(original_image=image, target='CenterCrop', aug=aug)
    aug(image=image)['image'].shape

    +++++++++++++++++++++++++++++++++++++++++++++++++

    # crop ì„ ì‚¬ìš© ì‹œ resize ë¥¼ ì´ìš©í•˜ì—¬ ì›í•˜ëŠ” ì´ë¯¸ì§€ ì‚¬ì´ì¦ˆë¡œ ë³€ê²½ í•œ í›„ ì‚¬ìš© í•  ê²ƒ.
    aug = A.Compose([
        A.CenterCrop(height=100, width=200, p=1),
        A.Resize(250, 250)
    ])

    repeat_aug(original_image=image, target='CenterCrop', aug=aug)
    aug(image=image)['image'].shape

    +++++++++++++++++++++++++++++++++++++++++++++++++

    # íŠ¹ì • ì˜ì—­ì„ scale ë²”ìœ„ë§Œí¼ ì˜ë¼ë‚¸ í›„, ì „ë‹¬í•  widthì™€ height í¬ê¸°ë¡œ Resizeí•œë‹¤.
    # ì›ë³¸ ì´ë¯¸ì§€ê°€ 100 X 100 ì¼ ê²½ìš° scale(0.1, 0.5)ë¥¼ ì ìš©í•˜ë©´,
    # 10 ~ 50% ë²”ìœ„ì˜ ëœë¤í•œ ì˜ì—­ì„ ì˜ë¼ë‚¸ í›„ resize í•´ì¤€ë‹¤.
    aug = A.RandomResizedCrop(height=250, width=250, scale=(0.2, 0.7), p=1)

    repeat_aug(original_image=image, target='RandomResizedCrop', aug=aug, ncols=5)
    aug(image=image)['image'].shape

    +++++++++++++++++++++++++++++++++++++++++++++++++
    # ë°ê¸°, ëŒ€ë¹„
    # 0.2 == (-0.2, 0.2)
    # ê°œë³„ ì‘ì—… ì§„í–‰ ì‹œ, ë‚˜ë¨¸ì§€ëŠ” 0ì„ ì „ë‹¬í•œë‹¤.

    aug = A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=1)

    repeat_aug(original_image=image, target='RandomBrightnessContrast', aug=aug, ncols=5)
    aug(image=image)['image'].shape

    +++++++++++++++++++++++++++++++++++++++++++++++++
    # ìƒ‰ìƒ, ì±„ë„, ëª…ë„
    # hue_shift_limit
    # sat_shift_limit
    # val_shift_limit

    aug = A.HueSaturationValue(p=1)

    repeat_aug(original_image=image, target='HueSaturationValue', aug=aug, ncols=5)


    +++++++++++++++++++++++++++++++++++++++++++++++++

    # ë°ê¸°, ëŒ€ë¹„, ì±„ë„, ìƒ‰ìƒ
    aug = A.ColorJitter(p=1)
    repeat_aug(original_image=image, target='ColorJitter', aug=aug, ncols=5)

    +++++++++++++++++++++++++++++++++++++++++++++++++
    # ì±„ë„ ìœ„ì¹˜ ë³€ê²½
    aug = A.ChannelShuffle(p=1)

    repeat_aug(original_image=image, target='ColorJitter', aug=aug, ncols=4)

    +++++++++++++++++++++++++++++++++++++++++++++++++
    # ê°€ìš°ì‹œì•ˆ ë¶„í¬(ì •ê·œ ë¶„í¬)ë¥¼ ì‚¬ìš©í•´ì„œ Noiseë¥¼ ìƒì„±í•œë‹¤.
    aug = A.GaussNoise(p=1, var_limit=(400, 900))

    repeat_aug(original_image=image, target='GaussNoise', aug=aug, ncols=4)

    +++++++++++++++++++++++++++++++++++++++++++++++++
    # ëª…ì•”ëŒ€ë¹„ê°€ ì„ ëª…í•œ ì •ë„ ì¡°ì • / ì–´ë‘ìš´ ì´ë¯¸ì§€ê°€ ë§ì„ ë•Œ íš¨ê³¼ì 
    aug = A.CLAHE(p=1, clip_limit=4)

    repeat_aug(original_image=image, target='CLAHE', aug=aug, ncols=4)


    +++++++++++++++++++++++++++++++++++++++++++++++++
    # íë ¤ì§€ê²Œ í•˜ê¸° / ë¸”ëŸ¬ì²˜ë¦¬
    aug = A.Blur(p=1, blur_limit=(3,12))

    repeat_aug(original_image=image, target='Blur', aug=aug, ncols=4)

    +++++++++++++++++++++++++++++++++++++++++++++++++
    aug = A.Compose([
        A.CenterCrop(height=100, width=100, p=0.5),
        A.HorizontalFlip(p=0.5),
        A.RandomBrightnessContrast(p=0.5),
        A.Resize(225,300, p=1)
    ], p=0.5)

    repeat_aug(original_image=image, target='Compose', aug=aug, ncols=4)

    +++++++++++++++++++++++++++++++++++++++++++++++++
    # ê²€ì€ìƒ‰ ì •ì‚¬ê°í˜•ì„ ëœë¤í•˜ê²Œ ë°°ì¹˜í•˜ì—¬ noiseë¥¼ ë°œìƒì‹œí‚¨ë‹¤.
    aug = A.CoarseDropout(max_holes=100, max_height=10, max_width=10, p=0.5)

    repeat_aug(original_image=image, target='CoarseDropout', aug=aug, ncols=4)

    +++++++++++++++++++++++++++++++++++++++++++++++++
    # ì—¬ëŸ¬ ê°œì¤‘ í•œê°œë§Œ ì ìš©ë˜ëŠ” ê²½ìš°
    aug = A.OneOf([
        A.CenterCrop(height=100, width=100, p=0.5),
        A.HorizontalFlip(p=0.5),
        A.RandomBrightnessContrast(p=0.5),
        A.Resize(225,300, p=1)
    ], p=0.5)

    repeat_aug(original_image=image, target='OneOf', aug=aug, ncols=4)

    +++++++++++++++++++++++++++++++++++++++++++++++++

    aug = A.Compose([
        A.CenterCrop(height=100, width=100, p=0.5),
        A.HorizontalFlip(p=0.5),
        A.Rotate(limit=(45, 90), p=1, border_mode=cv2.BORDER_CONSTANT),
        A.OneOf([
            A.Blur(p=0.3, blur_limit=(0.3, 0.5)),
            A.CLAHE(p=0.3)
        ]),
        A.Resize(225,300, p=1)
    ], p=0.5)

    repeat_aug(original_image=image, target='Compose', aug=aug, ncols=4)

    import albumentations as A

    +++++++++++++++++++++++++++++++++++++++++++++++++

    def transform(image):
        aug = A.Compose([
            A.HorizontalFlip(p=0.5),
            A.VerticalFlip(p=0.5),
            A.OneOf([
                A.ColorJitter(p=0.5),
                A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5)
            ], p=1)
        ], p=0.5)

        return aug(image=image)['image']

    idg = ImageDataGenerator(preprocessing_function=transform, rescale=1./255)

</details>

<details>
    <summary>8. Pretrained Mode (VGG)</summary>

        from tensorflow.keras.models import Model
        from tensorflow.keras.layers import Input, Dense , Conv2D , Dropout , Flatten , Activation, MaxPooling2D , GlobalAveragePooling2D
        from tensorflow.keras.optimizers import Adam
        from tensorflow.keras.layers import BatchNormalization
        from tensorflow.keras.callbacks import ReduceLROnPlateau , EarlyStopping , ModelCheckpoint

        def vggnet(input_shape=(224, 224, 3), n_classes=10):
            input_tensor = Input(shape=input_shape)

            # Block 1
            x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(input_tensor)
            x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)
            x = MaxPooling2D((2, 2), strides=1, name='block1_pool')(x)

            # Block 2
            x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)
            x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)
            x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)

            # Block 3
            x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)
            x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)
            x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)
            x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)

            # Block 4
            x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)
            x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)
            x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)
            x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)

            # Block 5
            x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)
            x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)
            x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)
            x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)

            x = GlobalAveragePooling2D()(x)
            x = Dropout(0.5)(x)
            x = Dense(units = 120, activation = 'relu')(x)
            x = Dropout(0.5)(x)

            output = Dense(units = n_classes, activation = 'softmax')(x)

            model = Model(inputs=input_tensor, outputs=output)
            model.summary()

            return model

</details>

<details>
    <summary>9. Pretrained Mode (Inception)</summary>

    from tensorflow.keras.models import Model
    from tensorflow.keras.layers import Input, Dense , Conv2D , Dropout , Flatten , Activation, MaxPooling2D , GlobalAveragePooling2D
    from tensorflow.keras.optimizers import Adam , RMSprop
    from tensorflow.keras.layers import BatchNormalization
    from tensorflow.keras.callbacks import ReduceLROnPlateau , EarlyStopping , ModelCheckpoint , LearningRateScheduler

    from tensorflow.keras.layers import Concatenate

    def inception_module(x, filters_1x1, filters_3x3_reduce, filters_3x3, filters_5x5_reduce, filters_5x5,filters_pool_reduce, name=None):

        # ì²«ë²ˆì§¸ 1x1 Conv
        conv_1x1 = Conv2D(filters_1x1, (1, 1), padding='same', activation='relu')(x)

        # 3x3 ì ìš© ì „ 1x1 conv
        conv_3x3 = Conv2D(filters_3x3_reduce, (1, 1), padding='same', activation='relu')(x)
        conv_3x3 = Conv2D(filters_3x3, (3, 3), padding='same', activation='relu')(conv_3x3)

        # 5x5 ì ìš© ì „ 1x1 Conv
        conv_5x5 = Conv2D(filters_5x5_reduce, (1, 1), padding='same', activation='relu')(x)
        conv_5x5 = Conv2D(filters_5x5, (5, 5), padding='same', activation='relu')(conv_5x5)

        pool = MaxPooling2D((3, 3), strides=(1, 1), padding='same')(x)
        pool = Conv2D(filters_pool_reduce, (1, 1), padding='same', activation='relu')(pool)

        # 1x1 ê²°ê³¼, 3x3 ê²°ê³¼, 5x5 ê²°ê³¼, poolì´í›„ 1x1 ê²°ê³¼ feature mapì„ ì±„ë„(axis=-1) ê¸°ì¤€ìœ¼ë¡œ Concat ì ìš©.
        # ConcatenateëŠ” ì‚¬ì´ì¦ˆëŠ” ê·¸ëŒ€ë¡œì´ê³ , ê° ì±„ë„ ìˆ˜ë¥¼ ë”í•œë‹¤. ì¦‰, ê·¸ëŒ€ë¡œ ë’¤ì— ì—°ê²°ëœë‹¤.
        output = Concatenate(axis=-1, name=name)([conv_1x1, conv_3x3, conv_5x5, pool])
        return output

    ---
    def googlenet(in_shape=(224, 224, 3), n_classes=10):
        input_tensor = Input(in_shape)

        x = Conv2D(64, (7, 7), padding='same', strides=(2, 2), activation='relu', name='conv_1_7x7_2')(input_tensor)
        x = MaxPooling2D((3, 3), padding='same', strides=(2, 2), name='max_pool_1_3x3_2')(x)
        x = Conv2D(64, (1, 1), padding='same', strides=(1, 1), activation='relu', name='conv_2a_3x3_1')(x)
        x = Conv2D(192, (3, 3), padding='same', strides=(1, 1), activation='relu', name='conv_2b_3x3_1')(x)
        x = MaxPooling2D((3, 3), padding='same', strides=(2, 2), name='max_pool_2_3x3_2')(x)

        # ì²«ë²ˆì§¸ inception ëª¨ë“ˆ
        x = inception_module(x, filters_1x1=64,
                            filters_3x3_reduce=96,
                            filters_3x3=128,
                            filters_5x5_reduce=16,
                            filters_5x5=32,
                            filters_pool_reduce=32,
                            name='inception_3a')
        # ë‘ë²ˆì§¸ inception ëª¨ë“ˆ
        x = inception_module(x,
                            filters_1x1=128,
                            filters_3x3_reduce=128,
                            filters_3x3=192,
                            filters_5x5_reduce=32,
                            filters_5x5=96,
                            filters_pool_reduce=64,
                            name='inception_3b')

        x = MaxPooling2D((3, 3), padding='same', strides=(2, 2), name='max_pool_3_3x3_2')(x)

        # ì„¸ë²ˆì§¸ inception ëª¨ë“ˆ
        x = inception_module(x,
                            filters_1x1=192,
                            filters_3x3_reduce=96,
                            filters_3x3=208,
                            filters_5x5_reduce=16,
                            filters_5x5=48,
                            filters_pool_reduce=64,
                            name='inception_4a')
        # ë„¤ë²ˆì§¸ inception ëª¨ë“ˆ
        x = inception_module(x,
                            filters_1x1=160,
                            filters_3x3_reduce=112,
                            filters_3x3=224,
                            filters_5x5_reduce=24,
                            filters_5x5=64,
                            filters_pool_reduce=64,
                            name='inception_4b')

        # ë‹¤ì„¯ë²ˆì§¸ inception ëª¨ë“ˆ
        x = inception_module(x,
                            filters_1x1=128,
                            filters_3x3_reduce=128,
                            filters_3x3=256,
                            filters_5x5_reduce=24,
                            filters_5x5=64,
                            filters_pool_reduce=64,
                            name='inception_4c')
        # ì—¬ì„¯ë²ˆì§¸ inception ëª¨ë“ˆ
        x = inception_module(x,
                            filters_1x1=112,
                            filters_3x3_reduce=144,
                            filters_3x3=288,
                            filters_5x5_reduce=32,
                            filters_5x5=64,
                            filters_pool_reduce=64,
                            name='inception_4d')
        # ì¼ê³±ë²ˆì§¸ inception ëª¨ë“ˆ
        x = inception_module(x,
                            filters_1x1=256,
                            filters_3x3_reduce=160,
                            filters_3x3=320,
                            filters_5x5_reduce=32,
                            filters_5x5=128,
                            filters_pool_reduce=128,
                            name='inception_4e')

        x = MaxPooling2D((3, 3), padding='same', strides=(2, 2), name='max_pool_4_3x3_2')(x)
        # ì—¬ëŸë²ˆì§¸ inception ëª¨ë“ˆ
        x = inception_module(x,
                            filters_1x1=256,
                            filters_3x3_reduce=160,
                            filters_3x3=320,
                            filters_5x5_reduce=32,
                            filters_5x5=128,
                            filters_pool_reduce=128,
                            name='inception_5a')
        # ì•„í™‰ë²ˆì§¸ inception ëª¨ë“ˆ
        x = inception_module(x,
                            filters_1x1=384,
                            filters_3x3_reduce=192,
                            filters_3x3=384,
                            filters_5x5_reduce=48,
                            filters_5x5=128,
                            filters_pool_reduce=128,
                            name='inception_5b')

        x = GlobalAveragePooling2D(name='avg_pool_5_3x3_1')(x)
        x = Dropout(0.5)(x)
        output = Dense(n_classes, activation='softmax', name='output')(x)

        model = Model(inputs=input_tensor, outputs=output)
        model.summary()

        return model

</details>

<details>
    <summary>10. Pretrained Mode (ResNet)</summary>

    from tensorflow.keras.layers import ZeroPadding2D, MaxPooling2D

    def do_first_conv(input_tensor):
        # 7x7 Conv ì—°ì‚° ìˆ˜í–‰í•˜ì—¬ feature map ìƒì„±í•˜ë˜ input_tensor í¬ê¸°(image í¬ê¸°)ì˜ ì ˆë°˜ìœ¼ë¡œ ìƒì„±.  filter ê°œìˆ˜ëŠ” 64ê°œ
        # 224x224 ë¥¼ inputì„ 7x7 conv, strides=2ë¡œ 112x112 ì¶œë ¥í•˜ê¸° ìœ„í•´ Zero padding ì ìš©.
        x = ZeroPadding2D(padding=(3, 3), name='conv1_pad')(input_tensor)
        x = Conv2D(64, (7, 7), strides=(2, 2), padding='valid', kernel_initializer='he_normal', name='conv')(x)
        x = BatchNormalization(axis=3, name='bn_conv1')(x)
        x = Activation('relu')(x)
        # ë‹¤ì‹œ feature map í¬ê¸°ë¥¼ MaxPoolingìœ¼ë¡œ ì ˆë°˜ìœ¼ë¡œ ë§Œë“¬. 56x56ìœ¼ë¡œ ì¶œë ¥í•˜ê¸° ìœ„í•´ zero padding ì ìš©.
        x = ZeroPadding2D(padding=(1, 1), name='pool1_pad')(x)
        x = MaxPooling2D((3, 3), strides=(2, 2))(x)

        return x
    ---

    from tensorflow.keras.layers import Conv2D, Dense, BatchNormalization, Activation
    from tensorflow.keras.layers import add, Add

    # ì—¬ëŸ¬ ê°œì˜ blockì„ stageë¡œ êµ¬ë¶„
    # blockì€ ë™ì¼ stageë‚´ì—ì„œ identity blockì„ êµ¬ë¶„
    def identity_block(input_tensor, kernel_size, filters, stage, block):
        # filter1ì€ ì²«ë²ˆì§¸ 1x1 filter ê°œìˆ˜, filter2ëŠ” 3x3 filterê°œìˆ˜, filter3ëŠ” ë§ˆì§€ë§‰ 1x1 filterê°œìˆ˜
        filter1, filter2, filter3 = filters
        # conv layerì™€ Batch normalization layerê°ê°ì— ê³ ìœ í•œ ì´ë¦„ì„ ë¶€ì—¬í•˜ê¸° ìœ„í•´ ì„¤ì •. ì…ë ¥ë°›ì€ stageì™€ blockì— ê¸°ë°˜í•˜ì—¬ ì´ë¦„ ë¶€ì—¬
        conv_name_base = 'res' + str(stage) + block + '_branch'
        bn_name_base = 'bn' + str(stage) + block + '_branch'

        # ì´ì „ layerì— ì…ë ¥ ë°›ì€ input_tensor(í•¨ìˆ˜ì¸ìë¡œ ì…ë ¥ë°›ìŒ)ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì²«ë²ˆì§¸ 1x1 Conv->Batch Norm->Relu ìˆ˜í–‰.
        # ì²«ë²ˆì§¸ 1x1 Convì—ì„œ Channel Dimension Reduction ìˆ˜í–‰. filter1ì€ ì…ë ¥ input_tensor(ì…ë ¥ Feature Map) Channel ì°¨ì› ê°œìˆ˜ì˜ 1/4ì„.
        x = Conv2D(filters=filter1, kernel_size=(1, 1), kernel_initializer='he_normal', name=conv_name_base+'2a')(input_tensor)
        # Batch Normì ìš©. ì…ë ¥ ë°ì´í„°ëŠ” batch ì‚¬ì´ì¦ˆê¹Œì§€ í¬í•¨í•˜ì—¬ 4ì°¨ì›ì„(batch_size, height, width, channel depth)ì„
        # Batch Normì˜ axisëŠ” channel depthì— í•´ë‹¹í•˜ëŠ” axis indexì¸ 3ì„ ì…ë ¥.(ë¬´ì¡°ê±´ channelì´ ë§ˆì§€ë§‰ ì°¨ì›ì˜ ê°’ìœ¼ë¡œ ì…ë ¥ëœë‹¤ê³  ê°€ì •. )
        x = BatchNormalization(axis=3, name=bn_name_base+'2a')(x)
        # ReLU Activation ì ìš©.
        x = Activation('relu')(x)

        # ë‘ë²ˆì§¸ 3x3 Conv->Batch Norm->ReLU ìˆ˜í–‰
        # 3x3ì´ ì•„ë‹Œ ë‹¤ë¥¸ kernel sizeë„ êµ¬ì„± ê°€ëŠ¥í•  ìˆ˜ ìˆë„ë¡ identity_block() ì¸ìë¡œ ì…ë ¥ë°›ì€ kernel_size ì´ìš©.
        # Conv ìˆ˜í–‰ ì¶œë ¥ ì‚¬ì´ì¦ˆê°€ ë³€í•˜ì§€ ì•Šë„ë¡ padding='same'ìœ¼ë¡œ ì„¤ì •. filter ê°œìˆ˜ëŠ” ì´ì „ì˜ 1x1 filterê°œìˆ˜ì™€ ë™ì¼.
        x = Conv2D(filters=filter2, kernel_size=kernel_size, padding='same', kernel_initializer='he_normal', name=conv_name_base+'2b')(x)
        x = BatchNormalization(axis=3, name=bn_name_base+'2b')(x)
        x = Activation('relu')(x)

        # ë§ˆì§€ë§‰ 1x1 Conv->Batch Norm ìˆ˜í–‰. ReLUë¥¼ ìˆ˜í–‰í•˜ì§€ ì•ŠìŒì— ìœ ì˜.
        # filter í¬ê¸°ëŠ” input_tensor channel ì°¨ì› ê°œìˆ˜ë¡œ ì›ë³µ
        x = Conv2D(filters=filter3, kernel_size=(1, 1), kernel_initializer='he_normal', name=conv_name_base+'2c')(x)
        x = BatchNormalization(axis=3, name=bn_name_base+'2c')(x)
        # Residual Block ìˆ˜í–‰ ê²°ê³¼ì™€ input_tensorë¥¼ í•©í•œë‹¤.
        x = Add()([input_tensor, x])
        # ë˜ëŠ” x = add([x, input_tensor]) ì™€ ê°™ì´ êµ¬í˜„í•  ìˆ˜ë„ ìˆìŒ.

        # ë§ˆì§€ë§‰ìœ¼ë¡œ identity block ë‚´ì—ì„œ ìµœì¢… ReLUë¥¼ ì ìš©
        x = Activation('relu')(x)

        return x

    ---
    def conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2)):
        '''
        í•¨ìˆ˜ ì…ë ¥ ì¸ì ì„¤ëª…
        input_tensor: ì…ë ¥ tensor
        middle_kernel_size: ì¤‘ê°„ì— ìœ„ì¹˜í•˜ëŠ” kernel í¬ê¸°. identity blockë‚´ì— ìˆëŠ” ë‘ê°œì˜ conv layerì¤‘ 1x1 kernelì´ ì•„ë‹ˆê³ , 3x3 kernelì„.
                            3x3 ì»¤ë„ ì´ì™¸ì—ë„ 5x5 kernelë„ ì§€ì •í•  ìˆ˜ ìˆê²Œ êµ¬ì„±.
        filters: 3ê°œ conv layerë“¤ì˜ filterê°œìˆ˜ë¥¼ list í˜•íƒœë¡œ ì…ë ¥ ë°›ìŒ. ì²«ë²ˆì§¸ ì›ì†ŒëŠ” ì²«ë²ˆì§¸ 1x1 filter ê°œìˆ˜, ë‘ë²ˆì§¸ëŠ” 3x3 filter ê°œìˆ˜,
                ì„¸ë²ˆì§¸ëŠ” ë§ˆì§€ë§‰ 1x1 filter ê°œìˆ˜
        stage: identity blockë“¤ì´ ì—¬ëŸ¬ê°œê°€ ê²°í•©ë˜ë¯€ë¡œ ì´ë¥¼ êµ¬ë¶„í•˜ê¸° ìœ„í•´ì„œ ì„¤ì •. ë™ì¼í•œ filterìˆ˜ë¥¼ ê°€ì§€ëŠ” identity blockë“¤ì„  ë™ì¼í•œ stageë¡œ ì„¤ì •.
        block: ë™ì¼ stageë‚´ì—ì„œ identity blockì„ êµ¬ë³„í•˜ê¸° ìœ„í•œ êµ¬ë¶„ì
        strides: ì…ë ¥ feature mapì˜ í¬ê¸°ë¥¼ ì ˆë°˜ìœ¼ë¡œ ì¤„ì´ê¸° ìœ„í•´ì„œ ì‚¬ìš©. DefaultëŠ” 2ì´ì§€ë§Œ,
                ì²«ë²ˆì§¸ Stageì˜ ì²«ë²ˆì§¸ blockì—ì„œëŠ” ì´ë¯¸ ì…ë ¥ feature mapì´ max poolë¡œ ì ˆë°˜ì´ ì¤„ì–´ìˆëŠ” ìƒíƒœì´ë¯€ë¡œ ë‹¤ì‹œ ì¤„ì´ì§€ ì•Šê¸° ìœ„í•´ 1ì„ í˜¸ì¶œí•´ì•¼í•¨
        '''

        # filtersë¡œ list í˜•íƒœë¡œ ì…ë ¥ëœ filter ê°œìˆ˜ë¥¼ ê°ê° filter1, filter2, filter3ë¡œ í• ë‹¹.
        # filterì€ ì²«ë²ˆì§¸ 1x1 filter ê°œìˆ˜, filter2ëŠ” 3x3 filterê°œìˆ˜, filter3ëŠ” ë§ˆì§€ë§‰ 1x1 filterê°œìˆ˜
        filter1, filter2, filter3 = filters
        # conv layerì™€ Batch normalization layerê°ê°ì— ê³ ìœ í•œ ì´ë¦„ì„ ë¶€ì—¬í•˜ê¸° ìœ„í•´ ì„¤ì •. ì…ë ¥ë°›ì€ stageì™€ blockì— ê¸°ë°˜í•˜ì—¬ ì´ë¦„ ë¶€ì—¬
        conv_name_base = 'res' + str(stage) + block + '_branch'
        bn_name_base = 'bn' + str(stage) + block + '_branch'

        # ì´ì „ layerì— ì…ë ¥ ë°›ì€ input_tensor(í•¨ìˆ˜ì¸ìë¡œ ì…ë ¥ë°›ìŒ)ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì²«ë²ˆì§¸ 1x1 Conv->Batch Norm->Relu ìˆ˜í–‰.
        # ì…ë ¥ feature map ì‚¬ì´ì¦ˆë¥¼ 1/2ë¡œ ì¤„ì´ê¸° ìœ„í•´ stridesì¸ìë¥¼ ì…ë ¥
        x = Conv2D(filters=filter1, kernel_size=(1, 1), strides=strides, kernel_initializer='he_normal', name=conv_name_base+'2a')(input_tensor)
        # Batch Normì ìš©. ì…ë ¥ ë°ì´í„°ëŠ” batch ì‚¬ì´ì¦ˆê¹Œì§€ í¬í•¨í•˜ì—¬ 4ì°¨ì›ì„(batch_size, height, width, channel depth)ì„
        # Batch Normì˜ axisëŠ” channel depthì— í•´ë‹¹í•˜ëŠ” axis indexì¸ 3ì„ ì…ë ¥.(ë¬´ì¡°ê±´ channelì´ ë§ˆì§€ë§‰ ì°¨ì›ì˜ ê°’ìœ¼ë¡œ ì…ë ¥ëœë‹¤ê³  ê°€ì •. )
        x = BatchNormalization(axis=3, name=bn_name_base+'2a')(x)
        # ReLU Activation ì ìš©.
        x = Activation('relu')(x)

        # ë‘ë²ˆì§¸ 3x3 Conv->Batch Norm->ReLU ìˆ˜í–‰
        # 3x3ì´ ì•„ë‹Œ ë‹¤ë¥¸ kernel sizeë„ êµ¬ì„± ê°€ëŠ¥í•  ìˆ˜ ìˆë„ë¡ identity_block() ì¸ìë¡œ ì…ë ¥ë°›ì€ middle_kernel_sizeë¥¼ ì´ìš©.
        # Conv ìˆ˜í–‰ ì¶œë ¥ ì‚¬ì´ì¦ˆê°€ ë³€í•˜ì§€ ì•Šë„ë¡ padding='same'ìœ¼ë¡œ ì„¤ì •. filter ê°œìˆ˜ëŠ” ì´ì „ì˜ 1x1 filterê°œìˆ˜ì™€ ë™ì¼.
        x = Conv2D(filters=filter2, kernel_size=kernel_size, padding='same', kernel_initializer='he_normal', name=conv_name_base+'2b')(x)
        x = BatchNormalization(axis=3, name=bn_name_base+'2b')(x)
        x = Activation('relu')(x)

        # ë§ˆì§€ë§‰ 1x1 Conv->Batch Norm ìˆ˜í–‰. ReLUë¥¼ ìˆ˜í–‰í•˜ì§€ ì•ŠìŒì— ìœ ì˜.
        # filter í¬ê¸°ëŠ” input_tensor channel ì°¨ì› ê°œìˆ˜ë¡œ ì›ë³µ
        x = Conv2D(filters=filter3, kernel_size=(1, 1), kernel_initializer='he_normal', name=conv_name_base+'2c')(x)
        x = BatchNormalization(axis=3, name=bn_name_base+'2c')(x)

        # shortcutì„ 1x1 conv ìˆ˜í–‰, filter3ê°€ ì…ë ¥ feature mapì˜ filter ê°œìˆ˜
        shortcut = Conv2D(filter3, (1, 1), strides=strides, kernel_initializer='he_normal', name=conv_name_base+'1')(input_tensor)
        shortcut = BatchNormalization(axis=3, name=bn_name_base+'1')(shortcut)

        # Residual Block ìˆ˜í–‰ ê²°ê³¼ì™€ 1x1 convê°€ ì ìš©ëœ shortcutì„ í•©í•œë‹¤.
        x = add([x, shortcut])

        # ë§ˆì§€ë§‰ìœ¼ë¡œ identity block ë‚´ì—ì„œ ìµœì¢… ReLUë¥¼ ì ìš©
        x = Activation('relu')(x)

        return x

    ---
    from tensorflow.keras.models import Model
    from tensorflow.keras.layers import Input, Dense , Conv2D , Dropout , Flatten , Activation, MaxPooling2D , GlobalAveragePooling2D
    from tensorflow.keras.optimizers import Adam , RMSprop
    from tensorflow.keras.layers import BatchNormalization
    from tensorflow.keras.callbacks import ReduceLROnPlateau , EarlyStopping , ModelCheckpoint , LearningRateScheduler

    def resnet(in_shape=(224, 224, 3), n_classes=10):
        input_tensor = Input(shape=in_shape)

        #ì²«ë²ˆì§¸ 7x7 Convì™€ Max Polling ì ìš©.
        x = do_first_conv(input_tensor)

        # stage 2ì˜ conv_blockê³¼ identity block ìƒì„±. stage2ì˜ ì²«ë²ˆì§¸ conv_blockì€ stridesë¥¼ 1ë¡œ í•˜ì—¬ í¬ê¸°ë¥¼ ì¤„ì´ì§€ ì•ŠìŒ.
        x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))
        x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')
        x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')

        # stage 3ì˜ conv_blockê³¼ identity block ìƒì„±. stage3ì˜ ì²«ë²ˆì§¸ conv_blockì€ stridesë¥¼ 2(default)ë¡œ í•˜ì—¬ í¬ê¸°ë¥¼ ì¤„ì„
        x = conv_block(x, 3, [128, 128, 512], stage=3, block='a')
        x = identity_block(x, 3, [128, 128, 512], stage=3, block='b')
        x = identity_block(x, 3, [128, 128, 512], stage=3, block='c')
        x = identity_block(x, 3, [128, 128, 512], stage=3, block='d')

        # stage 4ì˜ conv_blockê³¼ identity block ìƒì„±. stage4ì˜ ì²«ë²ˆì§¸ conv_blockì€ stridesë¥¼ 2(default)ë¡œ í•˜ì—¬ í¬ê¸°ë¥¼ ì¤„ì„
        x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a')
        x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b')
        x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c')
        x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d')
        x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e')
        x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f')

        # stage 5ì˜ conv_blockê³¼ identity block ìƒì„±. stage5ì˜ ì²«ë²ˆì§¸ conv_blockì€ stridesë¥¼ 2(default)ë¡œ í•˜ì—¬ í¬ê¸°ë¥¼ ì¤„ì„
        x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a')
        x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')
        x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')

        # classification dense layerì™€ ì—°ê²° ì „ GlobalAveragePooling ìˆ˜í–‰
        x = GlobalAveragePooling2D(name='avg_pool')(x)
        x = Dropout(rate=0.5)(x)
        x = Dense(200, activation='relu', name='fc_01')(x)
        x = Dropout(rate=0.5)(x)
        output = Dense(n_classes, activation='softmax', name='fc_final')(x)

        model = Model(inputs=input_tensor, outputs=output, name='resnet50')
        model.summary()

        return model

    ---
    model = resnet(in_shape=(224, 224, 3), n_classes=10)

</details>

<details>
    <summary>11. transfer_learing</summary>

        from tensorflow.keras.models import Model
        from tensorflow.keras.layers import Input, Dense, Conv2D, Dropout, Flatten, Activation, MaxPooling2D, GlobalAveragePooling2D
        from tensorflow.keras.applications import VGG16

        def create_model(verbose=False):
            input_tensor = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))

            # include_top: ë¶„ë¥˜ê¸° ë¶€ë¶„ì„ ì œì™¸í•˜ê³  ëª¨ë¸ì„ ê°€ì ¸ì˜¬ ìˆ˜ ìˆê¸° ë•Œë¬¸ì— ê°œì¸ì´ ì»¤ìŠ¤í…€ ê°€ëŠ¥
            # weights='imagenet': ImageNet ë°ì´í„°ì…‹ìœ¼ë¡œ ì‚¬ì „ í•™ìŠµëœ ê°€ì¤‘ì¹˜ë¥¼ ë¡œë“œ

            # model = VGG16(input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3), include_top=False, weights='imagenet')
            model = VGG16(input_tensor=input_tensor, include_top=False, weights='imagenet')

            # ë¶„ë¥˜ê¸°
            x = model.output
            x = GlobalAveragePooling2D()(x)
            x = Dense(50, activation='relu')(x)
            output = Dense(10, activation='softmax')(x)

            model = Model(inputs=model.input, outputs=output)
            if verbose:
                model.summary()

            return model

</details>
<details>
    <summary>12. gc.collect()</summary>

        import gc
        # ë¶ˆí•„ìš”í•œ ì˜¤ë¸Œì íŠ¸ë¥¼ ì§€ìš°ëŠ” ì‘ì—…
        gc.collect()

</details>

<details>
    <summary>13. íŠ¹ì • ì´ë¯¸ì§€ì— ëŒ€í•˜ì—¬ í›ˆë ¨ëœ ëª¨ë¸ì´ ì–´ë–¤ ê²°ê³¼ë¥¼ ë³´ì—¬ì£¼ëŠ” ë©”ì†Œë“œ(decode_predictions)</summary>

    import numpy as np
    from tensorflow.keras.preprocessing.image import load_img, img_to_array
    from tensorflow.keras.applications.vgg16 import VGG16, decode_predictions

    model = VGG16()
    image = load_img('./datasets/hamster.jpeg', target_size=(224, 224))
    image = img_to_array(image)

    image = np.expand_dims(image, axis=0)
    prediction = model.predict(image)
    target = decode_predictions(prediction)
    print(target)
    print(target[0][0])
    print(target[0][0][1], f'{np.round(target[0][0][2] * 100, 4)}%')

</details>

<details>
    <summary>14. scaling_preprocessing & augumentation code</summary>

    from tensorflow.keras.preprocessing.image import ImageDataGenerator
    import albumentations as A

    IMAGE_SIZE = 64
    BATCH_SIZE = 64

    # trainë°ì´í„°ì— ëŒ€í•˜ì—¬ ë°ì´í„° ì¦ê°•ì´ í•„ìš”í•œ ê²½ìš° í•´ë‹¹ í•¨ìˆ˜ë¥¼ ì‚¬ìš©
    def preprocessing_scaling_for_train(image, mode='tf'):
        aug = A.HorizontalFlip(p=0.5)
        image = aug(image=image)['image']

        if mode == 'tf': # -1 ~ 1 scale
            image = image / 127.5
            image -= 1.

        elif mode == 'torch': # z-score scale
            image = image / 255.
            mean = [0.485, 0.456, 0.406]
            std = [0.229, 0.224, 0.225]

            image[:, :, 0] = (image[:, :, 0] - mean[0])/std[0]
            image[:, :, 1] = (image[:, :, 1] - mean[1])/std[1]
            image[:, :, 2] = (image[:, :, 2] - mean[2])/std[2]

        return image

    def preprocessing_scaling(image, mode='tf'):
        if mode == 'tf': # -1 ~ 1 scale
            image = image / 127.5
            image -= 1.

        elif mode == 'torch': # z-score scale
            image = image / 255.
            mean = [0.485, 0.456, 0.406]
            std = [0.229, 0.224, 0.225]

            image[:, :, 0] = (image[:, :, 0] - mean[0])/std[0]
            image[:, :, 1] = (image[:, :, 1] - mean[1])/std[1]
            image[:, :, 2] = (image[:, :, 2] - mean[2])/std[2]

        return image

    train_generator = ImageDataGenerator(preprocessing_function=preprocessing_scaling_for_train)
    validation_generator = ImageDataGenerator(preprocessing_function=preprocessing_scaling)
    test_generator = ImageDataGenerator(preprocessing_function=preprocessing_scaling)

    train_flow = train_generator.flow_from_dataframe(dataframe=train_df,
                                                    x_col='file_paths',
                                                    y_col='target_names',
                                                    target_size=(IMAGE_SIZE, IMAGE_SIZE),
                                                    class_mode='categorical',
                                                    shuffle=True)

    validation_flow = validation_generator.flow_from_dataframe(dataframe=validation_df,
                                                    x_col='file_paths',
                                                    y_col='target_names',
                                                    target_size=(IMAGE_SIZE, IMAGE_SIZE),
                                                    class_mode='categorical')

    test_flow = test_generator.flow_from_dataframe(dataframe=test_df,
                                                    x_col='file_paths',
                                                    y_col='target_names',
                                                    target_size=(IMAGE_SIZE, IMAGE_SIZE),
                                                    class_mode='categorical')

    print(train_flow.class_indices)
    print(validation_flow.class_indices)
    print(test_flow.class_indices)

    ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
    # ì´ë¯¸ì§€ pixel ê·¸ë˜í”„ í™•ì¸

    import cv2
    import matplotlib.pyplot as plt

    image = cv2.cvtColor(cv2.imread(train_df.file_paths.iloc[10]), cv2.COLOR_BGR2RGB)
    plt.imshow(image)
    plt.show()

---

    scaled_image_tf = preprocessing_scaling(image, mode='tf')
    scaled_image_torch = preprocessing_scaling(image, mode='torch')

---

    def show_pixel_histogram(image):
        fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(12, 4))
        titles = ['Red', 'Green', 'Blue']
        for i in range(3):
            axs[i].hist(image[:, :, i].flatten(), bins=100, alpha=0.5)
            title_str = titles[i]
            axs[i].set(title=title_str)

    show_pixel_histogram(scaled_image_tf)
    show_pixel_histogram(scaled_image_torch)

</details>
</div>
