{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8b239a2-c5c0-4a51-b8ea-afb5c1a3fca6",
   "metadata": {},
   "source": [
    "### Callback API\n",
    "- 모델이 학습 중에 충돌이 발생하거나 네트워크가 끊기면, 모든 훈련 시간이 낭비될 수 있고,  \n",
    "  과적합을 방지하기 위해 훈련을 중간에 중지해야 할 수도 있다.\n",
    "- 모델이 학습을 시작하면 학습이 완료될 때까지 아무런 제어를 하지 못하게 되고,  \n",
    "  신경망 훈련을 완료하는 데에는 몇 시간 또는 며칠이 걸릴 수 있기 때문에 모델을 모니터링하고 제어할 수 있는 기능이 필요하다.\n",
    "- 훈련 시(fit()) Callback API를 등록시키면 반복 내에서 특정 이벤트 발생마다 등록된 callback이 호출되어 수행된다.\n",
    "\n",
    "**ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=False, save_weight_only=False, mode='auto')**\n",
    "- 특정 조건에 따라서 모델 또는 가중치를 파일로 저장한다.\n",
    "- filepath: \"weight.{epoch: 03d}-{val_loss:.4f}-{acc:.4f}.weights.hdf5\" 와 같이 모델의 체크포인트를 저장한다.\n",
    "- monitor: 모니터링할 성능 지표를 작성한다.\n",
    "- save_best_only: 가장 좋은 성능을 나타내는 모델을 저장할 지에 대한 여부\n",
    "- save_weights_only: weights만 저장할 지에 대한 여부\n",
    "- mode: {auto, min, max} 중 한 가지를 작성한다. monitor의 성능 지표에 따라 좋은 경우를 선택한다.  \n",
    "  *monitor의 성능 지표가 감소해야 좋은 경우 min, 증가해야 좋은 경우 max, monitor의 이름으로부터 자동으로 유추하고 싶다면 auto를 사용한다.\n",
    "\n",
    "**ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, verbose=0, mode='auto, min_lr=0')** (LR: Learning Rate)\n",
    "- 특정 반복동안 성능이 개선되지 않을 때, 학습률을 동적으로 감소시킨다.\n",
    "- monitor: 모니터링할 성능 지표를 작성한다.\n",
    "- factor: 학습률을 감소시킬 비율, 새로운 학습률 = 기존 학습률 * factor\n",
    "- patience: 학습률을 줄이기 전에 monitor할 반복 횟수\n",
    "- mode: {auto, min, max} 중 한 가지를 작성한다. monitor의 성능 지표에 따라 좋은 경우를 선택한다.  \n",
    "  *monitor의 성능 지표가 감소해야 좋은 경우 min, 증가해야 좋은 경우 max, monitor의 이름으로부터 자동으로 유추하고 싶다면 auto를 사용한다.\n",
    "\n",
    "**EarlyStopping(monitor='val_loss'm patient=0, verbose=0, mode='auto')**\n",
    "- 특정 반복동안 성능이 개선되지 않을 때, 학습을 조기에 중단한다.\n",
    "- monitor: 모니터링할 성능 지표를 작성한다.\n",
    "- patience: Early Stopping을 적용하기 전에 monitor할 반복 횟수.\n",
    "- mode: {auto, min, max} 중 한 가지를 작성한다. monitor의 성능 지표에 따라 좋은 경우를 선택한다.  \n",
    "  *monitor의 성능 지표가 감소해야 좋은 경우 min, 증가해야 좋은 경우 max, monitor의 이름으로부터 자동으로 유추하고 싶다면 auto를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0f6ff70-4e60-46a4-b180-1f16a984be0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer, Input, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "INPUT_SIZE = 28\n",
    "\n",
    "def create_model():\n",
    "    input_tensor = Input(shape=(INPUT_SIZE, INPUT_SIZE))\n",
    "    x = Flatten()(input_tensor)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    output = Dense(10, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=input_tensor, outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d284b08c-46f8-4ee5-a005-28aa0cf75071",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# 전처리\n",
    "\n",
    "# 255 색상 minmax scale\n",
    "def get_preprocessed_data(images, targets):\n",
    "    images = np.array(images / 255.0, dtype = np.float32)\n",
    "    targets = np.array(targets, dtype = np.float32)\n",
    "\n",
    "    return images, targets\n",
    "\n",
    "# 원핫 인코딩\n",
    "def get_preprocessed_ohe(images, targets):\n",
    "    images, targets = get_preprocessed_data(images, targets)\n",
    "    oh_targets = to_categorical(targets)\n",
    "\n",
    "    return images, oh_targets\n",
    "\n",
    "def get_train_valid_test(train_images, train_targets, test_images, test_targets, validation_size=0.2, random_state=124):\n",
    "    train_images, train_oh_targets= get_preprocessed_ohe(train_images, train_targets)\n",
    "    test_images, test_oh_targets = get_preprocessed_ohe(test_images, test_targets)\n",
    "\n",
    "    train_images, validation_images, train_oh_targets, validation_oh_targets =\\\n",
    "    train_test_split(train_images, train_oh_targets, stratify=train_oh_targets, test_size=validation_size, random_state=random_state)\n",
    "\n",
    "    return (train_images, train_oh_targets), (validation_images, validation_oh_targets), (test_images, test_oh_targets)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b7bcbf5-d6e8-4825-9198-e61e1c39b535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 28, 28) (48000, 10)\n",
      "(12000, 28, 28) (12000, 10)\n",
      "(10000, 28, 28) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "(train_images, train_targets), (test_images, test_targets) = fashion_mnist.load_data()\n",
    "\n",
    "(train_images, train_oh_targets), (validation_images, validation_oh_targets), (test_images, test_oh_targets) = \\\n",
    "get_train_valid_test(train_images, train_targets, test_images, test_targets)\n",
    "\n",
    "print(train_images.shape, train_oh_targets.shape)\n",
    "print(validation_images.shape, validation_oh_targets.shape)\n",
    "print(test_images.shape, test_oh_targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10dc9711-7abe-4282-9e5b-a1b69fe0ef91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0B\tcallback_files\n"
     ]
    }
   ],
   "source": [
    "# !ls callback_files\n",
    "!du -sh callback_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105018b9-9bd0-48bb-9b44-7c331888338c",
   "metadata": {},
   "source": [
    "# ModelCheckPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ccdede11-f1b5-461b-a937-ae0155f640d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 828us/step - acc: 0.7377 - loss: 0.7598 - val_acc: 0.8460 - val_loss: 0.4254\n",
      "Epoch 2/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 794us/step - acc: 0.8529 - loss: 0.4089 - val_acc: 0.8525 - val_loss: 0.3911\n",
      "Epoch 3/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 795us/step - acc: 0.8696 - loss: 0.3582 - val_acc: 0.8694 - val_loss: 0.3574\n",
      "Epoch 4/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 761us/step - acc: 0.8758 - loss: 0.3340 - val_acc: 0.8691 - val_loss: 0.3599\n",
      "Epoch 5/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 786us/step - acc: 0.8852 - loss: 0.3142 - val_acc: 0.8728 - val_loss: 0.3404\n",
      "Epoch 6/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 780us/step - acc: 0.8917 - loss: 0.2937 - val_acc: 0.8735 - val_loss: 0.3451\n",
      "Epoch 7/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 783us/step - acc: 0.8972 - loss: 0.2797 - val_acc: 0.8687 - val_loss: 0.3463\n",
      "Epoch 8/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 751us/step - acc: 0.8993 - loss: 0.2713 - val_acc: 0.8745 - val_loss: 0.3391\n",
      "Epoch 9/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 865us/step - acc: 0.9029 - loss: 0.2577 - val_acc: 0.8864 - val_loss: 0.3164\n",
      "Epoch 10/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 815us/step - acc: 0.9057 - loss: 0.2485 - val_acc: 0.8798 - val_loss: 0.3378\n",
      "Epoch 11/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 902us/step - acc: 0.9098 - loss: 0.2413 - val_acc: 0.8861 - val_loss: 0.3144\n",
      "Epoch 12/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 721us/step - acc: 0.9143 - loss: 0.2345 - val_acc: 0.8857 - val_loss: 0.3184\n",
      "Epoch 13/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 703us/step - acc: 0.9180 - loss: 0.2219 - val_acc: 0.8877 - val_loss: 0.3176\n",
      "Epoch 14/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 782us/step - acc: 0.9190 - loss: 0.2163 - val_acc: 0.8894 - val_loss: 0.3245\n",
      "Epoch 15/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 705us/step - acc: 0.9215 - loss: 0.2097 - val_acc: 0.8827 - val_loss: 0.3336\n",
      "Epoch 16/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 719us/step - acc: 0.9215 - loss: 0.2073 - val_acc: 0.8729 - val_loss: 0.3870\n",
      "Epoch 17/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 716us/step - acc: 0.9234 - loss: 0.2017 - val_acc: 0.8876 - val_loss: 0.3280\n",
      "Epoch 18/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 715us/step - acc: 0.9287 - loss: 0.1900 - val_acc: 0.8896 - val_loss: 0.3288\n",
      "Epoch 19/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 794us/step - acc: 0.9299 - loss: 0.1856 - val_acc: 0.8905 - val_loss: 0.3282\n",
      "Epoch 20/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 722us/step - acc: 0.9318 - loss: 0.1818 - val_acc: 0.8889 - val_loss: 0.3434\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model = create_model()\n",
    "model.compile(optimizer=Adam(), loss=CategoricalCrossentropy(), metrics=['acc'])\n",
    "\n",
    "mcp_cb = ModelCheckpoint(\n",
    "    filepath=\"./callback_files/weights.{epoch:03d}-{val_loss:.4f}-{acc:.4f}.weights.h5\",\n",
    "    monitor='val_loss',\n",
    "    # 모든 epoch의 파일을 저장하지 않고 좋은 성능이라 판단될 경우만 저장할 때 True설정\n",
    "    save_best_only=False,\n",
    "    save_weights_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "# mcp_cb = ModelCheckpoint(\n",
    "#     filepath=\"./callback_files/model.{epoch:03d}-{val_loss:.4f}-{acc:.4f}.model.keras\",\n",
    "#     monitor='val_loss',\n",
    "#     # 모든 epoch의 파일을 저장\n",
    "#     save_best_only=False,\n",
    "#     save_weights_only=False,\n",
    "#     mode='min'\n",
    "# )\n",
    "\n",
    "history = model.fit(x=train_images, y=train_oh_targets, validation_data=(validation_images, validation_oh_targets), batch_size=64, epochs=20, callbacks=[mcp_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6630a37a-49ca-45ac-91b1-dd8bfad2d322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.001-0.4776-0.8046.model.keras  weights.006-0.3404-0.8927.weights.h5\n",
      "model.002-0.3782-0.8589.model.keras  weights.006-0.3451-0.8915.weights.h5\n",
      "model.003-0.3573-0.8709.model.keras  weights.007-0.3217-0.8956.weights.h5\n",
      "model.004-0.3578-0.8792.model.keras  weights.007-0.3463-0.8958.weights.h5\n",
      "model.005-0.3657-0.8867.model.keras  weights.008-0.3342-0.8986.weights.h5\n",
      "model.006-0.3250-0.8924.model.keras  weights.008-0.3391-0.9000.weights.h5\n",
      "model.007-0.3305-0.8943.model.keras  weights.009-0.3164-0.9019.weights.h5\n",
      "model.008-0.3318-0.8989.model.keras  weights.009-0.3182-0.9028.weights.h5\n",
      "model.009-0.3243-0.9010.model.keras  weights.010-0.3277-0.9045.weights.h5\n",
      "model.010-0.3160-0.9055.model.keras  weights.010-0.3378-0.9051.weights.h5\n",
      "model.011-0.3270-0.9081.model.keras  weights.011-0.3129-0.9098.weights.h5\n",
      "model.012-0.3285-0.9103.model.keras  weights.011-0.3144-0.9094.weights.h5\n",
      "model.013-0.3281-0.9139.model.keras  weights.012-0.3184-0.9132.weights.h5\n",
      "model.014-0.3277-0.9160.model.keras  weights.012-0.3246-0.9113.weights.h5\n",
      "model.015-0.3237-0.9180.model.keras  weights.013-0.3176-0.9143.weights.h5\n",
      "model.016-0.3215-0.9210.model.keras  weights.013-0.3250-0.9147.weights.h5\n",
      "model.017-0.3452-0.9236.model.keras  weights.014-0.3179-0.9179.weights.h5\n",
      "model.018-0.3443-0.9241.model.keras  weights.014-0.3245-0.9166.weights.h5\n",
      "model.019-0.3347-0.9268.model.keras  weights.015-0.3262-0.9196.weights.h5\n",
      "model.020-0.3346-0.9290.model.keras  weights.015-0.3336-0.9197.weights.h5\n",
      "weights.001-0.4209-0.8079.weights.h5 weights.016-0.3376-0.9216.weights.h5\n",
      "weights.001-0.4254-0.8059.weights.h5 weights.016-0.3870-0.9212.weights.h5\n",
      "weights.002-0.3911-0.8553.weights.h5 weights.017-0.3192-0.9240.weights.h5\n",
      "weights.002-0.3954-0.8584.weights.h5 weights.017-0.3280-0.9229.weights.h5\n",
      "weights.003-0.3479-0.8719.weights.h5 weights.018-0.3288-0.9248.weights.h5\n",
      "weights.003-0.3574-0.8708.weights.h5 weights.018-0.3317-0.9274.weights.h5\n",
      "weights.004-0.3599-0.8788.weights.h5 weights.019-0.3163-0.9286.weights.h5\n",
      "weights.004-0.3695-0.8816.weights.h5 weights.019-0.3282-0.9285.weights.h5\n",
      "weights.005-0.3384-0.8859.weights.h5 weights.020-0.3386-0.9302.weights.h5\n",
      "weights.005-0.3404-0.8852.weights.h5 weights.020-0.3434-0.9303.weights.h5\n"
     ]
    }
   ],
   "source": [
    "!ls callback_files\n",
    "# !du -sh callback_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06dadbde-2d3f-4296-953e-c85500e32d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322us/step - acc: 0.8838 - loss: 0.3760\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.377580463886261, 0.8830000162124634]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_images, test_oh_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e0f4872-7159-4c71-a7bc-8814c83a61a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296us/step - acc: 0.8838 - loss: 0.3760\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.377580463886261, 0.8830000162124634]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.load_weights('./callback_files/weights.020-0.3434-0.9303.weights.h5')\n",
    "\n",
    "model.compile(optimizer=Adam(), loss=CategoricalCrossentropy(), metrics=['acc'])\n",
    "model.evaluate(test_images, test_oh_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1e87e31-130a-480b-8c2d-8941b2a3532c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298us/step - acc: 0.8840 - loss: 0.3692\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3576537072658539, 0.8859000205993652]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model('./callback_files/model.020-0.3346-0.9290.model.keras')\n",
    "model.evaluate(test_images, test_oh_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429ac5b7-26af-42c9-8e88-702db3cd467a",
   "metadata": {},
   "source": [
    "# ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d0f1af0-0bd2-4367-ad99-65de8ba93db8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 906us/step - acc: 0.7380 - loss: 0.7534 - val_acc: 0.8522 - val_loss: 0.4091 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 760us/step - acc: 0.8538 - loss: 0.4103 - val_acc: 0.8609 - val_loss: 0.3802 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 870us/step - acc: 0.8673 - loss: 0.3626 - val_acc: 0.8652 - val_loss: 0.3570 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 815us/step - acc: 0.8786 - loss: 0.3340 - val_acc: 0.8608 - val_loss: 0.3827 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 788us/step - acc: 0.8845 - loss: 0.3131 - val_acc: 0.8767 - val_loss: 0.3335 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 757us/step - acc: 0.8931 - loss: 0.2928 - val_acc: 0.8763 - val_loss: 0.3256 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 963us/step - acc: 0.8949 - loss: 0.2907 - val_acc: 0.8767 - val_loss: 0.3276 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 829us/step - acc: 0.8981 - loss: 0.2781 - val_acc: 0.8841 - val_loss: 0.3150 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 930us/step - acc: 0.9017 - loss: 0.2640 - val_acc: 0.8819 - val_loss: 0.3179 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 831us/step - acc: 0.9058 - loss: 0.2499 - val_acc: 0.8756 - val_loss: 0.3303 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 706us/step - acc: 0.9203 - loss: 0.2173 - val_acc: 0.8933 - val_loss: 0.2915 - learning_rate: 1.0000e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 725us/step - acc: 0.9261 - loss: 0.2019 - val_acc: 0.8932 - val_loss: 0.2906 - learning_rate: 1.0000e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 745us/step - acc: 0.9253 - loss: 0.2020 - val_acc: 0.8936 - val_loss: 0.2902 - learning_rate: 1.0000e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 755us/step - acc: 0.9236 - loss: 0.2076 - val_acc: 0.8948 - val_loss: 0.2913 - learning_rate: 1.0000e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 713us/step - acc: 0.9242 - loss: 0.2009 - val_acc: 0.8946 - val_loss: 0.2892 - learning_rate: 1.0000e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 759us/step - acc: 0.9289 - loss: 0.1914 - val_acc: 0.8946 - val_loss: 0.2915 - learning_rate: 1.0000e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 769us/step - acc: 0.9293 - loss: 0.1904 - val_acc: 0.8948 - val_loss: 0.2904 - learning_rate: 1.0000e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 758us/step - acc: 0.9307 - loss: 0.1902 - val_acc: 0.8953 - val_loss: 0.2888 - learning_rate: 1.0000e-05\n",
      "Epoch 19/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 743us/step - acc: 0.9322 - loss: 0.1878 - val_acc: 0.8950 - val_loss: 0.2896 - learning_rate: 1.0000e-05\n",
      "Epoch 20/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 749us/step - acc: 0.9304 - loss: 0.1886 - val_acc: 0.8954 - val_loss: 0.2892 - learning_rate: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "model = create_model()\n",
    "model.compile(optimizer=Adam(), loss=CategoricalCrossentropy(), metrics=['acc'])\n",
    "\n",
    "\n",
    "# ReduceLROnPlateau 콜백 정의\n",
    "rlr_cb = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.1,\n",
    "    patience=2,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "history = model.fit(x=train_images, y=train_oh_targets, validation_data=(validation_images, validation_oh_targets), batch_size=64, epochs=20, callbacks=[rlr_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01aaec6e-2004-41b6-bbf2-b9da1cb199f3",
   "metadata": {},
   "source": [
    "# EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73da24c3-f587-40ac-983d-6372a2dc8e56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 857us/step - acc: 0.7320 - loss: 0.7792 - val_acc: 0.8451 - val_loss: 0.4253\n",
      "Epoch 2/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 748us/step - acc: 0.8564 - loss: 0.3987 - val_acc: 0.8656 - val_loss: 0.3652\n",
      "Epoch 3/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 849us/step - acc: 0.8721 - loss: 0.3481 - val_acc: 0.8685 - val_loss: 0.3560\n",
      "Epoch 4/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 702us/step - acc: 0.8796 - loss: 0.3288 - val_acc: 0.8646 - val_loss: 0.3589\n",
      "Epoch 5/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 697us/step - acc: 0.8851 - loss: 0.3112 - val_acc: 0.8702 - val_loss: 0.3530\n",
      "Epoch 6/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 704us/step - acc: 0.8937 - loss: 0.2899 - val_acc: 0.8815 - val_loss: 0.3278\n",
      "Epoch 7/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 707us/step - acc: 0.8961 - loss: 0.2838 - val_acc: 0.8781 - val_loss: 0.3380\n",
      "Epoch 8/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 713us/step - acc: 0.8990 - loss: 0.2720 - val_acc: 0.8832 - val_loss: 0.3269\n",
      "Epoch 9/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 704us/step - acc: 0.9031 - loss: 0.2622 - val_acc: 0.8835 - val_loss: 0.3215\n",
      "Epoch 10/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 705us/step - acc: 0.9048 - loss: 0.2550 - val_acc: 0.8780 - val_loss: 0.3382\n",
      "Epoch 11/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 758us/step - acc: 0.9081 - loss: 0.2462 - val_acc: 0.8841 - val_loss: 0.3369\n",
      "Epoch 12/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 800us/step - acc: 0.9124 - loss: 0.2351 - val_acc: 0.8861 - val_loss: 0.3233\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "model = create_model()\n",
    "model.compile(optimizer=Adam(), loss=CategoricalCrossentropy(), metrics=['acc'])\n",
    "\n",
    "\n",
    "# EarlyStopping 콜백 정의\n",
    "ely_cb = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "history = model.fit(x=train_images, y=train_oh_targets, validation_data=(validation_images, validation_oh_targets), batch_size=64, epochs=20, callbacks=[ely_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d26dab-c420-4893-8923-dfc4fb8f256e",
   "metadata": {},
   "source": [
    "# 3개 전부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c380a358-675d-4a5b-85af-f5687ff776c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 847us/step - acc: 0.7428 - loss: 0.7482 - val_acc: 0.8481 - val_loss: 0.4186 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 874us/step - acc: 0.8584 - loss: 0.3937 - val_acc: 0.8608 - val_loss: 0.3727 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 730us/step - acc: 0.8742 - loss: 0.3476 - val_acc: 0.8702 - val_loss: 0.3514 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 820us/step - acc: 0.8833 - loss: 0.3222 - val_acc: 0.8768 - val_loss: 0.3487 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 875us/step - acc: 0.8862 - loss: 0.3036 - val_acc: 0.8760 - val_loss: 0.3408 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 779us/step - acc: 0.8933 - loss: 0.2912 - val_acc: 0.8789 - val_loss: 0.3235 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 815us/step - acc: 0.8978 - loss: 0.2795 - val_acc: 0.8789 - val_loss: 0.3271 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 765us/step - acc: 0.9010 - loss: 0.2664 - val_acc: 0.8767 - val_loss: 0.3452 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 810us/step - acc: 0.9158 - loss: 0.2277 - val_acc: 0.8907 - val_loss: 0.2909 - learning_rate: 1.0000e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 810us/step - acc: 0.9178 - loss: 0.2209 - val_acc: 0.8936 - val_loss: 0.2897 - learning_rate: 1.0000e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 716us/step - acc: 0.9210 - loss: 0.2141 - val_acc: 0.8941 - val_loss: 0.2913 - learning_rate: 1.0000e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 734us/step - acc: 0.9200 - loss: 0.2162 - val_acc: 0.8924 - val_loss: 0.2911 - learning_rate: 1.0000e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 732us/step - acc: 0.9230 - loss: 0.2088 - val_acc: 0.8939 - val_loss: 0.2883 - learning_rate: 1.0000e-05\n",
      "Epoch 14/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 744us/step - acc: 0.9228 - loss: 0.2117 - val_acc: 0.8938 - val_loss: 0.2879 - learning_rate: 1.0000e-05\n",
      "Epoch 15/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 824us/step - acc: 0.9227 - loss: 0.2067 - val_acc: 0.8945 - val_loss: 0.2883 - learning_rate: 1.0000e-05\n",
      "Epoch 16/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 751us/step - acc: 0.9246 - loss: 0.2073 - val_acc: 0.8940 - val_loss: 0.2879 - learning_rate: 1.0000e-05\n",
      "Epoch 17/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 742us/step - acc: 0.9257 - loss: 0.2038 - val_acc: 0.8941 - val_loss: 0.2878 - learning_rate: 1.0000e-06\n",
      "Epoch 18/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 746us/step - acc: 0.9248 - loss: 0.2055 - val_acc: 0.8938 - val_loss: 0.2878 - learning_rate: 1.0000e-06\n",
      "Epoch 19/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 779us/step - acc: 0.9251 - loss: 0.2056 - val_acc: 0.8937 - val_loss: 0.2878 - learning_rate: 1.0000e-06\n",
      "Epoch 20/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 730us/step - acc: 0.9243 - loss: 0.2056 - val_acc: 0.8938 - val_loss: 0.2878 - learning_rate: 1.0000e-07\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model = create_model()\n",
    "model.compile(optimizer=Adam(), loss=CategoricalCrossentropy(), metrics=['acc'])\n",
    "\n",
    "mcp_cb = ModelCheckpoint(\n",
    "    filepath=\"./callback_files/weights.{epoch:03d}-{val_loss:.4f}-{acc:.4f}.weights.h5\",\n",
    "    monitor='val_loss',\n",
    "    # 모든 epoch의 파일을 저장하지 않고 좋은 성능이라 판단될 경우만 저장할 때 True설정\n",
    "    save_best_only=False,\n",
    "    save_weights_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "rlr_cb = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.1,\n",
    "    patience=2,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "ely_cb = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "history = model.fit(x=train_images, y=train_oh_targets, validation_data=(validation_images, validation_oh_targets), batch_size=64, epochs=20, callbacks=[mcp_cb, rlr_cb, ely_cb])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
