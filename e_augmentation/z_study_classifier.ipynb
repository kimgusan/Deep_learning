{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac6b4930-ea03-4b96-9182-301b3d809b73",
   "metadata": {},
   "source": [
    "# 새와 드론 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cd9524a-6c96-4a7c-a17c-20a938495d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "def transform(image):\n",
    "    aug = A.Compose([\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.OneOf([\n",
    "            A.ColorJitter(p=0.5),\n",
    "            A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5) \n",
    "        ], p=1)        \n",
    "    ], p=0.5)\n",
    "\n",
    "    return aug(image=image)['image']\n",
    "\n",
    "idg = ImageDataGenerator(preprocessing_function=transform, rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe009ac-3fa6-4fc6-bb9d-58232ae47334",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "IMAGE_SIZE = 244\n",
    "\n",
    "train_dir = './datasets/b_d_classifier/test/'\n",
    "validation_dir = './datasets/b_d_classifier/validation/'\n",
    "test_dir = './datasets/b_d_classifier/test'\n",
    "\n",
    "train_data_generator = idg\n",
    "validation_data_generator = ImageDataGenerator(rescale=1./255)\n",
    "test_data_generator = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# 과적합 발생 시 batch size를 낮추고 과소적합 발생시 batch size를 높인다. 단, 비율에 따라서 조절할 것.\n",
    "train_generator = train_data_generator.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "validation_generator = validation_data_generator.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "test_generator = test_data_generator.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "print(train_generator.class_indices)\n",
    "print(validation_generator.class_indices)\n",
    "print(test_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e34333a-d2b8-4e68-952b-8d0056dab747",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(cv2\u001b[38;5;241m.\u001b[39mimread(train_generator\u001b[38;5;241m.\u001b[39mfilepaths[\u001b[38;5;241m10\u001b[39m]), cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshow_image\u001b[39m(image):\n\u001b[1;32m      7\u001b[0m     plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m4\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_generator' is not defined"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image = cv2.cvtColor(cv2.imread(train_generator.filepaths[10]), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "def show_image(image):\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "\n",
    "show_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d34c2f-bfc9-4b99-9e0d-050c83147dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense , Conv2D , Dropout , Flatten , Activation, MaxPooling2D , GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam \n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau , EarlyStopping , ModelCheckpoint\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "\n",
    "IMAGE_SIZE = 244\n",
    "\n",
    "input_tensor = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "\n",
    "x = Conv2D(filters=64, kernel_size=3, strides=1, padding='same', kernel_initializer='he_normal')(input_tensor)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D()(x)\n",
    "\n",
    "x = Conv2D(filters=128, kernel_size=3, strides=1, padding='same', kernel_initializer='he_normal')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Conv2D(filters=128, kernel_size=3, strides=1, padding='same', kernel_initializer='he_normal')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D()(x)\n",
    "\n",
    "x = Conv2D(filters=256, kernel_size=3, strides=2, padding='same', kernel_initializer='he_normal')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# x = Dropout(rate=0.5)(x)\n",
    "x = Dense(100, activation='relu')(x)\n",
    "x = Dense(50, activation='relu')(x)\n",
    "output = Dense(1, activation='softmax', kernel_initializer='glorot_normal')(x)\n",
    "\n",
    "model = Model(inputs=input_tensor, outputs=output)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae96bd3-59d9-4275-a224-62e305fa99c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy, CategoricalCrossentropy\n",
    "\n",
    "model.compile(optimizer=Adam(), loss=BinaryCrossentropy(), metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40013bc3-34d4-451e-927e-96f2528ff07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcp_cb = ModelCheckpoint(\n",
    "    filepath='./callback_files/weights.{epoch:03d}-{val_loss:.4f}-{acc:.4f}.weights.h5',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    mode='auto'\n",
    ")\n",
    "\n",
    "rlr_cb = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.1,\n",
    "    patience=4,\n",
    "    mode='min',\n",
    "    verbose= 1\n",
    ")\n",
    "\n",
    "ely_cb = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    mode='min',\n",
    "    verbose= 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a593ff08-69f5-4f09-8177-8effe30f40ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_generator,\n",
    "                    batch_size=32,\n",
    "                    epochs=20,\n",
    "                    validation_data=validation_generator,\n",
    "                    callbacks = [mcp_cb, rlr_cb]\n",
    "                    # callbacks = [rlr_cb]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83747eb9-aac3-4521-9c6f-1daccc850a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_generator, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cda0e0-2477-48e1-8797-99c3cb0a9945",
   "metadata": {},
   "source": [
    "# 예측을 하지 못한다고 판단하여 추가 층 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f251b6-ec78-40cf-8681-02ccc556da13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense , Conv2D , Dropout , Flatten , Activation, MaxPooling2D , GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam \n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau , EarlyStopping , ModelCheckpoint\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "\n",
    "IMAGE_SIZE = 244\n",
    "\n",
    "input_tensor = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "\n",
    "x = Conv2D(filters=64, kernel_size=3, strides=1, kernel_initializer='he_normal')(input_tensor)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Conv2D(filters=64, kernel_size=3, strides=1, kernel_initializer='he_normal')(input_tensor)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Conv2D(filters=128, kernel_size=3, strides=1, kernel_initializer='he_normal')(input_tensor)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(2)(x)\n",
    "\n",
    "x = Conv2D(filters=128, kernel_size=3, strides=1, kernel_initializer='he_normal')(input_tensor)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Conv2D(filters=128, kernel_size=3, strides=2, kernel_initializer='he_normal')(input_tensor)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Conv2D(filters=256, kernel_size=3, strides=1, padding='same', kernel_initializer='he_normal')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Conv2D(filters=256, kernel_size=3, strides=1, padding='same', kernel_initializer='he_normal')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Conv2D(filters=256, kernel_size=3, strides=1, padding='same', kernel_initializer='he_normal')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(2)(x)\n",
    "\n",
    "x = Conv2D(filters=512, kernel_size=3, strides=1, padding='same', kernel_initializer='he_normal')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Conv2D(filters=512, kernel_size=3, strides=1, padding='same', kernel_initializer='he_normal')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Conv2D(filters=512, kernel_size=3, strides=1, padding='same', kernel_initializer='he_normal')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1000, activation='relu')(x)\n",
    "x = Dropout(rate=0.4)(x)\n",
    "output = Dense(1, activation='softmax', kernel_initializer='glorot_normal')(x)\n",
    "\n",
    "model = Model(inputs=input_tensor, outputs=output)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff2a608-56a5-4a18-b67e-2431fe8158e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy, CategoricalCrossentropy\n",
    "\n",
    "model.compile(optimizer=Adam(), loss=BinaryCrossentropy(), metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f7e3c7-5d07-47bb-996e-5606ad45d5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcp_cb = ModelCheckpoint(\n",
    "    filepath='./callback_files/weights.{epoch:03d}-{val_loss:.4f}-{acc:.4f}.weights.h5',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    mode='auto'\n",
    ")\n",
    "\n",
    "rlr_cb = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.1,\n",
    "    patience=4,\n",
    "    mode='min',\n",
    "    verbose= 1\n",
    ")\n",
    "\n",
    "ely_cb = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    mode='min',\n",
    "    verbose= 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f780cf1-d5ab-4d20-be48-32874f4ee112",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_generator,\n",
    "                    batch_size=32,\n",
    "                    epochs=10,\n",
    "                    validation_data=validation_generator,\n",
    "                    callbacks = [mcp_cb, rlr_cb]\n",
    "                    # callbacks = [rlr_cb]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384f01cd-a074-438e-a1c3-23128e95c6f8",
   "metadata": {},
   "source": [
    "## 사전 훈련 모델을 사용하여 추가 훈련 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcde9335-c0cb-4eb5-9838-d0290f20fe06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "train_root = './datasets/b_d_classifier/train'\n",
    "validation_root= './datasets/b_d_classifier/validation/'\n",
    "test_root = './datasets/b_d_classifier/test'\n",
    "\n",
    "directories = glob(os.path.join(root, '*'))\n",
    "directory_names = []\n",
    "for directory in directories:\n",
    "    directory_names.append(os.path.basename(directory))\n",
    "\n",
    "print(directory_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64641b0e-88f5-443a-a560-14c6044ba68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "\n",
    "def get_file_paths_and_targets(root_dir):\n",
    "    directories = glob(os.path.join(root_dir, '*'))\n",
    "    file_paths = []\n",
    "    targets = []\n",
    "    for directory in directories:\n",
    "        label = os.path.basename(directory)\n",
    "        files = glob(os.path.join(directory, '*'))\n",
    "        file_paths.extend(files)\n",
    "        targets.extend([label] * len(files))\n",
    "    return file_paths, targets\n",
    "\n",
    "# 각 폴더에서 파일 경로와 타겟 가져오기\n",
    "train_file_paths, train_targets = get_file_paths_and_targets(train_root)\n",
    "validation_file_paths, validation_targets = get_file_paths_and_targets(validation_root)\n",
    "test_file_paths, test_targets = get_file_paths_and_targets(test_root)\n",
    "\n",
    "# 모든 파일 경로와 타겟을 하나로 합치기\n",
    "all_file_paths = train_file_paths + validation_file_paths + test_file_paths\n",
    "all_targets = train_targets + validation_targets + test_targets\n",
    "\n",
    "# 데이터프레임으로 변환\n",
    "bd_df = pd.DataFrame({\n",
    "    'file_paths': all_file_paths,\n",
    "    'targets': all_targets\n",
    "})\n",
    "\n",
    "bd_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8f95ed-260c-4cde-875d-b78712339a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_images, test_images, train_targets, test_targets = \\\n",
    "train_test_split(bd_df.file_paths, \n",
    "                 bd_df.targets, \n",
    "                 stratify=bd_df.targets, \n",
    "                 test_size=0.2, random_state=124)\n",
    "\n",
    "print(train_targets.value_counts())\n",
    "print(test_targets.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec0fa6c-7808-4aad-9414-6a6a01bcc6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_images, validation_images, train_targets, validation_targets = \\\n",
    "train_test_split(train_images, \n",
    "                 train_targets, \n",
    "                 stratify=train_targets, \n",
    "                 test_size=0.2, random_state=124)\n",
    "\n",
    "print(train_targets.value_counts())\n",
    "print(validation_targets.value_counts())\n",
    "print(test_targets.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943c11c1-cc97-4a8c-beff-e7f2fc88dbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = bd_df.iloc[train_images.index].reset_index(drop=True)\n",
    "validation_df = bd_df.iloc[validation_images.index].reset_index(drop=True)\n",
    "test_df = bd_df.iloc[test_images.index].reset_index(drop=True)\n",
    "\n",
    "print(train_df.shape)\n",
    "print(validation_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f044c70-9cd6-4a32-8e15-c530832ce33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from sklearn.utils import shuffle\n",
    "import cv2\n",
    "\n",
    "IMAGE_SIZE = 64\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "class Dataset(Sequence):\n",
    "    def __init__(self, file_paths, targets, batch_size=BATCH_SIZE, aug=None, preprocess=None, shuffle=False):\n",
    "        self.file_paths = file_paths\n",
    "        self.targets = targets\n",
    "        self.batch_size = batch_size\n",
    "        self.aug = aug\n",
    "        self.preprocess = preprocess\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "        if self.shuffle:\n",
    "            # 에포크 종료 시, 객체 생성 및 데이터 섞기\n",
    "            self.on_epoch_end()\n",
    "\n",
    "    # __len__()는 전체 데이터 건수에서 batch_size 단위로 나눈 데이터 수\n",
    "    # 예를 들어, 1000개의 데이터를 30 batch_size로 설정하면, 1 batch당 33.33..개이다.\n",
    "    # 이 때, 소수점은 무조건 올려서 33 + 1 = 34개로 설정한다.\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.targets) / self.batch_size))\n",
    "\n",
    "    # batch_size 단위로 이미지 배열과 타켓 데이터들을 가져온 뒤 변환한 값을 리턴한다.\n",
    "    def __getitem__(self, index):\n",
    "        file_paths_batch = self.file_paths[index * self.batch_size: (index + 1) * self.batch_size]\n",
    "        targets_batch = self.targets[index * self.batch_size: (index + 1) * self.batch_size]\n",
    "\n",
    "        results_batch = np.zeros((file_paths_batch.shape[0], IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "\n",
    "        for i in range(file_paths_batch.shape[0]):\n",
    "            image = cv2.cvtColor(cv2.imread(file_paths_batch[i]), cv2.COLOR_BGR2RGB)\n",
    "            image = cv2.resize(image, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "\n",
    "            if self.aug is not None:\n",
    "                image = self.aug(image=image)['image']\n",
    "\n",
    "            if self.preprocess is not None:\n",
    "                image = self.preprocess(image)\n",
    "                    \n",
    "            results_batch[i] = image\n",
    "\n",
    "        return results_batch, targets_batch\n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            self.file_paths, self.targets = shuffle(self.file_paths, self.targets)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec1ec3c-71fd-492d-b576-95200c803ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from tensorflow.keras.applications.xception import preprocess_input as xception_preprocess_input\n",
    "\n",
    "train_file_paths = train_df['file_paths'].values\n",
    "# train_targets = train_df['targets'].values # SparseCategoricalCrossEntropy\n",
    "train_targets = pd.get_dummies(train_df['targets']).values # CategoricalCrossEntropy\n",
    "\n",
    "validation_file_paths = validation_df['file_paths'].values\n",
    "# validation_targets = validation_df['targets'].values # SparseCategoricalCrossEntropy\n",
    "validation_targets = pd.get_dummies(validation_df['targets']).values # CategoricalCrossEntropy\n",
    "\n",
    "test_file_paths = test_df['file_paths'].values\n",
    "# test_targets = test_df['targets'].values # SparseCategoricalCrossEntropy\n",
    "test_targets = pd.get_dummies(test_df['targets']).values # CategoricalCrossEntropy\n",
    "\n",
    "aug = A.Compose([\n",
    "    A.ShiftScaleRotate(p=0.5),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0, p=0.5)\n",
    "])\n",
    "\n",
    "train_dataset = Dataset(train_file_paths, \n",
    "                        train_targets, \n",
    "                        batch_size=BATCH_SIZE, \n",
    "                        aug=aug, \n",
    "                        preprocess=xception_preprocess_input, \n",
    "                        shuffle=True)\n",
    "\n",
    "validation_dataset = Dataset(validation_file_paths, \n",
    "                        validation_targets, \n",
    "                        batch_size=BATCH_SIZE, \n",
    "                        preprocess=xception_preprocess_input)\n",
    "\n",
    "test_dataset = Dataset(test_file_paths, \n",
    "                        test_targets, \n",
    "                        batch_size=BATCH_SIZE, \n",
    "                        preprocess=xception_preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858cd2d7-61d7-45e8-9b6d-027ff25f192c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense , Conv2D , Dropout , Flatten , Activation, MaxPooling2D , GlobalAveragePooling2D, BatchNormalization\n",
    "\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications import ResNet50V2\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "\n",
    "\n",
    "def create_model(model_name='vgg16', verbose=False):\n",
    "    input_tensor = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "    if model_name == 'vgg16':\n",
    "        model = VGG16(input_tensor=input_tensor, include_top=False, weights='imagenet')\n",
    "    elif model_name == 'resnet50': # ResNet50, 74.9% ; ResNet50V2, 76.0%\n",
    "        model = ResNet50V2(input_tensor=input_tensor, include_top=False, weights='imagenet')\n",
    "    elif model_name == 'xception': # Inception을 기초로 한 모델\n",
    "        model = Xception(input_tensor=input_tensor, include_top=False, weights='imagenet')\n",
    "    elif model_name == 'mobileneet': # 제한적인 장치에서 효과적인 모델\n",
    "        model = MobileNetV2(input_tensor=input_tensor, include_top=False, weights='imagenet')\n",
    "\n",
    "    x = model.output\n",
    "\n",
    "    # 분류기\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    if model_name != 'vgg16':\n",
    "        x = Dropout(rate=0.5)(x)\n",
    "    x = Dense(50, activation='relu')(x)\n",
    "    if model_name != 'vgg16':\n",
    "        x = Dropout(rate=0.5)(x)\n",
    "    output = Dense(1, activation='softmax', name='output')(x)\n",
    "    \n",
    "    model = Model(inputs=input_tensor, outputs=output)\n",
    "    \n",
    "    if verbose:\n",
    "        model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088bf617-7121-4dc4-a231-fc43f7634fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy, SparseCategoricalCrossentropy, binary_crossentropy\n",
    "\n",
    "model = create_model(model_name='mobileneet', verbose=True)\n",
    "# model.compile(optimizer=Adam(), loss=SparseCategoricalCrossentropy(), metrics=['acc'])\n",
    "model.compile(optimizer=Adam(), loss=binary_crossentropy(), metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4496e021-6880-4d4a-b648-5eaed9784536",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "mcp_cb = ModelCheckpoint(\n",
    "    filepath=\"./callback_files/weights.{epoch:03d}-{val_loss:.4f}-{acc:.4f}.weights.h5\",\n",
    "    monitor='val_loss',\n",
    "    save_best_only=False,\n",
    "    save_weights_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "rlr_cb = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.1,\n",
    "    patience=2,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "ely_cb = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=4,\n",
    "    mode='min'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b509540a-a86c-40e0-93fa-2d9f055b02e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "N_EPOCHS = 10\n",
    "\n",
    "history = model.fit(train_dataset,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=N_EPOCHS, \n",
    "                    validation_data=validation_dataset,\n",
    "                    callbacks=[mcp_cb, rlr_cb, ely_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a259fa-adc9-4207-8806-2d07e18d91b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8edefb-be0f-4849-9d54-e0b8aea85c67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36041924-d8b9-407a-9400-548a1cf3c625",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
