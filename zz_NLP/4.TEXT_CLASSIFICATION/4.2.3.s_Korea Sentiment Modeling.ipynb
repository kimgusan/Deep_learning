{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_IN_PATH = './data_in/'\n",
    "DATA_OUT_PATH = './data_out/'\n",
    "INPUT_TRAIN_DATA = 'nsmc_train_input.npy'\n",
    "LABEL_TRAIN_DATA = 'nsmc_train_label.npy'\n",
    "DATA_CONFIGS = 'data_configs.json'\n",
    "\n",
    "input_data = np.load(open(DATA_IN_PATH + INPUT_TRAIN_DATA, 'rb'))\n",
    "label_data = np.load(open(DATA_IN_PATH + LABEL_TRAIN_DATA, 'rb'))\n",
    "prepro_configs = json.load(open(DATA_IN_PATH + DATA_CONFIGS, 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SPLIT = 0.1\n",
    "RNG_SEED = 13371447\n",
    "VOCAB_SIZE = prepro_configs['vocab_size'] + 1\n",
    "EMB_SIZE = 128\n",
    "BATCH_SIZE=16\n",
    "NUM_EPOCHS = 1\n",
    "\n",
    "input_train, input_eval, label_train, label_eval = train_test_split(input_data, label_data, test_size=TEST_SPLIT, random_state=RNG_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_input_fn():\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((input_train, label_train))\n",
    "    dataset = dataset.shuffle(buffer_size=len(input_train))\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.repeat(count=NUM_EPOCHS)\n",
    "    return dataset\n",
    "\n",
    "def eval_input_fn():\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((input_eval, label_eval))\n",
    "    dataset = dataset.shuffle(buffer_size=len(input_eval))\n",
    "    dataset = dataset.batch(16)\n",
    "    dataset = dataset.repeat(count=NUM_EPOCHS)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "# 데이터셋 정의\n",
    "train_dataset = train_input_fn()\n",
    "eval_dataset = eval_input_fn()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def mapping_fn(X, Y):\n",
    "#     input, label = {'x': X}, Y\n",
    "#     return input, label\n",
    "\n",
    "# def train_input_fn():\n",
    "#     dataset = tf.data.Dataset.from_tensor_slices((input_train, label_train))\n",
    "#     dataset = dataset.shuffle(buffer_size=len(input_train))\n",
    "#     dataset = dataset.batch(BATCH_SIZE)\n",
    "#     dataset = dataset.repeat(count=NUM_EPOCHS)\n",
    "#     iterator = dataset.make_one_shot_iterator()\n",
    "    \n",
    "#     return iterator.get_next()\n",
    "\n",
    "# def eval_input_fn():\n",
    "#     dataset = tf.data.Dataset.from_tensor_slices((input_eval, label_eval))\n",
    "#     dataset = dataset.shuffle(buffer_size=len(input_eval))\n",
    "#     dataset = dataset.batch(16)\n",
    "#     iterator = dataset.make_one_shot_iterator()\n",
    "    \n",
    "#     return iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(vocab_size, emb_size):\n",
    "    # Input layer\n",
    "    inputs = tf.keras.Input(shape=(None, ), name = 'input_layer')\n",
    "\n",
    "    # Embedding layer\n",
    "    embedding_layer = tf.keras.layers.Embedding(vocab_size, emb_size)(inputs)\n",
    "    dropout_emb = tf.keras.layers.Dropout(0.2)(embedding_layer)\n",
    "\n",
    "    # Convolution layer\n",
    "    conv = tf.keras.layers.Conv1D(filters=32, kernel_size=3, padding='same', activation='relu')(dropout_emb)\n",
    "\n",
    "    # Global Max Poling layer\n",
    "    pool = tf.keras.layers.GlobalMaxPooling1D()(conv)\n",
    "\n",
    "    # Dense layer\n",
    "    hidden = tf.keras.layers.Dense(units=250, activation='relu')(pool)\n",
    "\n",
    "    #Dropout layer\n",
    "    dropout_hidden = tf.keras.layers.Dropout(0.2)(hidden)\n",
    "\n",
    "    # Output layer\n",
    "    logits = tf.keras.layers.Dense(units=1, activation='sigmoid')(dropout_hidden)\n",
    "\n",
    "    model = tf.keras.Model(inputs= inputs, outputs=logits)\n",
    "\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성\n",
    "model = create_model(VOCAB_SIZE, EMB_SIZE)\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(0.001), loss = tf.keras.losses.BinaryCrossentropy(from_logits=False), metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8438/8438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 16ms/step - acc: 0.7761 - loss: 0.4556 - val_acc: 0.8268 - val_loss: 0.3800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x321d33790>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 훈련\n",
    "model.fit(train_dataset, epochs= NUM_EPOCHS, validation_data= eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment started at 03:11:13\n",
      ".......................................\n",
      "\u001b[1m8438/8438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 16ms/step - acc: 0.8651 - loss: 0.3176 - val_acc: 0.8294 - val_loss: 0.3760\n",
      ".......................................\n",
      "Experiment finished at 03:13:26\n",
      "\n",
      "Experiment elapsed time: 133.027063 seconds\n"
     ]
    }
   ],
   "source": [
    "time_start = datetime.utcnow()\n",
    "print(\"Experiment started at {}\".format(time_start.strftime(\"%H:%M:%S\")))\n",
    "print(\".......................................\") \n",
    "\n",
    "model.fit(train_dataset, epochs= NUM_EPOCHS, validation_data= eval_dataset)\n",
    "\n",
    "time_end = datetime.utcnow()\n",
    "print(\".......................................\")\n",
    "print(\"Experiment finished at {}\".format(time_end.strftime(\"%H:%M:%S\")))\n",
    "print(\"\")\n",
    "time_elapsed = time_end - time_start\n",
    "print(\"Experiment elapsed time: {} seconds\".format(time_elapsed.total_seconds()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - acc: 0.8290 - loss: 0.3795\n"
     ]
    }
   ],
   "source": [
    "predict = model.evaluate(eval_dataset) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_TEST_DATA = 'nsmc_test_input.npy'\n",
    "LABEL_TEST_DATA = 'nsmc_test_label.npy'\n",
    "\n",
    "test_input_data = np.load(open(DATA_IN_PATH + INPUT_TEST_DATA, 'rb'))\n",
    "test_label_data = np.load(open(DATA_IN_PATH + LABEL_TEST_DATA, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_input_fn():\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((test_input_data, test_label_data))\n",
    "    dataset = dataset.batch(16)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "# 함수의 반환값을 전달해야 합니다.\n",
    "test_dataset = test_input_fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 320us/step - acc: 0.8323 - loss: 0.3750\n"
     ]
    }
   ],
   "source": [
    "predict = model.evaluate(test_dataset) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def model_fn(features, labels, mode, params):\n",
    "#     TRAIN = mode == tf.estimator.ModeKeys.TRAIN\n",
    "#     EVAL = mode == tf.estimator.ModeKeys.EVAL\n",
    "#     PREDICT = mode == tf.estimator.ModeKeys.PREDICT\n",
    "\n",
    "#     embedding_layer = tf.keras.layers.Embedding(\n",
    "#                     VOCAB_SIZE,\n",
    "#                     EMB_SIZE)(features['x'])\n",
    "\n",
    "#     dropout_emb = tf.keras.layers.Dropout(rate = 0.2)(embedding_layer)\n",
    "    \n",
    "#     conv = tf.keras.layers.Conv1D(\n",
    "#            filters=32,\n",
    "#            kernel_size=3,\n",
    "#            padding='same',\n",
    "#            activation=tf.nn.relu)(dropout_emb)\n",
    "  \n",
    "#     pool = tf.keras.layers.GlobalMaxPool1D()(conv)\n",
    "\n",
    "#     hidden = tf.keras.layers.Dense(units=250, activation=tf.nn.relu)(pool)   \n",
    "\n",
    "\n",
    "#     dropout_hidden = tf.keras.layers.Dropout(rate=0.2)(hidden, training = TRAIN)\n",
    "#     logits = tf.keras.layers.Dense(units=1)(dropout_hidden)\n",
    "\n",
    "#     if labels is not None:\n",
    "#         labels = tf.reshape(labels, [-1, 1])\n",
    "        \n",
    "#     if TRAIN:\n",
    "#         global_step = tf.train.get_global_step()\n",
    "#         loss = tf.losses.sigmoid_cross_entropy(labels, logits)\n",
    "#         train_op = tf.train.AdamOptimizer(0.001).minimize(loss, global_step)\n",
    "\n",
    "#         return tf.estimator.EstimatorSpec(mode=mode, train_op=train_op, loss = loss)\n",
    "    \n",
    "#     elif EVAL:\n",
    "#         loss = tf.losses.sigmoid_cross_entropy(labels, logits)\n",
    "#         pred = tf.nn.sigmoid(logits)\n",
    "#         accuracy = tf.metrics.accuracy(labels, tf.round(pred))\n",
    "#         return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops={'acc': accuracy})\n",
    "        \n",
    "#     elif PREDICT:\n",
    "#         return tf.estimator.EstimatorSpec(\n",
    "#             mode=mode,\n",
    "#             predictions={\n",
    "#                 'prob': tf.nn.sigmoid(logits),\n",
    "#             }\n",
    "#         )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
