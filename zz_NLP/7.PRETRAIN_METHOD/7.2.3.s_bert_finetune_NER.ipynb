{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 버트를 활용한 한국어 개체명 인식 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/opt/anaconda3/lib/python3.11/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <CFED5F8E-EC3F-36FD-AAA3-2C6C7F8D3DD9> /opt/anaconda3/lib/python3.11/site-packages/torchvision/image.so\n",
      "  Expected in:     <A54E39C4-6B62-3303-9BE6-7DB88EB078BF> /opt/anaconda3/lib/python3.11/site-packages/torch/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/transformers/deepspeed.py:24: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import copy\n",
    "\n",
    "import tensorflow as tf\n",
    "from transformers import *\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from seqeval.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시각화\n",
    "\n",
    "def plot_graphs(histroy, string):\n",
    "    plt.plot(history.history[string])\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel(string)\n",
    "    plt.legend([string])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed 고정\n",
    "tf.random.set_seed(1234)\n",
    "np.random.seed(1234)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS =3\n",
    "MAX_LEN = 111 # EDA에서 추출된 Max Length\n",
    "DATA_IN_PATH = 'data_in/KOR'\n",
    "DATA_OUT_PATH = 'data_out/KOR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "개체명 인식 학습 데이터 개수: 81000\n",
      "개체명 인식 테스트 데이터 개수: 9000\n"
     ]
    }
   ],
   "source": [
    "# 데이터 전처리 준비\n",
    "DATA_TRAIN_PATH = os.path.join(DATA_IN_PATH, \"NER\", \"train.tsv\")\n",
    "DATA_LABEL_PATH = os.path.join(DATA_IN_PATH, \"NER\", \"label.txt\")\n",
    "DATA_TEST_PATH = os.path.join(DATA_IN_PATH, \"NER\", \"test.tsv\")\n",
    "\n",
    "def read_file(input_path):\n",
    "    \"\"\"Read tsv file, and return words and label as list\"\"\"\n",
    "    with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        sentences = []\n",
    "        labels = []\n",
    "        for line in f:\n",
    "            split_line = line.strip().split(\"\\t\")\n",
    "            sentences.append(split_line[0])\n",
    "            labels.append(split_line[1])\n",
    "        return sentences, labels\n",
    "\n",
    "train_sentences, train_labels = read_file(DATA_TRAIN_PATH)\n",
    "train_ner_dict = {\"sentence\": train_sentences, \"label\": train_labels}\n",
    "train_ner_df = pd.DataFrame(train_ner_dict)\n",
    "\n",
    "test_sentences, test_labels = read_file(DATA_TEST_PATH)\n",
    "test_ner_dict = {\"sentence\": test_sentences, \"label\": test_labels}\n",
    "test_ner_df = pd.DataFrame(test_ner_dict)\n",
    "\n",
    "print(\"개체명 인식 학습 데이터 개수: {}\".format(len(train_ner_df)))\n",
    "print(\"개체명 인식 테스트 데이터 개수: {}\".format(len(test_ner_df)))\n",
    "\n",
    "# 개체명 인식 학습 데이터 개수: 81000\n",
    "# 개체명 인식 테스트 데이터 개수: 9000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>금석객잔 여러분, 감사드립니다 .</td>\n",
       "      <td>ORG-B O O O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>이기범 한두 쪽을 먹고 10분 후쯤 화제인을 먹는 것이 좋다고 한다 .</td>\n",
       "      <td>PER-B O O O TIM-B TIM-I CVL-B O O O O O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7-8위 결정전에서 김중배 무스파타(샌안토니오)가 참은 법국을 누르고 유럽축구선수권...</td>\n",
       "      <td>EVT-B EVT-I PER-B PER-I O LOC-B O EVT-B CVL-B O O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>스코틀랜드의 한 마을에서 보통하게 살고 있다는 이 기혼 남성의 시조가 유튜브 등에서...</td>\n",
       "      <td>LOC-B NUM-B NUM-I O O O O O O O O O O O O O CV...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>보니까 저 옆에 사조가 있어요 .</td>\n",
       "      <td>O O O O O O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80995</th>\n",
       "      <td>원숭이 중에서도 침팬지의 유전체 요율은 16.8%가 일치해 그 차이는 13.23%에...</td>\n",
       "      <td>O O ANM-B O O NUM-B O O O NUM-B O O O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80996</th>\n",
       "      <td>세터 장쉬가 한국도로공사에서 전속해오면서 인천시장 인생에 전환점을 맞았다 .</td>\n",
       "      <td>CVL-B PER-B ORG-B O CVL-B O O O O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80997</th>\n",
       "      <td>국립대학교는 20쿼터 5분여를 남겨두고 2-94로 추격했다 .</td>\n",
       "      <td>ORG-B NUM-B TIM-B O NUM-B O O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80998</th>\n",
       "      <td>위원회는 격전 KIA전에서 간탁 안정숙상의 30.1이닝 무실점 장병문 문경현호의 야...</td>\n",
       "      <td>ORG-B EVT-B EVT-I O PER-B NUM-B NUM-B PER-B PE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80999</th>\n",
       "      <td>아시아선수권대회 출진 인터리커너미아지는 9월 28일부터 21일까지 차이나 영통구에서...</td>\n",
       "      <td>EVT-B O ORG-B DAT-B DAT-I DAT-I LOC-B LOC-B O ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence  \\\n",
       "0                                     금석객잔 여러분, 감사드립니다 .   \n",
       "1                이기범 한두 쪽을 먹고 10분 후쯤 화제인을 먹는 것이 좋다고 한다 .   \n",
       "2      7-8위 결정전에서 김중배 무스파타(샌안토니오)가 참은 법국을 누르고 유럽축구선수권...   \n",
       "3      스코틀랜드의 한 마을에서 보통하게 살고 있다는 이 기혼 남성의 시조가 유튜브 등에서...   \n",
       "4                                     보니까 저 옆에 사조가 있어요 .   \n",
       "...                                                  ...   \n",
       "80995  원숭이 중에서도 침팬지의 유전체 요율은 16.8%가 일치해 그 차이는 13.23%에...   \n",
       "80996         세터 장쉬가 한국도로공사에서 전속해오면서 인천시장 인생에 전환점을 맞았다 .   \n",
       "80997                 국립대학교는 20쿼터 5분여를 남겨두고 2-94로 추격했다 .   \n",
       "80998  위원회는 격전 KIA전에서 간탁 안정숙상의 30.1이닝 무실점 장병문 문경현호의 야...   \n",
       "80999  아시아선수권대회 출진 인터리커너미아지는 9월 28일부터 21일까지 차이나 영통구에서...   \n",
       "\n",
       "                                                   label  \n",
       "0                                            ORG-B O O O  \n",
       "1                PER-B O O O TIM-B TIM-I CVL-B O O O O O  \n",
       "2      EVT-B EVT-I PER-B PER-I O LOC-B O EVT-B CVL-B O O  \n",
       "3      LOC-B NUM-B NUM-I O O O O O O O O O O O O O CV...  \n",
       "4                                            O O O O O O  \n",
       "...                                                  ...  \n",
       "80995              O O ANM-B O O NUM-B O O O NUM-B O O O  \n",
       "80996                  CVL-B PER-B ORG-B O CVL-B O O O O  \n",
       "80997                      ORG-B NUM-B TIM-B O NUM-B O O  \n",
       "80998  ORG-B EVT-B EVT-I O PER-B NUM-B NUM-B PER-B PE...  \n",
       "80999  EVT-B O ORG-B DAT-B DAT-I DAT-I LOC-B LOC-B O ...  \n",
       "\n",
       "[81000 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ner_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>금석객잔 여러분, 감사드립니다 .</td>\n",
       "      <td>ORG-B O O O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>이기범 한두 쪽을 먹고 10분 후쯤 화제인을 먹는 것이 좋다고 한다 .</td>\n",
       "      <td>PER-B O O O TIM-B TIM-I CVL-B O O O O O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7-8위 결정전에서 김중배 무스파타(샌안토니오)가 참은 법국을 누르고 유럽축구선수권...</td>\n",
       "      <td>EVT-B EVT-I PER-B PER-I O LOC-B O EVT-B CVL-B O O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>스코틀랜드의 한 마을에서 보통하게 살고 있다는 이 기혼 남성의 시조가 유튜브 등에서...</td>\n",
       "      <td>LOC-B NUM-B NUM-I O O O O O O O O O O O O O CV...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>보니까 저 옆에 사조가 있어요 .</td>\n",
       "      <td>O O O O O O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16195</th>\n",
       "      <td>큰 축원경으로는 지구에서 15억광년 떨어진 곳에 있는 은하수도 볼 수 있는데요 .</td>\n",
       "      <td>O O O NUM-B O O O O O O O O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16196</th>\n",
       "      <td>그는 이 지르텍PC가 포맷된 어떤 SW가 설비됐는지 말하고, 노트북PC 속의 지워진...</td>\n",
       "      <td>O O TRM-B O O TRM-B O O TRM-B O O O O O O O O ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16197</th>\n",
       "      <td>손은서가 부진으로 20군으로 내려가 마커스의 에이스 역할이 요구되는 상태 .</td>\n",
       "      <td>PER-B O NUM-B O PER-B CVL-B O O O O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16198</th>\n",
       "      <td>-그렇게 케이트의 용지를 살피는 오상자이엘 .</td>\n",
       "      <td>O PER-B O O ORG-B O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16199</th>\n",
       "      <td>권함이 원하는 구가 데포르마시옹시킬 수 있다는 말인데, 점토의 체제 때문이죠 .</td>\n",
       "      <td>O O O O O O O O O O O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence  \\\n",
       "0                                     금석객잔 여러분, 감사드립니다 .   \n",
       "1                이기범 한두 쪽을 먹고 10분 후쯤 화제인을 먹는 것이 좋다고 한다 .   \n",
       "2      7-8위 결정전에서 김중배 무스파타(샌안토니오)가 참은 법국을 누르고 유럽축구선수권...   \n",
       "3      스코틀랜드의 한 마을에서 보통하게 살고 있다는 이 기혼 남성의 시조가 유튜브 등에서...   \n",
       "4                                     보니까 저 옆에 사조가 있어요 .   \n",
       "...                                                  ...   \n",
       "16195      큰 축원경으로는 지구에서 15억광년 떨어진 곳에 있는 은하수도 볼 수 있는데요 .   \n",
       "16196  그는 이 지르텍PC가 포맷된 어떤 SW가 설비됐는지 말하고, 노트북PC 속의 지워진...   \n",
       "16197         손은서가 부진으로 20군으로 내려가 마커스의 에이스 역할이 요구되는 상태 .   \n",
       "16198                          -그렇게 케이트의 용지를 살피는 오상자이엘 .   \n",
       "16199       권함이 원하는 구가 데포르마시옹시킬 수 있다는 말인데, 점토의 체제 때문이죠 .   \n",
       "\n",
       "                                                   label  \n",
       "0                                            ORG-B O O O  \n",
       "1                PER-B O O O TIM-B TIM-I CVL-B O O O O O  \n",
       "2      EVT-B EVT-I PER-B PER-I O LOC-B O EVT-B CVL-B O O  \n",
       "3      LOC-B NUM-B NUM-I O O O O O O O O O O O O O CV...  \n",
       "4                                            O O O O O O  \n",
       "...                                                  ...  \n",
       "16195                        O O O NUM-B O O O O O O O O  \n",
       "16196  O O TRM-B O O TRM-B O O TRM-B O O O O O O O O ...  \n",
       "16197                PER-B O NUM-B O PER-B CVL-B O O O O  \n",
       "16198                                O PER-B O O ORG-B O  \n",
       "16199                              O O O O O O O O O O O  \n",
       "\n",
       "[16200 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_length = len(train_ner_df) // 5\n",
    "train_ner_df = train_ner_df[:drop_length]\n",
    "train_ner_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "개체명 인식 레이블 개수: 30\n"
     ]
    }
   ],
   "source": [
    "# Label 불러오기\n",
    "# label 사전에서 확인할 것 \n",
    "\n",
    "def get_labels(label_path):\n",
    "    return [label.strip() for label in open(os.path.join(label_path),'r',encoding='utf-8')]\n",
    "\n",
    "ner_labels = get_labels(DATA_LABEL_PATH)\n",
    "\n",
    "print(f\"개체명 인식 레이블 개수: {len(ner_labels)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file vocab.txt from cache at bert-ckpt/models--bert-base-multilingual-cased/snapshots/3f076fdb1ab68d5b2880cb87a0886f315b8146f8/vocab.txt\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at bert-ckpt/models--bert-base-multilingual-cased/snapshots/3f076fdb1ab68d5b2880cb87a0886f315b8146f8/tokenizer_config.json\n",
      "loading file tokenizer.json from cache at bert-ckpt/models--bert-base-multilingual-cased/snapshots/3f076fdb1ab68d5b2880cb87a0886f315b8146f8/tokenizer.json\n",
      "loading configuration file config.json from cache at bert-ckpt/models--bert-base-multilingual-cased/snapshots/3f076fdb1ab68d5b2880cb87a0886f315b8146f8/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.44.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 버트 토크나이저 설정\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\", cache_dir='bert-ckpt', clean_up_tokenization_spaces=True)\n",
    "\n",
    "pad_token_id = tokenizer.pad_token_id # 0\n",
    "pad_token_label_id = 0\n",
    "cls_token_label_id = 0\n",
    "sep_token_label_id = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_tokenizer(sent, MAX_LEN):\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "        text = sent, \n",
    "        truncation=True,\n",
    "        add_special_tokens = True, # [CLS] 와 [SEP]추가\n",
    "        max_length = MAX_LEN,       # 문장 패팅 및 자르기 진행\n",
    "        # pad_to_max_length = True, # 버젼으로 인한 문구 변경 -> padding\n",
    "        padding = 'max_length',\n",
    "        return_attention_mask= True # 어텐션 마스크 설정\n",
    "    )\n",
    "\n",
    "    input_id = encoded_dict['input_ids']\n",
    "    attention_mask = encoded_dict['attention_mask']\n",
    "    token_type_id = encoded_dict['token_type_ids']\n",
    "\n",
    "    return input_id, attention_mask, token_type_id\n",
    "\n",
    "# BERT 토크나이저로 문장을 토큰화하고 레이블을 변환하는 함수\n",
    "def convert_label(words, labels_idx, ner_begin_label, max_seq_len):\n",
    "\n",
    "    tokens = []  # 문장을 BERT 토크나이저로 토큰화한 토큰들을 저장하는 리스트\n",
    "    label_ids = []  # 토큰에 대응하는 레이블 인덱스를 저장하는 리스트\n",
    "\n",
    "    # 단어와 각 단어에 대응하는 NER 레이블을 반복 처리\n",
    "    for word, slot_label in zip(words, labels_idx):\n",
    "\n",
    "        # 단어를 BERT 토크나이저로 토큰화\n",
    "        word_tokens = tokenizer.tokenize(word)\n",
    "\n",
    "        # 만약 단어가 토큰화되지 않는 경우(토큰이 없으면), [UNK] 토큰을 대신 사용\n",
    "        if not word_tokens:\n",
    "            word_tokens = [unk_token]\n",
    "        \n",
    "        # 토큰화된 단어들을 tokens 리스트에 추가\n",
    "        tokens.extend(word_tokens)\n",
    "\n",
    "        # 슬롯 레이블이 NER Begin(B-) 레이블인 경우 (예: B-PER), 첫 번째 토큰에만 Begin 레이블을, 나머지 토큰에는 Inside(I-) 레이블 추가\n",
    "        if int(slot_label) in ner_begin_label:\n",
    "            # 첫 번째 토큰에는 Begin 레이블, 나머지 토큰에는 Inside 레이블을 추가\n",
    "            label_ids.extend([int(slot_label)] + [int(slot_label) + 1] * (len(word_tokens) - 1))\n",
    "        else:\n",
    "            # Begin 레이블이 아닌 경우는 모든 토큰에 동일한 레이블을 적용\n",
    "            label_ids.extend([int(slot_label)] * len(word_tokens))\n",
    "\n",
    "    # 특수 토큰 [CLS]와 [SEP]이 필요하므로 그만큼 시퀀스 길이를 제한 (BERT 입력 형식에 맞게)\n",
    "    special_tokens_count = 2\n",
    "    if len(label_ids) > max_seq_len - special_tokens_count:\n",
    "        # 최대 시퀀스 길이를 넘지 않도록 label_ids를 자름\n",
    "        label_ids = label_ids[: (max_seq_len - special_tokens_count)]\n",
    "\n",
    "    # [SEP] 토큰에 해당하는 레이블을 추가\n",
    "    label_ids = [sep_token_label_id]\n",
    "\n",
    "    # [CLS] 토큰에 해당하는 레이블을 추가하고, 기존 레이블을 연결\n",
    "    label_ids = [cls_token_label_id] + label_ids\n",
    "\n",
    "    # 시퀀스 길이를 max_seq_len에 맞추기 위해 패딩을 추가\n",
    "    padding_length = max_seq_len - len(label_ids)\n",
    "    # 패딩 레이블을 추가하여 시퀀스 길이를 맞춤\n",
    "    label_ids = label_ids + ([pad_token_label_id] * padding_length)\n",
    "\n",
    "    return label_ids  # 변환된 레이블 리스트를 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28]\n",
      "['PER-B', 'FLD-B', 'AFW-B', 'ORG-B', 'LOC-B', 'CVL-B', 'DAT-B', 'TIM-B', 'NUM-B', 'EVT-B', 'ANM-B', 'PLT-B', 'MAT-B', 'TRM-B']\n"
     ]
    }
   ],
   "source": [
    "# 테스트용\n",
    "ner_begin_label = [ner_labels.index(begin_label)for begin_label in ner_labels if \"B\" in begin_label]\n",
    "ner_begin_label_string = [ner_labels[label_index] for label_index in ner_begin_label]\n",
    "\n",
    "print(ner_begin_label)\n",
    "print(ner_begin_label_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_begin_label = [ner_labels.index(begin_label) for begin_label in ner_labels if \"B\" in begin_label]\n",
    "\n",
    "def create_inputs_targets(df):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    token_type_ids = []\n",
    "    label_list = []\n",
    "\n",
    "    for i, data in enumerate(df[['sentence', 'label']].values):\n",
    "        sentence, labels = data\n",
    "        words = sentence.split()\n",
    "        labels = labels.split()\n",
    "        labels_idx = []\n",
    "        \n",
    "        for label in labels:\n",
    "            labels_idx.append(ner_labels.index(label) if label in ner_labels else ner_labels.index(\"UNK\"))\n",
    "\n",
    "        assert len(words) == len(labels_idx)\n",
    "\n",
    "        input_id, attention_mask, token_type_id = bert_tokenizer(sentence, MAX_LEN)\n",
    "\n",
    "        convert_label_id = convert_label(words, labels_idx, ner_begin_label, MAX_LEN)\n",
    "\n",
    "        input_ids.append(input_id)\n",
    "        attention_masks.append(attention_mask)\n",
    "        token_type_ids.append(token_type_id)\n",
    "        label_list.append(convert_label_id)\n",
    "\n",
    "    input_ids = np.array(input_ids, dtype=int)\n",
    "    attention_masks = np.array(attention_masks, dtype=int)\n",
    "    token_type_ids = np.array(token_type_ids, dtype=int)\n",
    "    label_list = np.asarray(label_list, dtype=int) #레이블 토크나이징 리스트\n",
    "    inputs = (input_ids, attention_masks, token_type_ids)\n",
    "    \n",
    "    return inputs, label_list\n",
    "\n",
    "train_inputs, train_labels = create_inputs_targets(train_ner_df)\n",
    "test_inputs, test_labels = create_inputs_targets(test_ner_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFBertNERClassifier(tf.keras.Model):\n",
    "    def __init__(self, model_name, dir_path, num_class):\n",
    "        super(TFBertNERClassifier, self).__init__()\n",
    "\n",
    "        self.bert = TFBertModel.from_pretrained(model_name, cache_dir=dir_path)\n",
    "        self.dropout = tf.keras.layers.Dropout(self.bert.config.hidden_dropout_prob)\n",
    "        self.classifier = tf.keras.layers.Dense(num_class, \n",
    "                                                kernel_initializer=tf.keras.initializers.TruncatedNormal(self.bert.config.initializer_range),\n",
    "                                                name=\"ner_classifier\")\n",
    "\n",
    "    def call(self, inputs, attention_mask=None, token_type_ids=None, training=False):\n",
    "\n",
    "        #outputs 값: # sequence_output, pooled_output, (hidden_states), (attentions)\n",
    "        outputs = self.bert(inputs, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        sequence_output = outputs[0]\n",
    "                \n",
    "        sequence_output = self.dropout(sequence_output, training=training)\n",
    "        logits = self.classifier(sequence_output)\n",
    "        \n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at bert_ckpt/models--bert-base-multilingual-cased/snapshots/3f076fdb1ab68d5b2880cb87a0886f315b8146f8/config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.44.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at bert_ckpt/models--bert-base-multilingual-cased/snapshots/3f076fdb1ab68d5b2880cb87a0886f315b8146f8/model.safetensors\n",
      "Loaded 177,853,440 parameters in the TF 2.0 model.\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "ner_model = TFBertNERClassifier(model_name='bert-base-multilingual-cased',\n",
    "                                  dir_path='bert_ckpt',\n",
    "                                  num_class=len(ner_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실함수에 대하여 커스텀 하는 함수\n",
    "def compute_loss(labels, logits):\n",
    "    # SparseCategoricalCrossentropy 손실 함수 정의\n",
    "    # from_logits=True: 로짓 값을 입력으로 받아 내부에서 소프트맥스를 적용\n",
    "    # reduction=tf.keras.losses.Reduction.NONE: 각 데이터 포인트에 대해 개별적인 손실 값을 반환\n",
    "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True, reduction=tf.keras.losses.Reduction.NONE\n",
    "    )\n",
    "\n",
    "    # 0의 레이블 값은 손실 계산에서 제외하기 위해 마스크 생성\n",
    "    # labels를 1D 형태로 변환하고, 값이 0이 아닌 부분에 대해서만 True인 마스크를 생성\n",
    "    active_loss = tf.reshape(labels, (-1,)) != 0\n",
    "\n",
    "    # logits도 1D 형태로 변환한 후, active_loss가 True인 부분만 남긴다\n",
    "    # shape_list(logits)[2]는 logits의 마지막 차원의 크기를 의미 (클래스 수)\n",
    "    reduced_logits = tf.boolean_mask(tf.reshape(logits, (-1, shape_list(logits)[2])), active_loss)\n",
    "\n",
    "    # labels도 active_loss가 True인 값만 남긴다\n",
    "    # 0인 레이블은 손실 계산에서 제외되므로, 해당 부분에 대해 마스크를 적용\n",
    "    labels = tf.boolean_mask(tf.reshape(labels, (-1,)), active_loss)\n",
    "\n",
    "    # 손실 값을 계산하고 반환\n",
    "    return loss_fn(labels, reduced_logits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class F1Metrics(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, x_eval, y_eval):\n",
    "        self.x_eval = x_eval\n",
    "        self.y_eval = y_eval\n",
    "\n",
    "    def compute_f1_pre_rec(self, labels, preds):\n",
    "\n",
    "        return {\n",
    "            \"precision\": precision_score(labels, preds, suffix=True),\n",
    "            \"recall\": recall_score(labels, preds, suffix=True),\n",
    "            \"f1\": f1_score(labels, preds, suffix=True)\n",
    "        }\n",
    "\n",
    "\n",
    "    def show_report(self, labels, preds):\n",
    "        return classification_report(labels, preds, suffix=True)\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "\n",
    "        results = {}\n",
    "        \n",
    "        pred = self.model.predict(self.x_eval)\n",
    "        label = self.y_eval\n",
    "        pred_argmax = np.argmax(pred, axis = 2)\n",
    "\n",
    "        slot_label_map = {i: label for i, label in enumerate(ner_labels)}\n",
    "\n",
    "        out_label_list = [[] for _ in range(label.shape[0])]\n",
    "        preds_list = [[] for _ in range(label.shape[0])]\n",
    "\n",
    "        for i in range(label.shape[0]):\n",
    "            for j in range(label.shape[1]):\n",
    "                if label[i, j] != 0:\n",
    "                    out_label_list[i].append(slot_label_map[label[i][j]])\n",
    "                    preds_list[i].append(slot_label_map[pred_argmax[i][j]])\n",
    "                    \n",
    "        result = self.compute_f1_pre_rec(out_label_list, preds_list)\n",
    "        results.update(result)\n",
    "\n",
    "        print(\"********\")\n",
    "        print(\"F1 Score\")\n",
    "        for key in sorted(results.keys()):\n",
    "            print(\"{}, {:.4f}\".format(key, results[key]))\n",
    "        print(\"\\n\" + self.show_report(out_label_list, preds_list))\n",
    "        print(\"********\")\n",
    "\n",
    "f1_score_callback = F1Metrics(test_inputs, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # F1Metrics 클래스는 keras의 콜백을 상속받아 모델 평가 시 F1 점수를 계산하는 클래스\n",
    "# class F1Metrics(tf.keras.callbacks.Callback):\n",
    "#     # 클래스 초기화\n",
    "#     def __init__(self, x_eval, y_eval):\n",
    "#         # 평가할 데이터셋을 입력으로 받음\n",
    "#         self.x_eval = x_eval  # 평가용 입력 데이터\n",
    "#         self.y_eval = y_eval  # 평가용 레이블 데이터\n",
    "\n",
    "#     # F1 점수, precision(정밀도), recall(재현율)을 계산하는 함수\n",
    "#     def compute_f1_pre_rec(self, labels, preds):\n",
    "#         return {\n",
    "#             \"precision\": precision_score(labels, preds, suffix=True),  # 정밀도 계산\n",
    "#             \"recall\": recall_score(labels, preds, suffix=True),          # 재현율 계산\n",
    "#             \"f1\": f1_score(labels, preds, suffix=True)                   # F1 점수 계산\n",
    "#         }\n",
    "\n",
    "#     # classification_report 출력 (자세한 분류 성능 보고서 출력)\n",
    "#     def show_report(self, labels, preds):\n",
    "#         return classification_report(labels, preds, suffix=True)\n",
    "\n",
    "#     # 각 에포크가 끝날 때마다 호출\n",
    "#     def on_epoch_end(self, epoch, logs=None):\n",
    "#         results = {}  # 평가 결과 저장용 딕셔너리\n",
    "        \n",
    "#         # 모델에 평가용 데이터를 입력하여 예측값 생성\n",
    "#         pred = self.model.predict(self.x_eval)  # 평가 데이터에 대한 예측값\n",
    "#         label = self.y_eval  # 실제 레이블\n",
    "#         pred_argmax = np.argmax(pred, axis=2)  # 예측 결과에서 가장 높은 확률을 가진 클래스 선택 (argmax)\n",
    "\n",
    "#         # NER 레이블 맵 (숫자 인덱스를 실제 레이블 이름으로 매핑)\n",
    "#         slot_label_map = {i: label for i, label in enumerate(ner_labels)}\n",
    "\n",
    "#         # 각 문장마다 실제 레이블과 예측 레이블을 저장할 리스트 초기화\n",
    "#         out_label_list = [[] for _ in range(label.shape[0])]  # 실제 레이블\n",
    "#         preds_list = [[] for _ in range(label.shape[0])]      # 예측 레이블\n",
    "\n",
    "#         # 각 문장과 각 토큰에 대해 실제 레이블과 예측 레이블을 수집\n",
    "#         for i in range(label.shape[0]):  # 문장 단위로 반복\n",
    "#             for j in range(label.shape[1]):  # 각 문장 안에서 토큰 단위로 반복\n",
    "#                 # 레이블이 0(패딩)이 아닌 경우에만 레이블을 수집\n",
    "#                 if label[i, j] != 0:\n",
    "#                     out_label_list[i].append(slot_label_map[label[i][j]])  # 실제 레이블\n",
    "#                     preds_list[i].append(slot_label_map[pred_argmax[i][j]])  # 예측된 레이블\n",
    "\n",
    "#         # 수집된 실제 레이블과 예측 레이블로 F1, precision, recall 계산\n",
    "#         result = self.compute_f1_pre_rec(out_label_list, preds_list)\n",
    "#         results.update(result)  # 결과를 저장\n",
    "\n",
    "#         # F1 점수와 각 지표 출력\n",
    "#         print(\"********\")\n",
    "#         print(\"F1 Score\")\n",
    "#         for key in sorted(results.keys()):  # precision, recall, f1 순서로 출력\n",
    "#             print(\"{}, {:.4f}\".format(key, results[key]))\n",
    "#         # 상세한 classification_report 출력\n",
    "#         print(\"\\n\" + self.show_report(out_label_list, preds_list))\n",
    "#         print(\"********\")\n",
    "\n",
    "# # F1Metrics 콜백을 생성하고, 평가 데이터로 초기화\n",
    "# f1_score_callback = F1Metrics(test_inputs, test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training: Compile tf.keras model with optimizer, loss and learning rate schedule\n",
    "optimizer = tf.keras.optimizers.Adam(3e-5)\n",
    "# ner_model.compile(optimizer=optimizer, loss=compute_loss, run_eagerly=True)\n",
    "ner_model.compile(optimizer= optimizer, loss=compute_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_out/KOR/tf2_bert_ner -- Folder already exists \n",
      "\n",
      "Epoch 1/3\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m708s\u001b[0m 3s/step\n",
      "********\n",
      "F1 Score\n",
      "f1, 0.0000\n",
      "precision, 0.0000\n",
      "recall, 0.0000\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "max() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 19\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# cp_callback = ModelCheckpoint(\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m#     checkpoint_path, verbose=1, save_best_only=True, save_weights_only=True, motinor='loss')\u001b[39;00m\n\u001b[1;32m     16\u001b[0m cp_callback \u001b[38;5;241m=\u001b[39m ModelCheckpoint(\n\u001b[1;32m     17\u001b[0m     checkpoint_path, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, save_weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 19\u001b[0m history \u001b[38;5;241m=\u001b[39m ner_model\u001b[38;5;241m.\u001b[39mfit(train_inputs, train_labels, batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE, epochs\u001b[38;5;241m=\u001b[39mNUM_EPOCHS,\n\u001b[1;32m     20\u001b[0m                         callbacks\u001b[38;5;241m=\u001b[39m[cp_callback, f1_score_callback])\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(history\u001b[38;5;241m.\u001b[39mhistory)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[0;32mIn[18], line 44\u001b[0m, in \u001b[0;36mF1Metrics.on_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(results\u001b[38;5;241m.\u001b[39mkeys()):\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(key, results[key]))\n\u001b[0;32m---> 44\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshow_report(out_label_list, preds_list))\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m********\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[18], line 16\u001b[0m, in \u001b[0;36mF1Metrics.show_report\u001b[0;34m(self, labels, preds)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshow_report\u001b[39m(\u001b[38;5;28mself\u001b[39m, labels, preds):\n\u001b[0;32m---> 16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m classification_report(labels, preds, suffix\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/seqeval/metrics/sequence_labeling.py:686\u001b[0m, in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, digits, suffix, output_dict, mode, sample_weight, zero_division, scheme)\u001b[0m\n\u001b[1;32m    684\u001b[0m     reporter \u001b[38;5;241m=\u001b[39m DictReporter()\n\u001b[1;32m    685\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 686\u001b[0m     name_width \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mlen\u001b[39m, target_names))\n\u001b[1;32m    687\u001b[0m     avg_width \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweighted avg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    688\u001b[0m     width \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(name_width, avg_width, digits)\n",
      "\u001b[0;31mValueError\u001b[0m: max() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    "model_name = \"tf2_bert_ner\"\n",
    "\n",
    "checkpoint_path = os.path.join(DATA_OUT_PATH, model_name, '.weights.h5')\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create path if exists\n",
    "if os.path.exists(checkpoint_dir):\n",
    "    print(\"{} -- Folder already exists \\n\".format(checkpoint_dir))\n",
    "else:\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    print(\"{} -- Folder create complete \\n\".format(checkpoint_dir))\n",
    "    \n",
    "# cp_callback = ModelCheckpoint(\n",
    "#     checkpoint_path, verbose=1, save_best_only=True, save_weights_only=True, motinor='loss')\n",
    "\n",
    "cp_callback = ModelCheckpoint(\n",
    "    checkpoint_path, verbose=1, save_best_only=True, save_weights_only=True)\n",
    "\n",
    "history = ner_model.fit(train_inputs, train_labels, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS,\n",
    "                        callbacks=[cp_callback, f1_score_callback])\n",
    "\n",
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graphs(history, 'loss')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
