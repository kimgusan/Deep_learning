# 사전 학습 모델
사전 학습 (Pretrained) 모델과 미세 조정 (Fine-tuned) 학습에 대해서 알아보도록 합시다.  
여기서 활용하는 모델은BERT라는 모델과 GPT3 모델을 사용합니다. 

## 실습 자원
---
본 장에서 활용하게 될 모델과 데이터 셋 입니다.

### 모델
- Huggingface의 Transformers 라이브러리 도큐먼트
- 구글 공식 BERT 깃허브 저장소
- Ko-GPT3 모델 깃허브 저장소

### 데이터
- KorNLU Dataset
- Naver NLP Challenge Dataset
- KorQuAD 1.0

## 실습 내용
---
### 7.2 버트를 활용한 미세 조정 학습
- 버트를 활용한 한국어 텍스트 분류 모델
- 버트를 활용한 한국어 자연어 추론 모델 (데이터 분석)
- 버트를 활용한 한국어 개체명 인식 모델 (데이터 분석)
- 버트를 활용한 한국어 텍스트 유사도 모델 (데이터 분석)
- 버트를 활용한 한국어 기계 독해 모델

### 7.3 GPT

### 7.4 GPT3를 활용한 미세 조정 학습
- GPT3를 활용한 한국어 언어 생성 모델
- GPT3를 활용한 한국어 텍스트 분류 모델
- GPT3를 활용한 한국어 자연어 추론 모델
- GPT3를 활용한 한국어 텍스트 유사도 모델